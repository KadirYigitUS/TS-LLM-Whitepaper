ordinal,file_stub,category,authors,year,title,doi,url,stage,vector,raw
1,001_Bowker_2023,Tertiary Sources (Translation Theory & Critique),"Bowker, L",2023,"De-mystifying translation: Introducing translation to non-translators",10.4324/9781003217718,https://doi.org/10.4324/9781003217718,,Critique,"Bowker, L. (2023). *De-mystifying translation: Introducing translation to non-translators* (1st ed.). Routledge. https://doi.org/10.4324/9781003217718"
2,002_Brown_2020,Primary Sources (The Seminal LLM Papers),"Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., ... Amodei, D",2020,"Language models are few-shot learners",10.48550/arXiv.2005.14165,https://doi.org/10.48550/arXiv.2005.14165,Scale,,"Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., ... Amodei, D. (2020). Language models are few-shot learners. *Advances in Neural Information Processing Systems*, 33, 1877–1901. https://doi.org/10.48550/arXiv.2005.14165"
3,003_Devlin_2019,Primary Sources (The Seminal LLM Papers),"Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K",2019,"BERT: Pre-training of deep bidirectional transformers for language understanding",10.48550/arXiv.1810.04805,https://doi.org/10.48550/arXiv.1810.04805,Context,,"Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. *Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies*, 1, 4171–4186. https://doi.org/10.48550/arXiv.1810.04805"
4,004_Halliday_1978,Tertiary Sources (Translation Theory & Critique),"Halliday, M. A. K",1978,"Language as social semiotic: The social interpretation of language and meaning",,https://archive.org/details/languageassocial0000hall,,Context,"Halliday, M. A. K. (1978). *Language as social semiotic: The social interpretation of language and meaning*. Edward Arnold. https://archive.org/details/languageassocial0000hall"
5,005_House_2015,Tertiary Sources (Translation Theory & Critique),"House, J",2015,"Translation quality assessment: Past and present",10.4324/9781315752839,https://doi.org/10.4324/9781315752839,,Context,"House, J. (2015). *Translation quality assessment: Past and present*. Routledge. https://doi.org/10.4324/9781315752839"
6,006_Jurafsky_2024,Secondary Sources (NLP & Engineering Foundations),"Jurafsky, D., & Martin, J. H",2024,""Speech and language processing: An introduction to natural language processing", computational linguistics, and speech recognition (3rd draft ed",,,Pre-Neural,,"Jurafsky, D., & Martin, J. H. (2024). *Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition* (3rd draft ed.). Stanford University. https://web.stanford.edu/~jurafsky/slp3/"
7,007_Kaplan_2020,Primary Sources (The Seminal LLM Papers),"Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., & Amodei, D",2020,"Scaling laws for neural language models",10.48550/arXiv.2001.08361,https://doi.org/10.48550/arXiv.2001.08361,Scale,,"Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., & Amodei, D. (2020). *Scaling laws for neural language models*. arXiv. https://doi.org/10.48550/arXiv.2001.08361"
8,008_Kenny_2022,Tertiary Sources (Translation Theory & Critique),"Kenny, D.",2022,"Machine translation for everyone: Empowering users in the age of artificial intelligence",,https://langsci-press.org/catalog/book/385,,Critique,"Kenny, D. (2022). *Machine translation for everyone: Empowering users in the age of artificial intelligence*. Language Science Press. https://langsci-press.org/catalog/book/385"
9,009_Koehn_2010,Tertiary Sources (Translation Theory & Critique),"Koehn, P",2010,"Statistical machine translation",10.1017/CBO9780511815820,https://doi.org/10.1017/CBO9780511815820,,Critique,"Koehn, P. (2010). *Statistical machine translation*. Cambridge University Press. https://doi.org/10.1017/CBO9780511815820"
10,010_Koehn_2020,Tertiary Sources (Translation Theory & Critique),"Koehn, P",2020,"Neural machine translation",10.1017/9781108608480,https://doi.org/10.1017/9781108608480,,,"Koehn, P. (2020). *Neural machine translation*. Cambridge University Press. https://doi.org/10.1017/9781108608480"
11,011_Longpre_2023,Primary Sources (The Seminal LLM Papers),"Longpre, S., Hou, L., Vu, T., Webson, A., Chung, H. W., Tay, Y., Zhou, D., Le, Q. V., Zoph, B., Wei, J., & Roberts, A",2023,"The Flan collection: Designing data and methods for effective instruction tuning",10.48550/arXiv.2301.13688,https://doi.org/10.48550/arXiv.2301.13688,Alignment,,"Longpre, S., Hou, L., Vu, T., Webson, A., Chung, H. W., Tay, Y., Zhou, D., Le, Q. V., Zoph, B., Wei, J., & Roberts, A. (2023). The Flan collection: Designing data and methods for effective instruction tuning. *Proceedings of the 40th International Conference on Machine Learning*, 202, 22631–22648. https://doi.org/10.48550/arXiv.2301.13688"
12,012_Mikolov_2013,Secondary Sources (NLP & Engineering Foundations),"Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J",2013,"Distributed representations of words and phrases and their compositionality",10.48550/arXiv.1310.4546,https://doi.org/10.48550/arXiv.1310.4546,Pre-Neural,,"Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of words and phrases and their compositionality. *Advances in Neural Information Processing Systems*, 26, 3111–3119. https://doi.org/10.48550/arXiv.1310.4546"
13,013_Nord_1997,Tertiary Sources (Translation Theory & Critique),"Nord, C",1997,"Translating as a purposeful activity: Functionalist approaches explained",,,,Skopos,"Nord, C. (1997). *Translating as a purposeful activity: Functionalist approaches explained*. St. Jerome Publishing."
14,014_Ouyang_2022,Primary Sources (The Seminal LLM Papers),"Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., & Kelton, F",2022,"Training language models to follow instructions with human feedback",10.48550/arXiv.2203.02155,https://doi.org/10.48550/arXiv.2203.02155,Alignment,,"Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., & Kelton, F. (2022). Training language models to follow instructions with human feedback. *Advances in Neural Information Processing Systems*, 35, 27730–27744. https://doi.org/10.48550/arXiv.2203.02155"
15,015_Reiss_2013,Tertiary Sources (Translation Theory & Critique),"Reiss, K., & Vermeer, H. J",2013,"Towards a general theory of translational action: Skopos theory explained",,,,Skopos,"Reiss, K., & Vermeer, H. J. (2013). *Towards a general theory of translational action: Skopos theory explained* (C. Nord, Trans.). St. Jerome Publishing."
16,016_Schick_2023,Primary Sources (The Seminal LLM Papers),"Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., & Scialom, T",2023,"Toolformer: Language models can teach themselves to use tools",10.48550/arXiv.2302.04761,https://doi.org/10.48550/arXiv.2302.04761,Agency,,"Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., & Scialom, T. (2023). Toolformer: Language models can teach themselves to use tools. *arXiv*. https://doi.org/10.48550/arXiv.2302.04761"
17,017_Touvron_2023,Primary Sources (The Seminal LLM Papers),"Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Edunov, S., & Lample, G",2023,"LLaMA: Open and efficient foundation language models",10.48550/arXiv.2302.13971,https://doi.org/10.48550/arXiv.2302.13971,Efficiency,,"Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Edunov, S., & Lample, G. (2023). *LLaMA: Open and efficient foundation language models*. arXiv. https://doi.org/10.48550/arXiv.2302.13971"
18,018_Vaswani_2017,Primary Sources (The Seminal LLM Papers),"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I",2017,"Attention is all you need",10.48550/arXiv.1706.03762,https://doi.org/10.48550/arXiv.1706.03762,Architecture,,"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017). Attention is all you need. *Advances in Neural Information Processing Systems*, 30. https://doi.org/10.48550/arXiv.1706.03762"
19,019_Wei_2022,Primary Sources (The Seminal LLM Papers),"Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., & Zhou, D",2022,"Chain-of-thought prompting elicits reasoning in large language models",10.48550/arXiv.2201.11903,https://doi.org/10.48550/arXiv.2201.11903,Reasoning,,"Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., & Zhou, D. (2022). Chain-of-thought prompting elicits reasoning in large language models. *Advances in Neural Information Processing Systems*, 35, 24824–24837. https://doi.org/10.48550/arXiv.2201.11903"
