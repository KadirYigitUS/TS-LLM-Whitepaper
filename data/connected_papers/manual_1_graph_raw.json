{
  "common_authors": [
    {
      "id": "1757942",
      "mention_indexes": [
        2,
        22
      ],
      "mentions": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "eaa7b6893790279292e9f2fafe48662af8b6ae3d"
      ],
      "name": "Feras Dayoub",
      "url": "https://www.semanticscholar.org/author/1757942"
    },
    {
      "id": "1803115",
      "mention_indexes": [
        2,
        22
      ],
      "mentions": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "eaa7b6893790279292e9f2fafe48662af8b6ae3d"
      ],
      "name": "B. Upcroft",
      "url": "https://www.semanticscholar.org/author/1803115"
    },
    {
      "id": "1867220",
      "mention_indexes": [
        2,
        29,
        22
      ],
      "mentions": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "c4700a0be2f3621310c5d1142bd2d29431efcc10",
        "eaa7b6893790279292e9f2fafe48662af8b6ae3d"
      ],
      "name": "Inkyu Sa",
      "url": "https://www.semanticscholar.org/author/1867220"
    },
    {
      "id": "1980700",
      "mention_indexes": [
        19,
        30
      ],
      "mentions": [
        "1c8c77afa31d57c45cfbf404231217dc4db17a14",
        "7e1e9488e65ad2f9d9171ebac959969b1ca19188"
      ],
      "name": "Simon Denman",
      "url": "https://www.semanticscholar.org/author/1980700"
    },
    {
      "id": "2011584",
      "mention_indexes": [
        5,
        10
      ],
      "mentions": [
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946"
      ],
      "name": "K. Walsh",
      "url": "https://www.semanticscholar.org/author/2011584"
    },
    {
      "id": "2068824789",
      "mention_indexes": [
        19,
        30,
        2,
        29,
        22
      ],
      "mentions": [
        "1c8c77afa31d57c45cfbf404231217dc4db17a14",
        "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "c4700a0be2f3621310c5d1142bd2d29431efcc10",
        "eaa7b6893790279292e9f2fafe48662af8b6ae3d"
      ],
      "name": "Tristan Perez",
      "url": "https://www.semanticscholar.org/author/2068824789"
    },
    {
      "id": "2145911384",
      "mention_indexes": [
        5,
        10
      ],
      "mentions": [
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946"
      ],
      "name": "Zhenglin Wang",
      "url": "https://www.semanticscholar.org/author/2145911384"
    },
    {
      "id": "2355154",
      "mention_indexes": [
        29,
        22
      ],
      "mentions": [
        "c4700a0be2f3621310c5d1142bd2d29431efcc10",
        "eaa7b6893790279292e9f2fafe48662af8b6ae3d"
      ],
      "name": "Christopher F. Lehnert",
      "url": "https://www.semanticscholar.org/author/2355154"
    },
    {
      "id": "2690856",
      "mention_indexes": [
        7,
        15,
        8
      ],
      "mentions": [
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
        "b95191e4672475b32d0a4c571bd2817659747dca"
      ],
      "name": "Suchet Bargoti",
      "url": "https://www.semanticscholar.org/author/2690856"
    },
    {
      "id": "2861522",
      "mention_indexes": [
        19,
        30
      ],
      "mentions": [
        "1c8c77afa31d57c45cfbf404231217dc4db17a14",
        "7e1e9488e65ad2f9d9171ebac959969b1ca19188"
      ],
      "name": "Michael Halstead",
      "url": "https://www.semanticscholar.org/author/2861522"
    },
    {
      "id": "3140440",
      "mention_indexes": [
        19,
        30
      ],
      "mentions": [
        "1c8c77afa31d57c45cfbf404231217dc4db17a14",
        "7e1e9488e65ad2f9d9171ebac959969b1ca19188"
      ],
      "name": "C. Fookes",
      "url": "https://www.semanticscholar.org/author/3140440"
    },
    {
      "id": "3319082",
      "mention_indexes": [
        7,
        15,
        8
      ],
      "mentions": [
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
        "b95191e4672475b32d0a4c571bd2817659747dca"
      ],
      "name": "J. Underwood",
      "url": "https://www.semanticscholar.org/author/3319082"
    },
    {
      "id": "49872143",
      "mention_indexes": [
        19,
        30,
        2,
        29,
        22
      ],
      "mentions": [
        "1c8c77afa31d57c45cfbf404231217dc4db17a14",
        "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "c4700a0be2f3621310c5d1142bd2d29431efcc10",
        "eaa7b6893790279292e9f2fafe48662af8b6ae3d"
      ],
      "name": "C. McCool",
      "url": "https://www.semanticscholar.org/author/49872143"
    },
    {
      "id": "7239856",
      "mention_indexes": [
        5,
        10
      ],
      "mentions": [
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946"
      ],
      "name": "A. Koirala",
      "url": "https://www.semanticscholar.org/author/7239856"
    }
  ],
  "common_citations": [
    {
      "abstract": "S2 TL;DR: The results demonstrated that this vision algorithm designed in a deep learning framework was robust against various illuminations and complex backgrounds, and yielded satisfactory segmentation and picking-point detection performances for minor and medium occlusion or overlap, and for medium and large mangoes.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "1490866837"
          ],
          "name": "Chan Zheng"
        },
        {
          "ids": [
            null
          ],
          "name": "Pengfei Chen"
        },
        {
          "ids": [
            "2054728466"
          ],
          "name": "Jing Pang"
        },
        {
          "ids": [
            "2109504822"
          ],
          "name": "Xiaofan Yang"
        },
        {
          "ids": [
            "2156749639"
          ],
          "name": "Chen Changxin"
        },
        {
          "ids": [
            "41157630"
          ],
          "name": "S. Tu"
        },
        {
          "ids": [
            "3104125"
          ],
          "name": "Yueju Xue"
        }
      ],
      "corpusid": 234815086,
      "doi": "10.1016/J.BIOSYSTEMSENG.2021.03.012",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 234815086,
        "DBLP": null,
        "DOI": "10.1016/J.BIOSYSTEMSENG.2021.03.012",
        "MAG": "3155085480",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering",
        "Environmental Science"
      ],
      "id": "2a98f4df8a0c0c0a388a38e2c9c494149cd85355",
      "isOpenAccess": false,
      "journalName": "Biosystems Engineering",
      "journalPages": "32-54",
      "journalVolume": "206",
      "magId": "3155085480",
      "number_of_authors": 7,
      "paperId": "2a98f4df8a0c0c0a388a38e2c9c494149cd85355",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2021-06-01",
      "publicationTypes": null,
      "title": "A mango picking vision algorithm on instance segmentation and key point detection from RGB images in an open orchard",
      "tldr": "The results demonstrated that this vision algorithm designed in a deep learning framework was robust against various illuminations and complex backgrounds, and yielded satisfactory segmentation and picking-point detection performances for minor and medium occlusion or overlap, and for medium and large mangoes.",
      "url": "https://www.semanticscholar.org/paper/2a98f4df8a0c0c0a388a38e2c9c494149cd85355",
      "venue": "",
      "year": 2021,
      "edges_count": 45,
      "local_references": [
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a598e30cce3902fafa5c2692e2ad68437339b383",
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946",
        "b95191e4672475b32d0a4c571bd2817659747dca",
        "c2eaffc617c57ab5106ba3bc95b7b910be473389",
        "d3eb6e57f618cf0830678594efd7e67eec76a898",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "2a98f4df8a0c0c0a388a38e2c9c494149cd85355",
      "pi_name": "Yueju Xue"
    },
    {
      "abstract": "S2 TL;DR: An algorithmic pipeline for detection and yield estimation of melons from top-view color images acquired by a digital camera mounted on an unmanned aerial vehicle, and overall yield estimation derived by summing the weights of all melons in the field resulted in only a 3% underestimation of the actual total yield.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2023676090"
          ],
          "name": "A. Kalantar"
        },
        {
          "ids": [
            "1726598"
          ],
          "name": "Y. Edan"
        },
        {
          "ids": [
            "2047255517"
          ],
          "name": "A. Gur"
        },
        {
          "ids": [
            "2399212"
          ],
          "name": "I. Klapp"
        }
      ],
      "corpusid": 225119211,
      "doi": "10.1016/j.compag.2020.105748",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 225119211,
        "DBLP": "journals/cea/KalantarEGK20",
        "DOI": "10.1016/j.compag.2020.105748",
        "MAG": "3092383557",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering",
        "Mathematics"
      ],
      "id": "d28f8ba640a7d70ef195077008f110b788cac43d",
      "isOpenAccess": false,
      "journalName": "Comput. Electron. Agric.",
      "journalPages": "105748",
      "journalVolume": "178",
      "magId": "3092383557",
      "number_of_authors": 4,
      "paperId": "d28f8ba640a7d70ef195077008f110b788cac43d",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2020-11-01",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "A deep learning system for single and overall weight estimation of melons using unmanned aerial vehicle images",
      "tldr": "An algorithmic pipeline for detection and yield estimation of melons from top-view color images acquired by a digital camera mounted on an unmanned aerial vehicle, and overall yield estimation derived by summing the weights of all melons in the field resulted in only a 3% underestimation of the actual total yield.",
      "url": "https://www.semanticscholar.org/paper/d28f8ba640a7d70ef195077008f110b788cac43d",
      "venue": "Computers and Electronics in Agriculture",
      "year": 2020,
      "edges_count": 45,
      "local_references": [
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a598e30cce3902fafa5c2692e2ad68437339b383",
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946",
        "b95191e4672475b32d0a4c571bd2817659747dca",
        "c2eaffc617c57ab5106ba3bc95b7b910be473389",
        "d3eb6e57f618cf0830678594efd7e67eec76a898",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "d28f8ba640a7d70ef195077008f110b788cac43d",
      "pi_name": "I. Klapp"
    },
    {
      "abstract": null,
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2243198774"
          ],
          "name": "Yuhao Jin"
        },
        {
          "ids": [
            "2350454616"
          ],
          "name": "Xiaoyu Xia"
        },
        {
          "ids": [
            "2324225416"
          ],
          "name": "Qizhong Gao"
        },
        {
          "ids": [
            "2105583806"
          ],
          "name": "Yong Yue"
        },
        {
          "ids": [
            "2368752801"
          ],
          "name": "Eng Gee Lim"
        },
        {
          "ids": [
            "2284349150"
          ],
          "name": "Prudence Wong"
        },
        {
          "ids": [
            "2274164335"
          ],
          "name": "Weiping Ding"
        },
        {
          "ids": [
            "46875737"
          ],
          "name": "Xiaohui Zhu"
        }
      ],
      "corpusid": 276974595,
      "doi": "10.1016/j.asoc.2025.112971",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 276974595,
        "DBLP": "journals/asc/JinXGYLWDZ25",
        "DOI": "10.1016/j.asoc.2025.112971",
        "MAG": null,
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering",
        "Environmental Science"
      ],
      "id": "567196e86b6f4b9376d82f78f70f945402b406f4",
      "isOpenAccess": false,
      "journalName": "Appl. Soft Comput.",
      "journalPages": "112971",
      "journalVolume": "174",
      "magId": null,
      "number_of_authors": 8,
      "paperId": "567196e86b6f4b9376d82f78f70f945402b406f4",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2025-04-01",
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ],
      "title": "Deep learning in produce perception of harvesting robots: A comprehensive review",
      "tldr": null,
      "url": "https://www.semanticscholar.org/paper/567196e86b6f4b9376d82f78f70f945402b406f4",
      "venue": "Applied Soft Computing",
      "year": 2025,
      "edges_count": 36,
      "local_references": [
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a598e30cce3902fafa5c2692e2ad68437339b383",
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946",
        "b95191e4672475b32d0a4c571bd2817659747dca",
        "c2eaffc617c57ab5106ba3bc95b7b910be473389",
        "d3eb6e57f618cf0830678594efd7e67eec76a898",
        "eaa7b6893790279292e9f2fafe48662af8b6ae3d"
      ],
      "paper_id": "567196e86b6f4b9376d82f78f70f945402b406f4",
      "pi_name": "Xiaohui Zhu"
    },
    {
      "abstract": "As one of the representative algorithms of deep learning, a convolutional neural network (CNN) with the advantage of local perception and parameter sharing has been rapidly developed. CNN-based detection technology has been widely used in computer vision, natural language processing, and other fields. Fresh fruit production is an important socioeconomic activity, where CNN-based deep learning detection technology has been successfully applied to its important links. To the best of our knowledge, this review is the first on the whole production process of fresh fruit. We first introduced the network architecture and implementation principle of CNN and described the training process of a CNN-based deep learning model in detail. A large number of articles were investigated, which have made breakthroughs in response to challenges using CNN-based deep learning detection technology in important links of fresh fruit production including fruit flower detection, fruit detection, fruit harvesting, and fruit grading. Object detection based on CNN deep learning was elaborated from data acquisition to model training, and different detection methods based on CNN deep learning were compared in each link of the fresh fruit production. The investigation results of this review show that improved CNN deep learning models can give full play to detection potential by combining with the characteristics of each link of fruit production. The investigation results also imply that CNN-based detection may penetrate the challenges created by environmental issues, new area exploration, and multiple task execution of fresh fruit production in the future.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "47075029"
          ],
          "name": "Chenglin Wang"
        },
        {
          "ids": [
            "2165365507"
          ],
          "name": "Suchun Liu"
        },
        {
          "ids": [
            "2162615905"
          ],
          "name": "Yawei Wang"
        },
        {
          "ids": [
            "2072937642"
          ],
          "name": "Juntao Xiong"
        },
        {
          "ids": [
            "2156121682"
          ],
          "name": "Zhaoguo Zhang"
        },
        {
          "ids": [
            "2143737320"
          ],
          "name": "Bo Zhao"
        },
        {
          "ids": [
            "2198612"
          ],
          "name": "Lufeng Luo"
        },
        {
          "ids": [
            "2243173"
          ],
          "name": "Guichao Lin"
        },
        {
          "ids": [
            "2088425243"
          ],
          "name": "Peng He"
        }
      ],
      "corpusid": 248800512,
      "doi": "10.3389/fpls.2022.868745",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 248800512,
        "DBLP": null,
        "DOI": "10.3389/fpls.2022.868745",
        "MAG": null,
        "PubMed": "35651761",
        "PubMedCentral": "9149381"
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Medicine"
      ],
      "id": "7bbd671805ab6a50d288aaaf5d657d04ebcc9fb2",
      "isOpenAccess": true,
      "journalName": "Frontiers in Plant Science",
      "journalPages": null,
      "journalVolume": "13",
      "magId": null,
      "number_of_authors": 9,
      "paperId": "7bbd671805ab6a50d288aaaf5d657d04ebcc9fb2",
      "pdfUrls": [
        "https://www.frontiersin.org/articles/10.3389/fpls.2022.868745/pdf"
      ],
      "pmid": "35651761",
      "publicationDate": "2022-05-16",
      "publicationTypes": [
        "Review",
        "JournalArticle"
      ],
      "title": "Application of Convolutional Neural Network-Based Detection Methods in Fresh Fruit Production: A Comprehensive Review",
      "tldr": "Improved CNN deep learning models can give full play to detection potential by combining with the characteristics of each link of fruit production, and imply that CNN-based detection may penetrate the challenges created by environmental issues, new area exploration, and multiple task execution of fresh fruit production in the future.",
      "url": "https://www.semanticscholar.org/paper/7bbd671805ab6a50d288aaaf5d657d04ebcc9fb2",
      "venue": "Frontiers in Plant Science",
      "year": 2022,
      "edges_count": 36,
      "local_references": [
        "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
        "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946",
        "b95191e4672475b32d0a4c571bd2817659747dca",
        "ca7871a6571158cad8d8fcd114c115c39c372ac6",
        "d3eb6e57f618cf0830678594efd7e67eec76a898",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "7bbd671805ab6a50d288aaaf5d657d04ebcc9fb2",
      "pi_name": "Peng He"
    },
    {
      "abstract": "Smart farming employs intelligent systems for every domain of agriculture to obtain sustainable economic growth with the available resources using advanced technologies. Deep Learning (DL) is a sophisticated artificial neural network architecture that provides state-of-the-art results in smart farming applications. One of the main tasks in this domain is yield estimation. Manual yield estimation undergoes many hurdles such as labor-intensive, time-consuming, imprecise results, etc. These issues motivate the development of an intelligent fruit yield estimation system that offers more benefits to the farmers in deciding harvesting, marketing, etc. Semantic segmentation combined with DL adds promising results in fruit detection and localization by performing pixel-based prediction. This paper reviews the different literature employing various techniques for fruit yield estimation using DL-based semantic segmentation architectures. It also discusses the challenging issues that occur during intelligent fruit yield estimation such as sampling, collection, annotation and data augmentation, fruit detection, and counting. Results show that the fruit yield estimation employing DL-based semantic segmentation techniques yields better performance than earlier techniques because of human cognition incorporated into the architecture. Future directions like customization of DL architecture for smart-phone applications to predict the yield, development of more comprehensive model encompassing challenging situations like occlusion, overlapping and illumination variation, etc., were also discussed.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2140887065"
          ],
          "name": "P. Maheswari"
        },
        {
          "ids": [
            "1404549959"
          ],
          "name": "P. Raja"
        },
        {
          "ids": [
            "1450687271"
          ],
          "name": "O. E. Apolo-Apolo"
        },
        {
          "ids": [
            "1399282204"
          ],
          "name": "M. P\u00e9rez-Ruiz"
        }
      ],
      "corpusid": 235629138,
      "doi": "10.3389/fpls.2021.684328",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 235629138,
        "DBLP": null,
        "DOI": "10.3389/fpls.2021.684328",
        "MAG": null,
        "PubMed": "34249054",
        "PubMedCentral": "8267528"
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Medicine"
      ],
      "id": "5730c38bc7e585cd96080722af701979a6623497",
      "isOpenAccess": true,
      "journalName": "Frontiers in Plant Science",
      "journalPages": null,
      "journalVolume": "12",
      "magId": null,
      "number_of_authors": 4,
      "paperId": "5730c38bc7e585cd96080722af701979a6623497",
      "pdfUrls": [
        "https://www.frontiersin.org/articles/10.3389/fpls.2021.684328/pdf"
      ],
      "pmid": "34249054",
      "publicationDate": "2021-06-25",
      "publicationTypes": [
        "Review",
        "JournalArticle"
      ],
      "title": "Intelligent Fruit Yield Estimation for Orchards Using Deep Learning Based Semantic Segmentation Techniques\u2014A Review",
      "tldr": "Results show that the fruit yield estimation employing DL-based semantic segmentation techniques yields better performance than earlier techniques because of human cognition incorporated into the architecture.",
      "url": "https://www.semanticscholar.org/paper/5730c38bc7e585cd96080722af701979a6623497",
      "venue": "Frontiers in Plant Science",
      "year": 2021,
      "edges_count": 36,
      "local_references": [
        "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
        "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
        "a598e30cce3902fafa5c2692e2ad68437339b383",
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b95191e4672475b32d0a4c571bd2817659747dca",
        "c2eaffc617c57ab5106ba3bc95b7b910be473389",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "5730c38bc7e585cd96080722af701979a6623497",
      "pi_name": "M. P\u00e9rez-Ruiz"
    },
    {
      "abstract": "Deep Learning (DL) is the state-of-the-art machine learning technology, which shows superior performance in computer vision, bioinformatics, natural language processing, and other areas. Especially as a modern image processing technology, DL has been successfully applied in various tasks, such as object detection, semantic segmentation, and scene analysis. However, with the increase of dense scenes in reality, due to severe occlusions, and small size of objects, the analysis of dense scenes becomes particularly challenging. To overcome these problems, DL recently has been increasingly applied to dense scenes and has begun to be used in dense agricultural scenes. The purpose of this review is to explore the applications of DL for dense scenes analysis in agriculture. In order to better elaborate the topic, we first describe the types of dense scenes in agriculture, as well as the challenges. Next, we introduce various popular deep neural networks used in these dense scenes. Then, the applications of these structures in various agricultural tasks are comprehensively introduced in this review, including recognition and classification, detection, counting and yield estimation. Finally, the surveyed DL applications, limitations and the future work for analysis of dense images in agriculture are summarized.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2145946746"
          ],
          "name": "Qian Zhang"
        },
        {
          "ids": [
            "10841021"
          ],
          "name": "Yeqi Liu"
        },
        {
          "ids": [
            "51436039"
          ],
          "name": "Chuanyang Gong"
        },
        {
          "ids": [
            "78941940"
          ],
          "name": "Yingyi Chen"
        },
        {
          "ids": [
            "46493350"
          ],
          "name": "Huihui Yu"
        }
      ],
      "corpusid": 212693734,
      "doi": "10.3390/s20051520",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 212693734,
        "DBLP": "journals/sensors/ZhangLGCY20",
        "DOI": "10.3390/s20051520",
        "MAG": "3011886372",
        "PubMed": "32164200",
        "PubMedCentral": "7085505"
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Medicine"
      ],
      "id": "ac0d024d53c1e6252229217c79fcd3b1f5d91caf",
      "isOpenAccess": true,
      "journalName": "Sensors (Basel, Switzerland)",
      "journalPages": null,
      "journalVolume": "20",
      "magId": "3011886372",
      "number_of_authors": 5,
      "paperId": "ac0d024d53c1e6252229217c79fcd3b1f5d91caf",
      "pdfUrls": [
        "https://www.mdpi.com/1424-8220/20/5/1520/pdf"
      ],
      "pmid": "32164200",
      "publicationDate": "2020-03-01",
      "publicationTypes": [
        "Review",
        "JournalArticle"
      ],
      "title": "Applications of Deep Learning for Dense Scenes Analysis in Agriculture: A Review",
      "tldr": "The applications of DL for dense scenes analysis in agriculture are explored, including recognition and classification, detection, counting and yield estimation, and various popular deep neural networks used in these dense scenes.",
      "url": "https://www.semanticscholar.org/paper/ac0d024d53c1e6252229217c79fcd3b1f5d91caf",
      "venue": "Italian National Conference on Sensors",
      "year": 2020,
      "edges_count": 36,
      "local_references": [
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
        "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b95191e4672475b32d0a4c571bd2817659747dca",
        "c2eaffc617c57ab5106ba3bc95b7b910be473389",
        "d3eb6e57f618cf0830678594efd7e67eec76a898",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "ac0d024d53c1e6252229217c79fcd3b1f5d91caf",
      "pi_name": "Huihui Yu"
    },
    {
      "abstract": "In this paper, applicability of YOLOv7 neural network model for the detection of very small objects is examined. The selected application example is the detection of olive fruits in images, which can have several practical uses, especially if it involves agricultural, food, or environmental applications. Automated detection could facilitate a better understanding and management of olive production, which could result in increased efficiency and improved product quality. Acquired images of olive trees were annotated and preprocessed. Two annotation approaches were used (two class approach and single class approach). After model training detection results were analyzed based on the size of the detected olives bounding box. Even though the training dataset was relatively small, the precision, recall, and F1 measure achieved in our study exhibit a remarkable similarity to the results reported in the existing literature. This noteworthy similarity underscores the effectiveness of the presented approach, despite the inherent challenge posed by the limited size of the training dataset. Therefore, the presented approach offers valuable insights and show its potential for practical solutions aimed at enhancing olive farming practices.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2004596722"
          ],
          "name": "Mirela Kundid Vasi\u0107"
        },
        {
          "ids": [
            "88329712"
          ],
          "name": "J. Gugic"
        },
        {
          "ids": [
            "2257044477"
          ],
          "name": "Vladan Papi\u0107"
        }
      ],
      "corpusid": 263838481,
      "doi": "10.23919/SoftCOM58365.2023.10271639",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 263838481,
        "DBLP": "conf/softcom/VasicGP23",
        "DOI": "10.23919/SoftCOM58365.2023.10271639",
        "MAG": null,
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Environmental Science"
      ],
      "id": "dec92fe2fea3aa9149abea3b8a38b2749ab203c7",
      "isOpenAccess": false,
      "journalName": "2023 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)",
      "journalPages": "1-6",
      "journalVolume": null,
      "magId": null,
      "number_of_authors": 3,
      "paperId": "dec92fe2fea3aa9149abea3b8a38b2749ab203c7",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2023-09-21",
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ],
      "title": "Detection of Small Fruits in Natural Environment Images",
      "tldr": null,
      "url": "https://www.semanticscholar.org/paper/dec92fe2fea3aa9149abea3b8a38b2749ab203c7",
      "venue": "International Conference on Software, Telecommunications and Computer Networks",
      "year": 2023,
      "edges_count": 28,
      "local_references": [
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a598e30cce3902fafa5c2692e2ad68437339b383",
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946",
        "c2eaffc617c57ab5106ba3bc95b7b910be473389",
        "d3eb6e57f618cf0830678594efd7e67eec76a898"
      ],
      "paper_id": "dec92fe2fea3aa9149abea3b8a38b2749ab203c7",
      "pi_name": "Vladan Papi\u0107"
    },
    {
      "abstract": null,
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2244657623"
          ],
          "name": "J. C. Miranda"
        },
        {
          "ids": [
            "1404331013"
          ],
          "name": "Jordi Gen\u00e9-Mola"
        },
        {
          "ids": [
            "1412953902"
          ],
          "name": "M. Zude-Sasse"
        },
        {
          "ids": [
            "115025084"
          ],
          "name": "Nikos Tsoulias"
        },
        {
          "ids": [
            "3238367"
          ],
          "name": "A. Escol\u00e0"
        },
        {
          "ids": [
            "34843989"
          ],
          "name": "J. Arn\u00f3"
        },
        {
          "ids": [
            "1382531391"
          ],
          "name": "J. R. Rosell-Polo"
        },
        {
          "ids": [
            "1405005477"
          ],
          "name": "Ricardo Sanz-Cortiella"
        },
        {
          "ids": [
            "1403283844"
          ],
          "name": "J. A. Martinez-Casasnovas"
        },
        {
          "ids": [
            "26679688"
          ],
          "name": "E. Gregorio"
        }
      ],
      "corpusid": 262221407,
      "doi": "10.1016/j.postharvbio.2023.112587",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 262221407,
        "DBLP": null,
        "DOI": "10.1016/j.postharvbio.2023.112587",
        "MAG": null,
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Biology",
        "Computer Science"
      ],
      "id": "26bebd48141120f1ea916f40b45c08ef81128c24",
      "isOpenAccess": true,
      "journalName": "Postharvest Biology and Technology",
      "journalPages": null,
      "journalVolume": null,
      "magId": null,
      "number_of_authors": 10,
      "paperId": "26bebd48141120f1ea916f40b45c08ef81128c24",
      "pdfUrls": [
        "https://doi.org/10.1016/j.postharvbio.2023.112587"
      ],
      "pmid": "",
      "publicationDate": "2023-12-01",
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ],
      "title": "Fruit sizing using AI: A review of methods and challenges",
      "tldr": null,
      "url": "https://www.semanticscholar.org/paper/26bebd48141120f1ea916f40b45c08ef81128c24",
      "venue": "Postharvest Biology and Technology",
      "year": 2023,
      "edges_count": 28,
      "local_references": [
        "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a598e30cce3902fafa5c2692e2ad68437339b383",
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946",
        "b95191e4672475b32d0a4c571bd2817659747dca",
        "c2eaffc617c57ab5106ba3bc95b7b910be473389",
        "d3eb6e57f618cf0830678594efd7e67eec76a898"
      ],
      "paper_id": "26bebd48141120f1ea916f40b45c08ef81128c24",
      "pi_name": "E. Gregorio"
    },
    {
      "abstract": "S2 TL;DR: This review aims to explore methods for improving fruit detection in complex environments and divides the improvement measures into two categories: optimization before and after image sampling and the future development trends of fruit detection optimization technology in complex backgrounds.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "8651546"
          ],
          "name": "Yunchao Tang"
        },
        {
          "ids": [
            "2154972600"
          ],
          "name": "Jiajun Qiu"
        },
        {
          "ids": [
            "2136582773"
          ],
          "name": "Yunqi Zhang"
        },
        {
          "ids": [
            "3041344"
          ],
          "name": "Dongxiao Wu"
        },
        {
          "ids": [
            "2212216397"
          ],
          "name": "Yuhong Cao"
        },
        {
          "ids": [
            "2212411431"
          ],
          "name": "Kexin Zhao"
        },
        {
          "ids": [
            "2280045248"
          ],
          "name": "Lixue Zhu"
        }
      ],
      "corpusid": 257735615,
      "doi": "10.1007/s11119-023-10009-9",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 257735615,
        "DBLP": null,
        "DOI": "10.1007/s11119-023-10009-9",
        "MAG": null,
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science"
      ],
      "id": "01cf85086dd0a5cc4be842a22d8e5390376f84c2",
      "isOpenAccess": false,
      "journalName": "Precision Agriculture",
      "journalPages": "1183-1219",
      "journalVolume": "24",
      "magId": null,
      "number_of_authors": 7,
      "paperId": "01cf85086dd0a5cc4be842a22d8e5390376f84c2",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2023-03-23",
      "publicationTypes": [
        "Review"
      ],
      "title": "Optimization strategies of fruit detection to overcome the challenge of unstructured background in field orchard environment: a review",
      "tldr": "This review aims to explore methods for improving fruit detection in complex environments and divides the improvement measures into two categories: optimization before and after image sampling and the future development trends of fruit detection optimization technology in complex backgrounds.",
      "url": "https://www.semanticscholar.org/paper/01cf85086dd0a5cc4be842a22d8e5390376f84c2",
      "venue": "Precision Agriculture",
      "year": 2023,
      "edges_count": 28,
      "local_references": [
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
        "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946",
        "c2eaffc617c57ab5106ba3bc95b7b910be473389",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "01cf85086dd0a5cc4be842a22d8e5390376f84c2",
      "pi_name": "Lixue Zhu"
    },
    {
      "abstract": "In the evolution of agriculture to its next stage, Agriculture 5.0, artificial intelligence will play a central role. Controlled-environment agriculture, or CEA, is a special form of urban and suburban agricultural practice that offers numerous economic, environmental, and social benefits, including shorter transportation routes to population centers, reduced environmental impact, and increased productivity. Due to its ability to control environmental factors, CEA couples well with computer vision (CV) in the adoption of real-time monitoring of the plant conditions and autonomous cultivation and harvesting. The objective of this article is to familiarize CV researchers with agricultural applications and agricultural practitioners with the solutions offered by CV. We identify five major CV applications in CEA, analyze their requirements and motivation, and survey the state-of-the-art as reflected in 68 technical papers using deep learning methods. In addition, we discuss five key subareas of computer vision and how they related to these CEA problems, as well as 14 vision-based CEA datasets. We hope the survey will help researchers quickly gain a bird\u2019s-eye view of the striving research area and will spark inspiration for new research and development.",
      "arxivId": "2210.11318",
      "authors": [
        {
          "ids": [
            "152365014"
          ],
          "name": "Jiayun Luo"
        },
        {
          "ids": [
            "1728712"
          ],
          "name": "Boyang Albert Li"
        },
        {
          "ids": [
            "2188346915"
          ],
          "name": "Cyril Leung"
        }
      ],
      "corpusid": 253018670,
      "doi": "10.1145/3626186",
      "externalIds": {
        "ACL": null,
        "ArXiv": "2210.11318",
        "CorpusId": 253018670,
        "DBLP": "journals/csur/LuoLL24",
        "DOI": "10.1145/3626186",
        "MAG": null,
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering",
        "Environmental Science"
      ],
      "id": "d63eb5bcca2301554da2114533d98fbfa4b955be",
      "isOpenAccess": true,
      "journalName": "ACM Computing Surveys",
      "journalPages": "1 - 39",
      "journalVolume": "56",
      "magId": null,
      "number_of_authors": 3,
      "paperId": "d63eb5bcca2301554da2114533d98fbfa4b955be",
      "pdfUrls": [
        "https://dl.acm.org/doi/pdf/10.1145/3626186"
      ],
      "pmid": "",
      "publicationDate": "2022-10-20",
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ],
      "title": "A Survey of Computer Vision Technologies in Urban and Controlled-environment Agriculture",
      "tldr": "Five major CV applications in CEA are identified, their requirements and motivation are analyzed, and the state-of-the-art as reflected in 68 technical papers using deep learning methods is surveyed.",
      "url": "https://www.semanticscholar.org/paper/d63eb5bcca2301554da2114533d98fbfa4b955be",
      "venue": "ACM Computing Surveys",
      "year": 2022,
      "edges_count": 28,
      "local_references": [
        "1c8c77afa31d57c45cfbf404231217dc4db17a14",
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a598e30cce3902fafa5c2692e2ad68437339b383",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946",
        "b95191e4672475b32d0a4c571bd2817659747dca",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "d63eb5bcca2301554da2114533d98fbfa4b955be",
      "pi_name": "Cyril Leung"
    }
  ],
  "common_references": [
    {
      "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available",
      "arxivId": "1506.01497",
      "authors": [
        {
          "ids": [
            "3080683"
          ],
          "name": "Shaoqing Ren"
        },
        {
          "ids": [
            "39353098"
          ],
          "name": "Kaiming He"
        },
        {
          "ids": [
            "2983898"
          ],
          "name": "Ross B. Girshick"
        },
        {
          "ids": [
            "2032184078"
          ],
          "name": "Jian Sun"
        }
      ],
      "corpusid": 10328909,
      "doi": "10.1109/TPAMI.2016.2577031",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1506.01497",
        "CorpusId": 10328909,
        "DBLP": "journals/pami/RenHG017",
        "DOI": "10.1109/TPAMI.2016.2577031",
        "MAG": "2953106684",
        "PubMed": "27295650",
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Medicine"
      ],
      "id": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
      "isOpenAccess": true,
      "journalName": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "journalPages": "1137-1149",
      "journalVolume": "39",
      "magId": "2953106684",
      "number_of_authors": 4,
      "paperId": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
      "pdfUrls": [
        "https://arxiv.org/pdf/1506.01497"
      ],
      "pmid": "27295650",
      "publicationDate": "2015-06-04",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
      "tldr": "This work introduces a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals and further merge RPN and Fast R-CNN into a single network by sharing their convolutionAL features.",
      "url": "https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "year": 2015,
      "edges_count": 561,
      "local_citations": [
        "0d44970499a233c3be99995f615a91980becf3d4",
        "1c8c77afa31d57c45cfbf404231217dc4db17a14",
        "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
        "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
        "2b16d04ae11a903c079946c83ea2b5d517cce970",
        "365b31515028f2c7444d5b5afd865d242b229bd2",
        "371400e61632592146f40b621fb3dbb6971721be",
        "3bb4c3127c77ffb06a81cfe09862716a0828114c",
        "4328ec9d98eff5d7eb70997f76d81b27849f3220",
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
        "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
        "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
        "663a60841c3e703d7c18cf78f0657efee6aebb9d",
        "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
        "738fa51e1a0f5c652019ab7165841ca4d399ce59",
        "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
        "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
        "8352826ff8f12ded684bf07540341a5ef6da06fd",
        "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
        "938ed8b290dcc01acfacf3533477e404f1d19c23",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a08767952d56b006deecb75488a6c5ce5c8aa16d",
        "a598e30cce3902fafa5c2692e2ad68437339b383",
        "b6946370d6c13d562b96e42d494817c7d1969a8f",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946",
        "b724c3f7ff395235b62537203ddeb710f0eb27bb",
        "b95191e4672475b32d0a4c571bd2817659747dca",
        "be1fb04cf17e259933ce33f0015cf54132f266be",
        "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
        "ca7871a6571158cad8d8fcd114c115c39c372ac6",
        "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
        "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
      "pi_name": "Jian Sun"
    },
    {
      "abstract": "S2 TL;DR: This paper introduces selective search which combines the strength of both an exhaustive search and segmentation, and shows that its selective search enables the use of the powerful Bag-of-Words model for recognition.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2242508491"
          ],
          "name": "Jasper R. R. Uijlings"
        },
        {
          "ids": [
            "1756979"
          ],
          "name": "K. V. D. Sande"
        },
        {
          "ids": [
            "2257152645"
          ],
          "name": "Theo Gevers"
        },
        {
          "ids": [
            "144638781"
          ],
          "name": "A. Smeulders"
        }
      ],
      "corpusid": 216077384,
      "doi": "10.1007/s11263-013-0620-5",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 216077384,
        "DBLP": "journals/ijcv/UijlingsSGS13",
        "DOI": "10.1007/s11263-013-0620-5",
        "MAG": "2088049833",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "9b223c8a31e0ea1d1f2c9787ffd8416dfc90c912",
      "isOpenAccess": false,
      "journalName": "International Journal of Computer Vision",
      "journalPages": "154 - 171",
      "journalVolume": "104",
      "magId": "2088049833",
      "number_of_authors": 4,
      "paperId": "9b223c8a31e0ea1d1f2c9787ffd8416dfc90c912",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2013-04-02",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Selective Search for Object Recognition",
      "tldr": "This paper introduces selective search which combines the strength of both an exhaustive search and segmentation, and shows that its selective search enables the use of the powerful Bag-of-Words model for recognition.",
      "url": "https://www.semanticscholar.org/paper/9b223c8a31e0ea1d1f2c9787ffd8416dfc90c912",
      "venue": "International Journal of Computer Vision",
      "year": 2013,
      "edges_count": 351,
      "local_citations": [
        "0d44970499a233c3be99995f615a91980becf3d4",
        "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
        "2b16d04ae11a903c079946c83ea2b5d517cce970",
        "365b31515028f2c7444d5b5afd865d242b229bd2",
        "371400e61632592146f40b621fb3dbb6971721be",
        "3bb4c3127c77ffb06a81cfe09862716a0828114c",
        "4328ec9d98eff5d7eb70997f76d81b27849f3220",
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
        "663a60841c3e703d7c18cf78f0657efee6aebb9d",
        "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
        "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
        "8352826ff8f12ded684bf07540341a5ef6da06fd",
        "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
        "938ed8b290dcc01acfacf3533477e404f1d19c23",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a08767952d56b006deecb75488a6c5ce5c8aa16d",
        "a598e30cce3902fafa5c2692e2ad68437339b383",
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b6946370d6c13d562b96e42d494817c7d1969a8f",
        "b724c3f7ff395235b62537203ddeb710f0eb27bb",
        "be1fb04cf17e259933ce33f0015cf54132f266be",
        "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
        "ca7871a6571158cad8d8fcd114c115c39c372ac6",
        "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
        "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "9b223c8a31e0ea1d1f2c9787ffd8416dfc90c912",
      "pi_name": "A. Smeulders"
    },
    {
      "abstract": "S2 TL;DR: A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2064160"
          ],
          "name": "A. Krizhevsky"
        },
        {
          "ids": [
            "1701686"
          ],
          "name": "I. Sutskever"
        },
        {
          "ids": [
            "1695689"
          ],
          "name": "Geoffrey E. Hinton"
        }
      ],
      "corpusid": 195908774,
      "doi": "10.1145/3065386",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 195908774,
        "DBLP": "conf/nips/KrizhevskySH12",
        "DOI": "10.1145/3065386",
        "MAG": "2618530766",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
      "isOpenAccess": true,
      "journalName": "Communications of the ACM",
      "journalPages": "84 - 90",
      "journalVolume": "60",
      "magId": "2618530766",
      "number_of_authors": 3,
      "paperId": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
      "pdfUrls": [
        "http://dl.acm.org/ft_gateway.cfm?id=3065386&type=pdf"
      ],
      "pmid": "",
      "publicationDate": "2012-12-03",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "ImageNet classification with deep convolutional neural networks",
      "tldr": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective.",
      "url": "https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff",
      "venue": "Communications of the ACM",
      "year": 2012,
      "edges_count": 351,
      "local_citations": [
        "0d44970499a233c3be99995f615a91980becf3d4",
        "2b16d04ae11a903c079946c83ea2b5d517cce970",
        "365b31515028f2c7444d5b5afd865d242b229bd2",
        "371400e61632592146f40b621fb3dbb6971721be",
        "3bb4c3127c77ffb06a81cfe09862716a0828114c",
        "4328ec9d98eff5d7eb70997f76d81b27849f3220",
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
        "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
        "663a60841c3e703d7c18cf78f0657efee6aebb9d",
        "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
        "738fa51e1a0f5c652019ab7165841ca4d399ce59",
        "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
        "8352826ff8f12ded684bf07540341a5ef6da06fd",
        "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
        "938ed8b290dcc01acfacf3533477e404f1d19c23",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a08767952d56b006deecb75488a6c5ce5c8aa16d",
        "a598e30cce3902fafa5c2692e2ad68437339b383",
        "b6946370d6c13d562b96e42d494817c7d1969a8f",
        "b724c3f7ff395235b62537203ddeb710f0eb27bb",
        "b95191e4672475b32d0a4c571bd2817659747dca",
        "be1fb04cf17e259933ce33f0015cf54132f266be",
        "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
        "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
        "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
        "f4a2732d4051b9c4b5d1f057aaa7935be390f51e"
      ],
      "paper_id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
      "pi_name": "Geoffrey E. Hinton"
    },
    {
      "abstract": "This paper proposes Fast R-CNN, a clean and fast framework for object detection. Compared to traditional R-CNN, and its accelerated version SPPnet, Fast R-CNN trains networks using a multi-task loss in a single training stage. The multi-task loss simplifies learning and improves detection accuracy. Unlike SPPnet, all network layers can be updated during fine-tuning. We show that this difference has practical ramifications for very deep networks, such as VGG16, where mAP suffers when only the fully-connected layers are updated. Compared to\"slow\"R-CNN, Fast R-CNN is 9x faster at training VGG16 for detection, 213x faster at test-time, and achieves a significantly higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn",
      "arxivId": "1504.08083",
      "authors": [
        {
          "ids": [
            "2983898"
          ],
          "name": "Ross B. Girshick"
        }
      ],
      "corpusid": 206770307,
      "doi": "",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1504.08083",
        "CorpusId": 206770307,
        "DBLP": null,
        "DOI": null,
        "MAG": null,
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "7ffdbc358b63378f07311e883dddacc9faeeaf4b",
      "isOpenAccess": false,
      "journalName": null,
      "journalPages": null,
      "journalVolume": null,
      "magId": null,
      "number_of_authors": 1,
      "paperId": "7ffdbc358b63378f07311e883dddacc9faeeaf4b",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2015-04-29",
      "publicationTypes": null,
      "title": "Fast R-CNN",
      "tldr": "This paper proposes Fast R-CNN, a clean and fast framework for object detection that trains networks using a multi-task loss in a single training stage and achieves a significantly higher mAP on PASCAL VOC 2012.",
      "url": "https://www.semanticscholar.org/paper/7ffdbc358b63378f07311e883dddacc9faeeaf4b",
      "venue": "",
      "year": 2015,
      "edges_count": 300,
      "local_citations": [
        "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
        "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
        "2b16d04ae11a903c079946c83ea2b5d517cce970",
        "365b31515028f2c7444d5b5afd865d242b229bd2",
        "371400e61632592146f40b621fb3dbb6971721be",
        "3bb4c3127c77ffb06a81cfe09862716a0828114c",
        "4328ec9d98eff5d7eb70997f76d81b27849f3220",
        "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
        "738fa51e1a0f5c652019ab7165841ca4d399ce59",
        "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
        "8352826ff8f12ded684bf07540341a5ef6da06fd",
        "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
        "938ed8b290dcc01acfacf3533477e404f1d19c23",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a08767952d56b006deecb75488a6c5ce5c8aa16d",
        "b6946370d6c13d562b96e42d494817c7d1969a8f",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946",
        "b724c3f7ff395235b62537203ddeb710f0eb27bb",
        "be1fb04cf17e259933ce33f0015cf54132f266be",
        "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
        "ca7871a6571158cad8d8fcd114c115c39c372ac6",
        "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
        "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
        "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "7ffdbc358b63378f07311e883dddacc9faeeaf4b",
      "pi_name": "Ross B. Girshick"
    },
    {
      "abstract": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.",
      "arxivId": "1311.2524",
      "authors": [
        {
          "ids": [
            "2983898"
          ],
          "name": "Ross B. Girshick"
        },
        {
          "ids": [
            "7408951"
          ],
          "name": "Jeff Donahue"
        },
        {
          "ids": [
            "1753210"
          ],
          "name": "Trevor Darrell"
        },
        {
          "ids": [
            "153652147"
          ],
          "name": "J. Malik"
        }
      ],
      "corpusid": 215827080,
      "doi": "10.1109/CVPR.2014.81",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1311.2524",
        "CorpusId": 215827080,
        "DBLP": "journals/corr/GirshickDDM13",
        "DOI": "10.1109/CVPR.2014.81",
        "MAG": "2951638509",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "2f4df08d9072fc2ac181b7fced6a245315ce05c8",
      "isOpenAccess": true,
      "journalName": "2014 IEEE Conference on Computer Vision and Pattern Recognition",
      "journalPages": "580-587",
      "journalVolume": null,
      "magId": "2951638509",
      "number_of_authors": 4,
      "paperId": "2f4df08d9072fc2ac181b7fced6a245315ce05c8",
      "pdfUrls": [
        "http://arxiv.org/pdf/1311.2524"
      ],
      "pmid": "",
      "publicationDate": "2013-11-11",
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ],
      "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation",
      "tldr": "This paper proposes a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%.",
      "url": "https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8",
      "venue": "2014 IEEE Conference on Computer Vision and Pattern Recognition",
      "year": 2013,
      "edges_count": 231,
      "local_citations": [
        "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
        "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
        "2b16d04ae11a903c079946c83ea2b5d517cce970",
        "365b31515028f2c7444d5b5afd865d242b229bd2",
        "371400e61632592146f40b621fb3dbb6971721be",
        "3bb4c3127c77ffb06a81cfe09862716a0828114c",
        "4328ec9d98eff5d7eb70997f76d81b27849f3220",
        "663a60841c3e703d7c18cf78f0657efee6aebb9d",
        "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
        "738fa51e1a0f5c652019ab7165841ca4d399ce59",
        "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
        "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
        "938ed8b290dcc01acfacf3533477e404f1d19c23",
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b6946370d6c13d562b96e42d494817c7d1969a8f",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946",
        "b724c3f7ff395235b62537203ddeb710f0eb27bb",
        "be1fb04cf17e259933ce33f0015cf54132f266be",
        "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
        "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
        "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "2f4df08d9072fc2ac181b7fced6a245315ce05c8",
      "pi_name": "J. Malik"
    },
    {
      "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.",
      "arxivId": "1409.1556",
      "authors": [
        {
          "ids": [
            "34838386"
          ],
          "name": "K. Simonyan"
        },
        {
          "ids": [
            "1688869"
          ],
          "name": "Andrew Zisserman"
        }
      ],
      "corpusid": 14124313,
      "doi": "",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1409.1556",
        "CorpusId": 14124313,
        "DBLP": "journals/corr/SimonyanZ14a",
        "DOI": null,
        "MAG": "2949429431",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "id": "eb42cf88027de515750f230b23b1a057dc782108",
      "isOpenAccess": false,
      "journalName": "CoRR",
      "journalPages": null,
      "journalVolume": "abs/1409.1556",
      "magId": "2949429431",
      "number_of_authors": 2,
      "paperId": "eb42cf88027de515750f230b23b1a057dc782108",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2014-09-04",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
      "tldr": "This work investigates the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting using an architecture with very small convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers.",
      "url": "https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108",
      "venue": "International Conference on Learning Representations",
      "year": 2014,
      "edges_count": 231,
      "local_citations": [
        "1c8c77afa31d57c45cfbf404231217dc4db17a14",
        "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
        "2b16d04ae11a903c079946c83ea2b5d517cce970",
        "365b31515028f2c7444d5b5afd865d242b229bd2",
        "371400e61632592146f40b621fb3dbb6971721be",
        "3bb4c3127c77ffb06a81cfe09862716a0828114c",
        "4328ec9d98eff5d7eb70997f76d81b27849f3220",
        "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
        "663a60841c3e703d7c18cf78f0657efee6aebb9d",
        "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
        "738fa51e1a0f5c652019ab7165841ca4d399ce59",
        "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
        "938ed8b290dcc01acfacf3533477e404f1d19c23",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "b6946370d6c13d562b96e42d494817c7d1969a8f",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946",
        "b724c3f7ff395235b62537203ddeb710f0eb27bb",
        "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
        "ca7871a6571158cad8d8fcd114c115c39c372ac6",
        "d3eb6e57f618cf0830678594efd7e67eec76a898",
        "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
        "f4a2732d4051b9c4b5d1f057aaa7935be390f51e"
      ],
      "paper_id": "eb42cf88027de515750f230b23b1a057dc782108",
      "pi_name": "Andrew Zisserman"
    },
    {
      "abstract": "S2 TL;DR: A novel method for generating object bounding box proposals using edges is proposed, showing results that are significantly more accurate than the current state-of-the-art while being faster to compute.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "1699161"
          ],
          "name": "C. L. Zitnick"
        },
        {
          "ids": [
            "3127283"
          ],
          "name": "Piotr Doll\u00e1r"
        }
      ],
      "corpusid": 5984060,
      "doi": "10.1007/978-3-319-10602-1_26",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 5984060,
        "DBLP": "conf/eccv/ZitnickD14",
        "DOI": "10.1007/978-3-319-10602-1_26",
        "MAG": "7746136",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "id": "b183947ee15718b45546eda6b01e179b9a95421f",
      "isOpenAccess": true,
      "journalName": null,
      "journalPages": "391-405",
      "journalVolume": null,
      "magId": "7746136",
      "number_of_authors": 2,
      "paperId": "b183947ee15718b45546eda6b01e179b9a95421f",
      "pdfUrls": [
        "https://link.springer.com/content/pdf/10.1007/978-3-319-10602-1_26.pdf"
      ],
      "pmid": "",
      "publicationDate": "2014-09-06",
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ],
      "title": "Edge Boxes: Locating Object Proposals from Edges",
      "tldr": "A novel method for generating object bounding box proposals using edges is proposed, showing results that are significantly more accurate than the current state-of-the-art while being faster to compute.",
      "url": "https://www.semanticscholar.org/paper/b183947ee15718b45546eda6b01e179b9a95421f",
      "venue": "European Conference on Computer Vision",
      "year": 2014,
      "edges_count": 231,
      "local_citations": [
        "0d44970499a233c3be99995f615a91980becf3d4",
        "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
        "2b16d04ae11a903c079946c83ea2b5d517cce970",
        "365b31515028f2c7444d5b5afd865d242b229bd2",
        "371400e61632592146f40b621fb3dbb6971721be",
        "3bb4c3127c77ffb06a81cfe09862716a0828114c",
        "4328ec9d98eff5d7eb70997f76d81b27849f3220",
        "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
        "663a60841c3e703d7c18cf78f0657efee6aebb9d",
        "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
        "8352826ff8f12ded684bf07540341a5ef6da06fd",
        "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a08767952d56b006deecb75488a6c5ce5c8aa16d",
        "a598e30cce3902fafa5c2692e2ad68437339b383",
        "b724c3f7ff395235b62537203ddeb710f0eb27bb",
        "be1fb04cf17e259933ce33f0015cf54132f266be",
        "ca7871a6571158cad8d8fcd114c115c39c372ac6",
        "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
        "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
        "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "b183947ee15718b45546eda6b01e179b9a95421f",
      "pi_name": "Piotr Doll\u00e1r"
    },
    {
      "abstract": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.",
      "arxivId": "1409.0575",
      "authors": [
        {
          "ids": [
            "2314850892"
          ],
          "name": "Olga Russakovsky"
        },
        {
          "ids": [
            "153302678"
          ],
          "name": "Jia Deng"
        },
        {
          "ids": [
            "144914140"
          ],
          "name": "Hao Su"
        },
        {
          "ids": [
            "2285165"
          ],
          "name": "J. Krause"
        },
        {
          "ids": [
            "145031342"
          ],
          "name": "S. Satheesh"
        },
        {
          "ids": [
            "2261887230"
          ],
          "name": "Sean Ma"
        },
        {
          "ids": [
            "3109481"
          ],
          "name": "Zhiheng Huang"
        },
        {
          "ids": [
            "2354728"
          ],
          "name": "A. Karpathy"
        },
        {
          "ids": [
            "2556428"
          ],
          "name": "A. Khosla"
        },
        {
          "ids": [
            "145879842"
          ],
          "name": "Michael S. Bernstein"
        },
        {
          "ids": [
            "39668247"
          ],
          "name": "A. Berg"
        },
        {
          "ids": [
            "48004138"
          ],
          "name": "Li Fei-Fei"
        }
      ],
      "corpusid": 2930547,
      "doi": "10.1007/s11263-015-0816-y",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1409.0575",
        "CorpusId": 2930547,
        "DBLP": "journals/corr/RussakovskyDSKSMHKKBBF14",
        "DOI": "10.1007/s11263-015-0816-y",
        "MAG": "2546241758",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd",
      "isOpenAccess": false,
      "journalName": "International Journal of Computer Vision",
      "journalPages": "211 - 252",
      "journalVolume": "115",
      "magId": "2546241758",
      "number_of_authors": 12,
      "paperId": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2014-09-01",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "ImageNet Large Scale Visual Recognition Challenge",
      "tldr": "The creation of this benchmark dataset and the advances in object recognition that have been possible as a result are described, and the state-of-the-art computer vision accuracy with human accuracy is compared.",
      "url": "https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd",
      "venue": "International Journal of Computer Vision",
      "year": 2014,
      "edges_count": 210,
      "local_citations": [
        "1c8c77afa31d57c45cfbf404231217dc4db17a14",
        "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
        "365b31515028f2c7444d5b5afd865d242b229bd2",
        "371400e61632592146f40b621fb3dbb6971721be",
        "3bb4c3127c77ffb06a81cfe09862716a0828114c",
        "4328ec9d98eff5d7eb70997f76d81b27849f3220",
        "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
        "663a60841c3e703d7c18cf78f0657efee6aebb9d",
        "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
        "738fa51e1a0f5c652019ab7165841ca4d399ce59",
        "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
        "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a08767952d56b006deecb75488a6c5ce5c8aa16d",
        "b6946370d6c13d562b96e42d494817c7d1969a8f",
        "b724c3f7ff395235b62537203ddeb710f0eb27bb",
        "be1fb04cf17e259933ce33f0015cf54132f266be",
        "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
        "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
        "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd",
      "pi_name": "Li Fei-Fei"
    },
    {
      "abstract": "Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224<inline-formula><tex-math>$\\times$ </tex-math><alternatives><inline-graphic xlink:type=\"simple\" xlink:href=\"he-ieq1-2389824.gif\"/></alternatives></inline-formula>224) input image. This requirement is \u201cartificial\u201d and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, \u201cspatial pyramid pooling\u201d, to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102 <inline-formula><tex-math>$\\times$</tex-math><alternatives><inline-graphic xlink:type=\"simple\" xlink:href=\"he-ieq2-2389824.gif\"/> </alternatives></inline-formula> faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank #2 in object detection and #3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.",
      "arxivId": "1406.4729",
      "authors": [
        {
          "ids": [
            "39353098"
          ],
          "name": "Kaiming He"
        },
        {
          "ids": [
            "1771551"
          ],
          "name": "X. Zhang"
        },
        {
          "ids": [
            "3080683"
          ],
          "name": "Shaoqing Ren"
        },
        {
          "ids": [
            null
          ],
          "name": "Jian Sun"
        }
      ],
      "corpusid": 436933,
      "doi": "10.1007/978-3-319-10578-9_23",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1406.4729",
        "CorpusId": 436933,
        "DBLP": "journals/pami/HeZR015",
        "DOI": "10.1007/978-3-319-10578-9_23",
        "MAG": "2179352600",
        "PubMed": "26353135",
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Medicine"
      ],
      "id": "cbb19236820a96038d000dc629225d36e0b6294a",
      "isOpenAccess": true,
      "journalName": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "journalPages": "1904-1916",
      "journalVolume": "37",
      "magId": "2179352600",
      "number_of_authors": 4,
      "paperId": "cbb19236820a96038d000dc629225d36e0b6294a",
      "pdfUrls": [
        "https://arxiv.org/pdf/1406.4729"
      ],
      "pmid": "26353135",
      "publicationDate": "2014-06-18",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition",
      "tldr": "This work equips the networks with another pooling strategy, \u201cspatial pyramid pooling\u201d, to eliminate the above requirement, and develops a new network structure, called SPP-net, which can generate a fixed-length representation regardless of image size/scale.",
      "url": "https://www.semanticscholar.org/paper/cbb19236820a96038d000dc629225d36e0b6294a",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "year": 2014,
      "edges_count": 210,
      "local_citations": [
        "0d44970499a233c3be99995f615a91980becf3d4",
        "365b31515028f2c7444d5b5afd865d242b229bd2",
        "371400e61632592146f40b621fb3dbb6971721be",
        "3bb4c3127c77ffb06a81cfe09862716a0828114c",
        "4328ec9d98eff5d7eb70997f76d81b27849f3220",
        "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
        "663a60841c3e703d7c18cf78f0657efee6aebb9d",
        "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
        "738fa51e1a0f5c652019ab7165841ca4d399ce59",
        "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
        "8352826ff8f12ded684bf07540341a5ef6da06fd",
        "938ed8b290dcc01acfacf3533477e404f1d19c23",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a08767952d56b006deecb75488a6c5ce5c8aa16d",
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b6946370d6c13d562b96e42d494817c7d1969a8f",
        "b724c3f7ff395235b62537203ddeb710f0eb27bb",
        "ca7871a6571158cad8d8fcd114c115c39c372ac6",
        "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
        "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "paper_id": "cbb19236820a96038d000dc629225d36e0b6294a",
      "pi_name": "Jian Sun"
    },
    {
      "abstract": "S2 TL;DR: A computer vision-based system for automated, rapid and accurate yield estimation that works well with both red and green apples in the tall-spindle planting system and is time-consuming, labor-intensive and inaccurate.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2155024218"
          ],
          "name": "Qi Wang"
        },
        {
          "ids": [
            "1775790"
          ],
          "name": "S. Nuske"
        },
        {
          "ids": [
            "1732972"
          ],
          "name": "M. Bergerman"
        },
        {
          "ids": [
            "2118413567"
          ],
          "name": "Sanjiv Singh"
        }
      ],
      "corpusid": 14107137,
      "doi": "10.1007/978-3-319-00065-7_50",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 14107137,
        "DBLP": "conf/iser/WangNBS12",
        "DOI": "10.1007/978-3-319-00065-7_50",
        "MAG": "2134974756",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering"
      ],
      "id": "7c3410cce942bce690d244562137ecfcb5f3b180",
      "isOpenAccess": false,
      "journalName": null,
      "journalPages": "745-758",
      "journalVolume": null,
      "magId": "2134974756",
      "number_of_authors": 4,
      "paperId": "7c3410cce942bce690d244562137ecfcb5f3b180",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": null,
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Automated Crop Yield Estimation for Apple Orchards",
      "tldr": "A computer vision-based system for automated, rapid and accurate yield estimation that works well with both red and green apples in the tall-spindle planting system and is time-consuming, labor-intensive and inaccurate.",
      "url": "https://www.semanticscholar.org/paper/7c3410cce942bce690d244562137ecfcb5f3b180",
      "venue": "International Symposium on Experimental Robotics",
      "year": 2012,
      "edges_count": 190,
      "local_citations": [
        "0d44970499a233c3be99995f615a91980becf3d4",
        "1c8c77afa31d57c45cfbf404231217dc4db17a14",
        "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
        "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
        "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
        "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
        "8352826ff8f12ded684bf07540341a5ef6da06fd",
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a08767952d56b006deecb75488a6c5ce5c8aa16d",
        "a598e30cce3902fafa5c2692e2ad68437339b383",
        "ac03e40cc705cbd9270d221eb23cf06460be579e",
        "b95191e4672475b32d0a4c571bd2817659747dca",
        "c2eaffc617c57ab5106ba3bc95b7b910be473389",
        "c4700a0be2f3621310c5d1142bd2d29431efcc10",
        "ca7871a6571158cad8d8fcd114c115c39c372ac6",
        "d3eb6e57f618cf0830678594efd7e67eec76a898",
        "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
        "eaa7b6893790279292e9f2fafe48662af8b6ae3d"
      ],
      "paper_id": "7c3410cce942bce690d244562137ecfcb5f3b180",
      "pi_name": "Sanjiv Singh"
    }
  ],
  "edges": [
    [
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      5.9263609828996686e-05
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.00040020045066971435
    ],
    [
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.0009325447998667635
    ],
    [
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.0024298126469102723
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.0024579687253898767
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.0025297342356202382
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.00272892590771632
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.0028461458255650512
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.002864244547768369
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.0030452039562014733
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.005167489651522423
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.005172740153432428
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.005331901388922656
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.005405455208758583
    ],
    [
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.005462455496391084
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.0056815342668847975
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.005874128648813095
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.006080238425964432
    ],
    [
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.0062068490885203945
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      0.006301338005090412
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.006539124344905144
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.006778055460771254
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.006788977874389734
    ],
    [
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.006922519845248311
    ],
    [
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.006958825645916863
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.007220283130832763
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.007230648631505681
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.007534208484347231
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.007534208484347231
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.007534208484347231
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.007534208484347231
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.007876672506363015
    ],
    [
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.00805985093674355
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.008251752149523157
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.008251752149523157
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.008251752149523157
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.008386353348611524
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.00851637433076054
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.008664339756999316
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.008788898309344878
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.008826769147634706
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.008886502314871094
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.008886502314871094
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.009120357638946648
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.009285897532156672
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.009366853791350613
    ],
    [
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.009524984948158035
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.009627044174443685
    ],
    [
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.009717070618496748
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.00990210257942779
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.01019334089058743
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.01036426687422745
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.01050223000848402
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.010660754235027175
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.010770708712432448
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.011179793234837827
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.011552453009332421
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.011552453009332421
    ],
    [
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.0115610191520596
    ],
    [
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.011564339880716945
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.01195081345793009
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.012343958299641683
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.012343958299641683
    ],
    [
      "b95191e4672475b32d0a4c571bd2817659747dca",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.012343958299641683
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.012377628224284737
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.012627727455955284
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.012627727455955284
    ],
    [
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.012774561496140811
    ],
    [
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.013078717722239402
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      0.013397710837415974
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.014434219580578039
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.014437325502587821
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.014455424850896181
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.014455424850896181
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.014648163848908132
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.014648163848908132
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.015049483406412462
    ],
    [
      "b95191e4672475b32d0a4c571bd2817659747dca",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.015049483406412462
    ],
    [
      "b95191e4672475b32d0a4c571bd2817659747dca",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.015179830728275633
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.015694461266687283
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.01575334501272603
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.015921917227074055
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.01690172751797092
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.01690172751797092
    ],
    [
      "b95191e4672475b32d0a4c571bd2817659747dca",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.01690172751797092
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      0.0174382902963192
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      0.0174382902963192
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      0.0174382902963192
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.017719553043034027
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      0.017918072357501633
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.017926220186895138
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      0.01801003751914934
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      0.01801003751914934
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.01801003751914934
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.018506125892841035
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.01894159118393293
    ],
    [
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.01894159118393293
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.019273899801194906
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.019273899801194906
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.019273899801194906
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.020095853954835555
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.020344672012372403
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.020344672012372403
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.02066079359283839
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.0207285337484549
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.021127159397463652
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.021127159397463652
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.02149398902900729
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      0.021541417424864897
    ],
    [
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.021972245773362195
    ],
    [
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.022067119829710265
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.022420658952410404
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.022420658952410404
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.022420658952410404
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.022420658952410404
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.022936248017562465
    ],
    [
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.023104906018664842
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.023374729546129996
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.023374729546129996
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.023374729546129996
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.02340208474865653
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.023882875840611082
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.023882875840611082
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.0242368529050354
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.024413606414846883
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.024413606414846883
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.02491704644833271
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.02519065040620763
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.025549122992281622
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.025549122992281622
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.02567211779851649
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.025954446317351623
    ],
    [
      "b95191e4672475b32d0a4c571bd2817659747dca",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.025958676007001618
    ],
    [
      "b95191e4672475b32d0a4c571bd2817659747dca",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.02599301927099795
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      0.026157435444478804
    ],
    [
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.026157435444478804
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.02692931426470146
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.02699762687871971
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.027310880100209236
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      0.027465307216702747
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.027465307216702747
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.029287909037744166
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.02970630773828337
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.029745396626439408
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.030665488697468178
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.031339568881592526
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.032312126137297344
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      0.032491274088747434
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.03300700859809263
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.03330210338601754
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.033398951204083364
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      0.03349231317450108
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.03353937970451348
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.034089205601308785
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.03433163402087843
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.03433163402087843
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.03537226181173847
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.03543910608606805
    ],
    [
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.03551948238690267
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.03648143055578659
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.03724569611540477
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      0.037808028030542465
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.037808028030542465
    ],
    [
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.037816653984803
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.03788318236786586
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.037905157433048876
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.03878163644419519
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      0.039234746069430865
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.03925458323010001
    ],
    [
      "b95191e4672475b32d0a4c571bd2817659747dca",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.039408172906964974
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.03973920771442223
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      0.039823156239685485
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.03988479984276951
    ],
    [
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.040207760409725804
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.0402135950766583
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.04035494300063187
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.04074526360592659
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.04077336356234972
    ],
    [
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.04117903835159014
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      0.04119243682750084
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.042254318794927304
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.04243758248326195
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.04286370213356251
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      0.04291834433157601
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.04291834433157601
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.04349832195767839
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.04394449154672439
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      0.04424343705701778
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.04424343705701778
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.04515113522904411
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.045205250906083384
    ],
    [
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.045205250906083384
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      0.045336279223495785
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      0.045336279223495785
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.045336279223495785
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.045665310958410366
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      0.045749851526932506
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.0457755120278379
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.04617936776360966
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.04617936776360966
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      0.046209812037329684
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      0.046209812037329684
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.046650374273452186
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.047260035038178085
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      0.0483591056204613
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.0483591056204613
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.0483591056204613
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.04836841653832366
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.04905705702299683
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      0.04906352348688401
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      0.04922416124252898
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.049510512897138946
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.049510512897138946
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      0.05109326706140001
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.051917352014003236
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.0519860385419959
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.0519860385419959
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.0519860385419959
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.05226344186091848
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      0.05276845614538034
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.05276845614538034
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.05276845614538034
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.053319013889226566
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.053319013889226566
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.053319013889226566
    ],
    [
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.05373957216625209
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      0.05376668070705404
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.054038046234205765
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.05414106796900181
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.05455721737064747
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.054626813086221186
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.054626813086221186
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.05472214583367989
    ],
    [
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.055072928746848486
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      0.05523810851068671
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.055443594839394206
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.05549785904945173
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.055597432830151804
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.056201122748103675
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.056201122748103675
    ],
    [
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.056201122748103675
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.05629432202696888
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.056471505699442114
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.056471505699442114
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.05729838272003889
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.05747992544407501
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.057762265046662105
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.05817400874117061
    ],
    [
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.05823859631327572
    ],
    [
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.058525014997603646
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.060532414500947804
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.060532414500947804
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.060596463287693525
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.06116004534352459
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.06116004534352459
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.06116004534352459
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.06116004534352459
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.06190145817054232
    ],
    [
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.06190145817054232
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      0.062213870459307465
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.06345359181702108
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.06345359181702108
    ],
    [
      "b95191e4672475b32d0a4c571bd2817659747dca",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.06399140961528767
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.06415088403479055
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      0.064377516497364
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.06578313350065648
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.06587350989809025
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.06633784599052203
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.0670599130180875
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.0670599130180875
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.0670599130180875
    ],
    [
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.0670599130180875
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.06707875940902697
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.06707875940902697
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.06725428117410608
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.06786967686469905
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.06788058659495279
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.06802473471214927
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.06848671967804681
    ],
    [
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.06848671967804681
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      0.06891382573954058
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.06898398016261405
    ],
    [
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.06931471805599453
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.06997556141017827
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.06997556141017827
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.06997556141017827
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.07068539834179102
    ],
    [
      "b95191e4672475b32d0a4c571bd2817659747dca",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.07077162326489268
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.07110156623920853
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      0.07153057388596001
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.07153057388596001
    ],
    [
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.07170488074758055
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.07181910990438446
    ],
    [
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.07315626874700457
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.07422948602949266
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.07426576934570842
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.07465664455116895
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.07465664455116895
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.07465664455116895
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.07484269804058898
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.07605261752892242
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.07681224272586762
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.07723101160465755
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.07723101160465755
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.07825855264386479
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.07850916646020002
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      0.07914164167190643
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.0799892620191096
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      0.0799892620191096
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.0799892620191096
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      0.08047189562170502
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.08223518189264449
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.08253527756072308
    ],
    [
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.08256163189959549
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      0.08295182727907661
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.08295182727907661
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.08295182727907661
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.08365569420551064
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      0.08451695609566298
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.08460478908936145
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.08614228217442572
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.08614228217442572
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.08661743301848432
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      0.08772327321386919
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.087831346530787
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.08875665116926129
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.08913269279762515
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.08958797346140275
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      0.08958797346140275
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.08958797346140275
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.09002674761385765
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.09141629945041096
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.0923289227716301
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.0933208056889612
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      0.0933208056889612
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.09401126333308354
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.09415694269622484
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.09467281837847649
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.09514845979973341
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.09530635474617313
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      0.09541642354025394
    ],
    [
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.09570049913386786
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      0.09704060527839234
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      0.09737823202326386
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.09765442565938753
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.09765442565938753
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.09775125394786044
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.09954219273489194
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.09954219273489194
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.09954219273489194
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.09987384442437362
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      0.10058986952713127
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.10108396383165869
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.10241632363449016
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.10250768163210457
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.10368582396518602
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      0.10383470402800647
    ],
    [
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.10383470402800647
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      0.1039720770839918
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.1041720621644218
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.10424518655653463
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.10424518655653463
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      0.10495648375286273
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.10589278496315171
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.10614055358483526
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.10665234935881279
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.10665234935881279
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.10665234935881279
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.10670032721887791
    ],
    [
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.10703007935116801
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      0.10925362617244237
    ],
    [
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.11014585749369697
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.11198496682675343
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.11198496682675343
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      0.11226404706088346
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      0.11226404706088346
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.11232268895433184
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.11235205401578341
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.11348536433056508
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.11371945931061601
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.11371945931061601
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.11446530288560666
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.11485637623256761
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.11485637623256761
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.1155245300933242
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.11583968880379913
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.1167546089433188
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.1167546089433188
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      0.1167546089433188
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.1174157994989651
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.1187688960722281
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.11913735606461101
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.11913735606461101
    ],
    [
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.11931221960458074
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.1205983769780417
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.12161938431595708
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.12161938431595708
    ],
    [
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.12161938431595708
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.1219015637467436
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      0.12206803207423442
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.12241039215507538
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.12285391323133187
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.12380291634108465
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.12420703079076466
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.12420703079076466
    ],
    [
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.12430948295276997
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.12442774091861493
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.12442774091861493
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.12442774091861493
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.12548354130826594
    ],
    [
      "b95191e4672475b32d0a4c571bd2817659747dca",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.12651057248079328
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.12690718363404216
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.12690718363404216
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.12690718363404216
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.12792139405522476
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.12798281923057533
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.12798281923057533
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.12826695059130624
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.12924850454918937
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.12996509635498973
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.1317470197961805
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.13267569198104406
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.13267569198104406
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.13316512589916482
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.13316512589916482
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.13455192708421526
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      0.13477861844221156
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      0.13477861844221156
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      0.13477861844221156
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.13477861844221156
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.13477861844221156
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.1357393537293981
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.13576117318990558
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      0.137321611243008
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.137321611243008
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.13732653608351372
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.13759397539698837
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.13893750152557124
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.1389935820753795
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.13941251586037037
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      0.13995112282035654
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      0.1399624114592197
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.1399624114592197
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.1399812085334418
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.1399812085334418
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.1417564243442722
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.1417564243442722
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.14238366944307168
    ],
    [
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.14270677246822402
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.1432307633236478
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.14449673138935926
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.14556090791758852
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.1459432611791485
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      0.14670663913130702
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.1480182267159488
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.14819437106237626
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.14853153869141683
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      0.14853153869141683
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.1493132891023379
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.14962645441426864
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.14986845454989817
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      0.15153272947146343
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.15162594574748803
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      0.15353898219475606
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.15362448545173524
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.1544620232093151
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.15777649857205242
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.15821837817129186
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.15821837817129186
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.1594097372072801
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      0.15979815107899778
    ],
    [
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.16038132735954297
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.1605823981266555
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.16072224418903458
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.16094379124341004
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.1617343421306539
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.16215917908794275
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.16270222111707147
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.16275737609897922
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.16394716573138352
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.16447036378528898
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.16541012263362329
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.1658282699876392
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.1658369006677438
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.16644001172569645
    ],
    [
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.1666705679735854
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      0.16679229849045543
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.16679229849045543
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.16925686967161455
    ],
    [
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.16925686967161455
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      0.16956832774861746
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.16986283472906896
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.17052911002959442
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.17249573349435623
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.17269388197455343
    ],
    [
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.1729179342108901
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.17397470856548614
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.17521777658761542
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.17638173915061545
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.17690092264139212
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.17690092264139212
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.17751330233852258
    ],
    [
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.17751330233852258
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.17868617335936643
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.17936527161928323
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.17936527161928323
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.17936527161928323
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.17936527161928323
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      0.17982877070834213
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.17983438592005893
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.1799407839470475
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      0.18176270883881868
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      0.18178303365742465
    ],
    [
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.18225497209962138
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.1824290764739356
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      0.1824290764739356
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.1824290764739356
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.18248800683509767
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      0.1831020481113516
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      0.1831020481113516
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.18321066839010974
    ],
    [
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.18468900775451355
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.18502915925845012
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.1866416113779224
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.18699783636903997
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.1873355681873727
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.18763138183888486
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.18831388539244967
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.18887937593033155
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.19042296295644615
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      0.1912791694454191
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.19188209108283716
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.19206807589554548
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.19337865103212667
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.19417314172614217
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.19459101490553132
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.19518044654017913
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.19530885131877507
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.19530885131877507
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.19530885131877507
    ],
    [
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.19627394230663803
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.19654879285232546
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.19654879285232546
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.19670392961836286
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.19670392961836286
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.19920800981107856
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.19954054113384703
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.19974768884874725
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.19974768884874725
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      0.19982460606653088
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.2018951346475553
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.20216792766331737
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.20234426248262782
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.2027768557057333
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.20316927291123935
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.20316927291123935
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.20439298393825298
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.20476246537778386
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.2072326583694641
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.2074174719401999
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.2079441541679836
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.20925948355583043
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.20925948355583043
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.21060013473525954
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.21118289449272512
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.21146189629537157
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.21146189629537157
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.21146189629537157
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.21193185096279496
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.21330469871762558
    ],
    [
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.21406015870233602
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.21409779221414024
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      0.21436337339865558
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.21436337339865558
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.2158673524681918
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.2158673524681918
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.21621223878392368
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.21621223878392368
    ],
    [
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.2187033397825087
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.21898906477930677
    ],
    [
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.21914015721641392
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      0.22046027486113207
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.2205468301781644
    ],
    [
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.2205468301781644
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.22125529979862624
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      0.2227577189386546
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.2245280941217669
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.22535636690627892
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.22535636690627892
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.22561655541899367
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.22570885055919973
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.22621653516965762
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.22639608650254456
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.22660190036352762
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.22736451515832307
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.2274486205742583
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.22768887707330251
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.22867146699851285
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.22984196257546421
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      0.2302585092994046
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.2302585092994046
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.23026714040938817
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.23114262560113924
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.2312867976143389
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.23164384023447462
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.23214138457589084
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.2324493503007602
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.2330721453380321
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.23438122977760928
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.23477565793159436
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      0.23575782489842828
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.23594278193467194
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.2364761308027729
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      0.23824823114582194
    ],
    [
      "b95191e4672475b32d0a4c571bd2817659747dca",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.238384829206014
    ],
    [
      "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      0.2397716942777895
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.2397716942777895
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.24046400226201908
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      0.24048480866108163
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.24133572977144377
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      0.24260151319598083
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.24409024092043113
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.24413606414846883
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      0.24439267548152246
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.24468319110187456
    ],
    [
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.24849066497880004
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.2489260005792741
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "e35d05f5abd049389e3022f40d467cf472f4987e",
      0.24907370057637068
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.24934079576330978
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      0.24978075758316362
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.24978075758316362
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.2509670826165319
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.2509670826165319
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      0.252751352102873
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.2530923439598889
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.2550952417870607
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.2578676712044151
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.2578676712044151
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.257937101246241
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.25873089439312125
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.2590408229618302
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.25993019270997947
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.25993019270997947
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.260640790521562
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.2653395887029176
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.26542449828512577
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.26568289534546685
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      0.2665729466754442
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.2673448438526025
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.26954467578833413
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.2695572368844231
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.2706671202778655
    ],
    [
      "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.2728205251621334
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.27465307216702745
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.27465307216702745
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      0.27481600258516464
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.2755619207544846
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.27882503172074075
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      0.27891809334355105
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.2800441329317083
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.2800441329317083
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.2807470300353534
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.2835128486885444
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.2835128486885444
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.2835128486885444
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.284728886954875
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.28546372295218697
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.28546372295218697
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.28598290716774283
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.28782313662425574
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.28788312859072274
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      0.28881132523331055
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.2924262527802891
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.2924262527802891
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.2929632769781626
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.29519704280042536
    ],
    [
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.2958248586114785
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.2959556950917158
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.29604665481352016
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.29604665481352016
    ],
    [
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.2961264738463991
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.29710840377900005
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      0.3016467645640875
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.3037108127518667
    ],
    [
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.3037108127518667
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.30574760335024953
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      0.307422470871586
    ],
    [
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.307422470871586
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.31048913359520175
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.31061333122350004
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.31061333122350004
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      0.31075985914287657
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.3114100521206954
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.3139888763173699
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.31551253589452244
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.31551253589452244
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.32129409165619444
    ],
    [
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      0.3238010287022877
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.32551475219795845
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      0.32848850365869176
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.331615928930788
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.3316254990500663
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.3330410101108848
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.3333411359471708
    ],
    [
      "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.3333411359471708
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      0.33424622317655506
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      0.34255646754262437
    ],
    [
      "b95191e4672475b32d0a4c571bd2817659747dca",
      "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      0.3434766800150065
    ],
    [
      "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "d3eb6e57f618cf0830678594efd7e67eec76a898",
      0.34372095865206187
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.3465735902799726
    ],
    [
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      0.3465735902799726
    ],
    [
      "365b31515028f2c7444d5b5afd865d242b229bd2",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.3487031808069189
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.35007903352039144
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.3515559323737951
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.358021485288031
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "a598e30cce3902fafa5c2692e2ad68437339b383",
      0.3592936631339154
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.35998500168704173
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      0.3625251224595857
    ],
    [
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.3633174655755107
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.3633174655755107
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      0.36514690964004637
    ],
    [
      "be1fb04cf17e259933ce33f0015cf54132f266be",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.3662040962227032
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      0.3664213367802195
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.3664213367802195
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.3674355387221871
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.36770209875373905
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "b6946370d6c13d562b96e42d494817c7d1969a8f",
      0.3693780155090271
    ],
    [
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.3693780155090271
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      0.37005831851690024
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.3726334803017731
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.37291027483693867
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.37326848754911063
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.3771015082903267
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.3780802803054247
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.3811971698333151
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.38599853848217136
    ],
    [
      "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.3946075934556211
    ],
    [
      "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.4019701933480589
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.4060133626182945
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.4147551238654687
    ],
    [
      "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      0.42125225350478823
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      0.4337668511498834
    ],
    [
      "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.4636181795270049
    ],
    [
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.4754412295260046
    ],
    [
      "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      0.48995226988627727
    ],
    [
      "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.49956151516632724
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      0.5031949802920221
    ],
    [
      "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "b95191e4672475b32d0a4c571bd2817659747dca",
      0.5179212800647162
    ],
    [
      "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.5291073171130956
    ],
    [
      "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.5395406343236635
    ],
    [
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.5693967533454625
    ],
    [
      "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      0.5974351320544848
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      0.6096385417175357
    ],
    [
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      0.6226561212466917
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.6463402637194625
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      0.6475916214985636
    ],
    [
      "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.6731162882750743
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.6931471805599453
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.6944971356636548
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.7044542828739452
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.708303336014054
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      0.724886294696053
    ],
    [
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.755523558414991
    ],
    [
      "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.7677549981911687
    ],
    [
      "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      0.7691745026692679
    ],
    [
      "0d44970499a233c3be99995f615a91980becf3d4",
      "8352826ff8f12ded684bf07540341a5ef6da06fd",
      0.779410318014646
    ],
    [
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      0.8267598845947457
    ],
    [
      "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      0.8494166348323489
    ],
    [
      "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      0.9788589266282299
    ]
  ],
  "nodes": {
    "9397e7acd062245d37350f5c05faf56e9cfae0d6": {
      "abstract": "This paper presents a novel approach to fruit detection using deep convolutional neural networks. The aim is to build an accurate, fast and reliable fruit detection system, which is a vital element of an autonomous agricultural robotic platform; it is a key element for fruit yield estimation and automated harvesting. Recent work in deep neural networks has led to the development of a state-of-the-art object detector termed Faster Region-based CNN (Faster R-CNN). We adapt this model, through transfer learning, for the task of fruit detection using imagery obtained from two modalities: colour (RGB) and Near-Infrared (NIR). Early and late fusion methods are explored for combining the multi-modal (RGB and NIR) information. This leads to a novel multi-modal Faster R-CNN model, which achieves state-of-the-art results compared to prior work with the F1 score, which takes into account both precision and recall performances improving from 0.807 to 0.838 for the detection of sweet pepper. In addition to improved accuracy, this approach is also much quicker to deploy for new fruits, as it requires bounding box annotation rather than pixel-level annotation (annotating bounding boxes is approximately an order of magnitude quicker to perform). The model is retrained to perform the detection of seven fruits, with the entire process taking four hours to annotate and train the new model per fruit.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "1867220"
          ],
          "name": "Inkyu Sa"
        },
        {
          "ids": [
            "1808390"
          ],
          "name": "ZongYuan Ge"
        },
        {
          "ids": [
            "1757942"
          ],
          "name": "Feras Dayoub"
        },
        {
          "ids": [
            "1803115"
          ],
          "name": "B. Upcroft"
        },
        {
          "ids": [
            "2068824789"
          ],
          "name": "Tristan Perez"
        },
        {
          "ids": [
            "49872143"
          ],
          "name": "C. McCool"
        }
      ],
      "corpusid": 17376502,
      "doi": "10.3390/s16081222",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 17376502,
        "DBLP": "journals/sensors/SaGDUPM16",
        "DOI": "10.3390/s16081222",
        "MAG": "2501369945",
        "PubMed": "27527168",
        "PubMedCentral": "5017387"
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering",
        "Medicine"
      ],
      "id": "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "isOpenAccess": true,
      "journalName": "Sensors (Basel, Switzerland)",
      "journalPages": null,
      "journalVolume": "16",
      "magId": "2501369945",
      "number_of_authors": 6,
      "paperId": "9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "pdfUrls": [
        "https://www.mdpi.com/1424-8220/16/8/1222/pdf?version=1470314790"
      ],
      "pmid": "27527168",
      "publicationDate": "2016-08-01",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "DeepFruits: A Fruit Detection System Using Deep Neural Networks",
      "tldr": "A novel multi-modal Faster R-CNN model, which achieves state-of-the-art results compared to prior work with the F1 score, which takes into account both precision and recall performances improving from 0.807 to 0.838 for the detection of sweet pepper.",
      "url": "https://www.semanticscholar.org/paper/9397e7acd062245d37350f5c05faf56e9cfae0d6",
      "venue": "Italian National Conference on Sensors",
      "year": 2016,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6"
      ],
      "path_length": 0,
      "pos": [
        -26.217436064569224,
        28.08717687647012
      ]
    },
    "e35d05f5abd049389e3022f40d467cf472f4987e": {
      "abstract": "Despite the importance of image representations such as histograms of oriented gradients and deep Convolutional Neural Networks (CNN), our theoretical understanding of them remains limited. Aimed at filling this gap, we investigate two key mathematical properties of representations: equivariance and equivalence. Equivariance studies how transformations of the input image are encoded by the representation, invariance being a special case where a transformation has no effect. Equivalence studies whether two representations, for example two different parameterizations of a CNN, two different layers, or two different CNN architectures, share the same visual information or not. A number of methods to establish these properties empirically are proposed, including introducing transformation and stitching layers in CNNs. These methods are then applied to popular representations to reveal insightful aspects of their structure, including clarifying at which layers in a CNN certain geometric invariances are achieved and how various CNN architectures differ. We identify several predictors of geometric and architectural compatibility, including the spatial resolution of the representation and the complexity and depth of the models. While the focus of the paper is theoretical, direct applications to structured-output regression are demonstrated too.",
      "arxivId": "1411.5908",
      "authors": [
        {
          "ids": [
            "3257286"
          ],
          "name": "Karel Lenc"
        },
        {
          "ids": [
            "1687524"
          ],
          "name": "A. Vedaldi"
        }
      ],
      "corpusid": 9044418,
      "doi": "10.1007/s11263-018-1098-y",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1411.5908",
        "CorpusId": 9044418,
        "DBLP": "journals/corr/LencV14",
        "DOI": "10.1007/s11263-018-1098-y",
        "MAG": "2803630603",
        "PubMed": "31148885",
        "PubMedCentral": "6510825"
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics",
        "Medicine"
      ],
      "id": "e35d05f5abd049389e3022f40d467cf472f4987e",
      "isOpenAccess": true,
      "journalName": "International Journal of Computer Vision",
      "journalPages": "456 - 476",
      "journalVolume": "127",
      "magId": "2803630603",
      "number_of_authors": 2,
      "paperId": "e35d05f5abd049389e3022f40d467cf472f4987e",
      "pdfUrls": [
        "https://link.springer.com/content/pdf/10.1007/s11263-018-1098-y.pdf"
      ],
      "pmid": "31148885",
      "publicationDate": "2014-11-21",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Understanding Image Representations by Measuring Their Equivariance and Equivalence",
      "tldr": "This work investigates two key mathematical properties of representations: equivariance and equivalence and identifies several predictors of geometric and architectural compatibility, including the spatial resolution of the representation and the complexity and depth of the models.",
      "url": "https://www.semanticscholar.org/paper/371400e61632592146f40b621fb3dbb6971721be",
      "venue": "International Journal of Computer Vision",
      "year": 2014,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "e35d05f5abd049389e3022f40d467cf472f4987e"
      ],
      "path_length": 4.9530663616321515,
      "pos": [
        101.72092088469314,
        104.87966885127157
      ]
    },
    "c4700a0be2f3621310c5d1142bd2d29431efcc10": {
      "abstract": "S2 TL;DR: A conditional random field is used on multi-spectral image data to model two classes: crop and background to explore a range of visual-texture features including local binary pattern, histogram of oriented gradients, and learn auto-encoder features.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "1867220"
          ],
          "name": "Inkyu Sa"
        },
        {
          "ids": [
            "49872143"
          ],
          "name": "C. McCool"
        },
        {
          "ids": [
            "2355154"
          ],
          "name": "Christopher F. Lehnert"
        },
        {
          "ids": [
            "2068824789"
          ],
          "name": "Tristan Perez"
        }
      ],
      "corpusid": 112987225,
      "doi": "",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 112987225,
        "DBLP": null,
        "DOI": null,
        "MAG": "2242035466",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering"
      ],
      "id": "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      "isOpenAccess": false,
      "journalName": "",
      "journalPages": null,
      "journalVolume": "",
      "magId": "2242035466",
      "number_of_authors": 4,
      "paperId": "c4700a0be2f3621310c5d1142bd2d29431efcc10",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": null,
      "publicationTypes": null,
      "title": "On Visual Detection of Highly-occluded Objects for Harvesting Automation in Horticulture",
      "tldr": "A conditional random field is used on multi-spectral image data to model two classes: crop and background to explore a range of visual-texture features including local binary pattern, histogram of oriented gradients, and learn auto-encoder features.",
      "url": "https://www.semanticscholar.org/paper/c4700a0be2f3621310c5d1142bd2d29431efcc10",
      "venue": "IEEE International Conference on Robotics and Automation",
      "year": 2015,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
        "c4700a0be2f3621310c5d1142bd2d29431efcc10"
      ],
      "path_length": 4.084883119019987,
      "pos": [
        -122.02778774531859,
        147.80994339642277
      ]
    },
    "2b16d04ae11a903c079946c83ea2b5d517cce970": {
      "abstract": "This study develops tomato disease detection methods based on deep convolutional neural networks and object detection models. Two different models, Faster R-CNN and Mask R-CNN, are used in these methods, where Faster R-CNN is used to identify the types of tomato diseases and Mask R-CNN is used to detect and segment the locations and shapes of the infected areas. To select the model that best fits the tomato disease detection task, four different deep convolutional neural networks are combined with the two object detection models. Data are collected from the Internet and the dataset is divided into a training set, a validation set, and a test set used in the experiments. The experimental results show that the proposed models can accurately and quickly identify the eleven tomato disease types and segment the locations and shapes of the infected areas.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "51513715"
          ],
          "name": "Qimei Wang"
        },
        {
          "ids": [
            "2056306756"
          ],
          "name": "Feng Qi"
        },
        {
          "ids": [
            "39382965"
          ],
          "name": "Minghe Sun"
        },
        {
          "ids": [
            "145686895"
          ],
          "name": "Jianhua Qu"
        },
        {
          "ids": [
            "1382510649"
          ],
          "name": "Jie Xue"
        }
      ],
      "corpusid": 209391851,
      "doi": "10.1155/2019/9142753",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 209391851,
        "DBLP": "journals/cin/WangQSQX19",
        "DOI": "10.1155/2019/9142753",
        "MAG": "2995726119",
        "PubMed": "31933623",
        "PubMedCentral": "6942764"
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Medicine"
      ],
      "id": "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "isOpenAccess": true,
      "journalName": "Computational Intelligence and Neuroscience",
      "journalPages": null,
      "journalVolume": "2019",
      "magId": "2995726119",
      "number_of_authors": 5,
      "paperId": "2b16d04ae11a903c079946c83ea2b5d517cce970",
      "pdfUrls": [
        "https://doi.org/10.1155/2019/9142753"
      ],
      "pmid": "31933623",
      "publicationDate": "2019-12-16",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Identification of Tomato Disease Types and Detection of Infected Areas Based on Deep Convolutional Neural Networks and Object Detection Techniques",
      "tldr": "The experimental results show that the proposed models can accurately and quickly identify the eleven tomato disease types and segment the locations and shapes of the infected areas.",
      "url": "https://www.semanticscholar.org/paper/2b16d04ae11a903c079946c83ea2b5d517cce970",
      "venue": "Computational Intelligence and Neuroscience",
      "year": 2019,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "2b16d04ae11a903c079946c83ea2b5d517cce970"
      ],
      "path_length": 4.8211946209059375,
      "pos": [
        74.30452592977414,
        61.74902427014061
      ]
    },
    "be1fb04cf17e259933ce33f0015cf54132f266be": {
      "abstract": "S2 TL;DR: This work applies the Faster R-CNN model to video clips from the ImageNet 2015 Object Detection from Video challenge, and ranked 3 rd place in terms of mean average precision.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "3377142"
          ],
          "name": "Prajit Ramachandran"
        }
      ],
      "corpusid": 2299630,
      "doi": "",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 2299630,
        "DBLP": null,
        "DOI": null,
        "MAG": null,
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "be1fb04cf17e259933ce33f0015cf54132f266be",
      "isOpenAccess": false,
      "journalName": null,
      "journalPages": null,
      "journalVolume": null,
      "magId": null,
      "number_of_authors": 1,
      "paperId": "be1fb04cf17e259933ce33f0015cf54132f266be",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": null,
      "publicationTypes": null,
      "title": "Object Detection in Video using Faster R-CNN",
      "tldr": "This work applies the Faster R-CNN model to video clips from the ImageNet 2015 Object Detection from Video challenge, and ranked 3 rd place in terms of mean average precision.",
      "url": "https://www.semanticscholar.org/paper/be1fb04cf17e259933ce33f0015cf54132f266be",
      "venue": "",
      "year": 2015,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "be1fb04cf17e259933ce33f0015cf54132f266be"
      ],
      "path_length": 4.437416229805832,
      "pos": [
        161.61517962721322,
        -45.30353577290502
      ]
    },
    "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb": {
      "abstract": "R-CNN style methods are sorts of the state-of-the-art object detection methods, which consist of region proposal generation and deep CNN classification. However, the proposal generation phase in this paradigm is usually time consuming, which would slow down the whole detection time in testing. This paper suggests that the value discrepancies among features in deep convolutional feature maps contain plenty of useful spatial information, and proposes a simple approach to extract the information for fast region proposal generation in testing. The proposed method, namely Relief R-CNN (\\(R^2\\)-CNN), adopts a novel region proposal generator in a trained R-CNN style model. The new generator directly generates proposals from convolutional features by some simple rules, thus resulting in a much faster proposal generation speed and a lower demand of computation resources. Empirical studies show that \\(R^2\\)-CNN could achieve the fastest detection speed with comparable accuracy among all the compared algorithms in testing.",
      "arxivId": "1601.06719",
      "authors": [
        {
          "ids": [
            "2198471"
          ],
          "name": "Guiying Li"
        },
        {
          "ids": [
            null
          ],
          "name": "Junlong Liu"
        },
        {
          "ids": [
            "2115485453"
          ],
          "name": "Chunhui Jiang"
        },
        {
          "ids": [
            "2146644512"
          ],
          "name": "Liangpeng Zhang"
        },
        {
          "ids": [
            "1996955"
          ],
          "name": "Minlong Lin"
        },
        {
          "ids": [
            "2055743310"
          ],
          "name": "Ke Tang"
        }
      ],
      "corpusid": 13248308,
      "doi": "10.1007/978-3-319-59072-1_46",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1601.06719",
        "CorpusId": 13248308,
        "DBLP": "conf/isnn/LiLJZLT17",
        "DOI": "10.1007/978-3-319-59072-1_46",
        "MAG": "2611549294",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "isOpenAccess": true,
      "journalName": null,
      "journalPages": "386-394",
      "journalVolume": null,
      "magId": "2611549294",
      "number_of_authors": 6,
      "paperId": "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "pdfUrls": [
        "https://arxiv.org/pdf/1601.06719"
      ],
      "pmid": "",
      "publicationDate": "2016-01-25",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Relief R-CNN: Utilizing Convolutional Features for Fast Object Detection",
      "tldr": "It is suggested that the value discrepancies among features in deep convolutional feature maps contain plenty of useful spatial information, and a simple approach to extract the information for fast region proposal generation in testing is proposed.",
      "url": "https://www.semanticscholar.org/paper/7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb",
      "venue": "International Symposium on Neural Networks",
      "year": 2016,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb"
      ],
      "path_length": 4.728984358502075,
      "pos": [
        116.65869595203793,
        -37.461598525781454
      ]
    },
    "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c": {
      "abstract": "S2 TL;DR: Results on publicly available datasets using convolutional neural network (CNN) architectures have demonstrated its viability, and the approach of using CNN\u2019s on a considerably diverse dataset would pave the way for automated disease recognition systems.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2000608829"
          ],
          "name": "H. Malik"
        },
        {
          "ids": [
            "89081319"
          ],
          "name": "M. Dwivedi"
        },
        {
          "ids": [
            "144148109"
          ],
          "name": "S. N. Omkar"
        },
        {
          "ids": [
            "2060402296"
          ],
          "name": "Tahir Javed"
        },
        {
          "ids": [
            "2003498224"
          ],
          "name": "Abdul Bakey"
        },
        {
          "ids": [
            "2003363966"
          ],
          "name": "Mohammad Raqib Pala"
        },
        {
          "ids": [
            "2063965852"
          ],
          "name": "A. Chakravarthy"
        }
      ],
      "corpusid": 224996136,
      "doi": "10.1007/978-981-15-3514-7_17",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 224996136,
        "DBLP": null,
        "DOI": "10.1007/978-981-15-3514-7_17",
        "MAG": "3049600440",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science"
      ],
      "id": "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      "isOpenAccess": false,
      "journalName": "",
      "journalPages": "189-206",
      "journalVolume": "",
      "magId": "3049600440",
      "number_of_authors": 7,
      "paperId": "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": null,
      "publicationTypes": null,
      "title": "Disease Recognition in Sugarcane Crop Using Deep Learning",
      "tldr": "Results on publicly available datasets using convolutional neural network (CNN) architectures have demonstrated its viability, and the approach of using CNN\u2019s on a considerably diverse dataset would pave the way for automated disease recognition systems.",
      "url": "https://www.semanticscholar.org/paper/c5260d2ec5916a85f772ca000d731fd6bc1e3c5c",
      "venue": "",
      "year": 2020,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c"
      ],
      "path_length": 4.432298853880181,
      "pos": [
        40.073540812869446,
        -158.67658922426978
      ]
    },
    "738fa51e1a0f5c652019ab7165841ca4d399ce59": {
      "abstract": "S2 TL;DR: Object detection algorithms have gone through significant improvement since 2012, due to availability of datasets, graphical processing units (GPU\u2019s) and pretrained networks the cost and the training time has been reduced drastically and Neural networks with large number of layers have higher capacity to learn complex features and are able to optimize certain tasks.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "115153416"
          ],
          "name": "M. Rachna"
        },
        {
          "ids": [
            "2472303"
          ],
          "name": "S. Bali"
        },
        {
          "ids": [
            "2287004266"
          ],
          "name": "Dr. Shyam Sunder Tyagi"
        }
      ],
      "corpusid": 245903046,
      "doi": "",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 245903046,
        "DBLP": null,
        "DOI": null,
        "MAG": null,
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "id": "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "isOpenAccess": false,
      "journalName": null,
      "journalPages": null,
      "journalVolume": null,
      "magId": null,
      "number_of_authors": 3,
      "paperId": "738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": null,
      "publicationTypes": null,
      "title": "DEVELOPMENT OF OBJECT",
      "tldr": "Object detection algorithms have gone through significant improvement since 2012, due to availability of datasets, graphical processing units (GPU\u2019s) and pretrained networks the cost and the training time has been reduced drastically and Neural networks with large number of layers have higher capacity to learn complex features and are able to optimize certain tasks.",
      "url": "https://www.semanticscholar.org/paper/738fa51e1a0f5c652019ab7165841ca4d399ce59",
      "venue": "",
      "year": null,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "738fa51e1a0f5c652019ab7165841ca4d399ce59"
      ],
      "path_length": 5.087795175375805,
      "pos": [
        -43.081105189444955,
        -83.7571935080948
      ]
    },
    "ca7871a6571158cad8d8fcd114c115c39c372ac6": {
      "abstract": "S2 TL;DR: The state-of-the-art deep-level Faster R-CNN framework for representing the strawberry flower instances under various camera view-points, different distances to flowers, overlaps, complex background illumination, blur, etc, shows the effectiveness.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "123089466"
          ],
          "name": "P. Lin"
        },
        {
          "ids": [
            "2286221639"
          ],
          "name": "Won Suk Lee"
        },
        {
          "ids": [
            "81369856"
          ],
          "name": "Y. M. Chen"
        },
        {
          "ids": [
            "3951198"
          ],
          "name": "N. Peres"
        },
        {
          "ids": [
            "2537366"
          ],
          "name": "C. Fraisse"
        }
      ],
      "corpusid": 174803287,
      "doi": "10.1007/s11119-019-09673-7",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 174803287,
        "DBLP": null,
        "DOI": "10.1007/s11119-019-09673-7",
        "MAG": "2948692490",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science"
      ],
      "id": "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      "isOpenAccess": false,
      "journalName": "Precision Agriculture",
      "journalPages": "387 - 402",
      "journalVolume": "21",
      "magId": "2948692490",
      "number_of_authors": 5,
      "paperId": "ca7871a6571158cad8d8fcd114c115c39c372ac6",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2019-06-07",
      "publicationTypes": null,
      "title": "A deep-level region-based visual representation architecture for detecting strawberry flowers in an outdoor field",
      "tldr": "The state-of-the-art deep-level Faster R-CNN framework for representing the strawberry flower instances under various camera view-points, different distances to flowers, overlaps, complex background illumination, blur, etc, shows the effectiveness.",
      "url": "https://www.semanticscholar.org/paper/ca7871a6571158cad8d8fcd114c115c39c372ac6",
      "venue": "Precision Agriculture",
      "year": 2019,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "ca7871a6571158cad8d8fcd114c115c39c372ac6"
      ],
      "path_length": 4.010575152528445,
      "pos": [
        -90.40337326834567,
        -2.41779604120351
      ]
    },
    "b724c3f7ff395235b62537203ddeb710f0eb27bb": {
      "abstract": "We present region-based, fully convolutional networks for accurate and efficient object detection. In contrast to previous region-based detectors such as Fast/Faster R-CNN that apply a costly per-region subnetwork hundreds of times, our region-based detector is fully convolutional with almost all computation shared on the entire image. To achieve this goal, we propose position-sensitive score maps to address a dilemma between translation-invariance in image classification and translation-variance in object detection. Our method can thus naturally adopt fully convolutional image classifier backbones, such as the latest Residual Networks (ResNets), for object detection. We show competitive results on the PASCAL VOC datasets (e.g., 83.6% mAP on the 2007 set) with the 101-layer ResNet. Meanwhile, our result is achieved at a test-time speed of 170ms per image, 2.5-20 times faster than the Faster R-CNN counterpart. Code is made publicly available at: https://github.com/daijifeng001/r-fcn.",
      "arxivId": "1605.06409",
      "authors": [
        {
          "ids": [
            "3304536"
          ],
          "name": "Jifeng Dai"
        },
        {
          "ids": [
            "2153682629"
          ],
          "name": "Yi Li"
        },
        {
          "ids": [
            "39353098"
          ],
          "name": "Kaiming He"
        },
        {
          "ids": [
            null
          ],
          "name": "Jian Sun"
        }
      ],
      "corpusid": 7428689,
      "doi": "",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1605.06409",
        "CorpusId": 7428689,
        "DBLP": "journals/corr/DaiLHS16",
        "DOI": null,
        "MAG": "2950800384",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "isOpenAccess": false,
      "journalName": null,
      "journalPages": "379-387",
      "journalVolume": null,
      "magId": "2950800384",
      "number_of_authors": 4,
      "paperId": "b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2016-05-20",
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ],
      "title": "R-FCN: Object Detection via Region-based Fully Convolutional Networks",
      "tldr": "This work presents region-based, fully convolutional networks for accurate and efficient object detection, and proposes position-sensitive score maps to address a dilemma between translation-invariance in image classification and translation-variance in object detection.",
      "url": "https://www.semanticscholar.org/paper/b724c3f7ff395235b62537203ddeb710f0eb27bb",
      "venue": "Neural Information Processing Systems",
      "year": 2016,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "b724c3f7ff395235b62537203ddeb710f0eb27bb"
      ],
      "path_length": 5.150042848924902,
      "pos": [
        52.515416736617205,
        -52.10483383449647
      ]
    },
    "4328ec9d98eff5d7eb70997f76d81b27849f3220": {
      "abstract": "Current high-quality object detection approaches use the scheme of salience-based object proposal methods followed by post-classification using deep convolutional features. This spurred recent research in improving object proposal methods. However, domain agnostic proposal generation has the principal drawback that the proposals come unranked or with very weak ranking, making it hard to trade-off quality for running time. This raises the more fundamental question of whether high-quality proposal generation requires careful engineering or can be derived just from data alone. We demonstrate that learning-based proposal methods can effectively match the performance of hand-engineered methods while allowing for very efficient runtime-quality trade-offs. Using the multi-scale convolutional MultiBox (MSC-MultiBox) approach, we substantially advance the state-of-the-art on the ILSVRC 2014 detection challenge data set, with $0.5$ mAP for a single model and $0.52$ mAP for an ensemble of two models. MSC-Multibox significantly improves the proposal quality over its predecessor MultiBox~method: AP increases from $0.42$ to $0.53$ for the ILSVRC detection challenge. Finally, we demonstrate improved bounding-box recall compared to Multiscale Combinatorial Grouping with less proposals on the Microsoft-COCO data set.",
      "arxivId": "1412.1441",
      "authors": [
        {
          "ids": [
            "2574060"
          ],
          "name": "Christian Szegedy"
        },
        {
          "ids": [
            "144828948"
          ],
          "name": "Scott E. Reed"
        },
        {
          "ids": [
            "1761978"
          ],
          "name": "D. Erhan"
        },
        {
          "ids": [
            "1838674"
          ],
          "name": "Dragomir Anguelov"
        }
      ],
      "corpusid": 17718521,
      "doi": "",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1412.1441",
        "CorpusId": 17718521,
        "DBLP": "journals/corr/SzegedyREA14",
        "DOI": null,
        "MAG": "1594098193",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "isOpenAccess": false,
      "journalName": "ArXiv",
      "journalPages": null,
      "journalVolume": "abs/1412.1441",
      "magId": "1594098193",
      "number_of_authors": 4,
      "paperId": "4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2014-12-03",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Scalable, High-Quality Object Detection",
      "tldr": "It is demonstrated that learning-based proposal methods can effectively match the performance of hand-engineered methods while allowing for very efficient runtime-quality trade-offs.",
      "url": "https://www.semanticscholar.org/paper/4328ec9d98eff5d7eb70997f76d81b27849f3220",
      "venue": "arXiv.org",
      "year": 2014,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "4328ec9d98eff5d7eb70997f76d81b27849f3220"
      ],
      "path_length": 4.735232000688618,
      "pos": [
        2.5500706051374227,
        -120.9076649730006
      ]
    },
    "f8e79ac0ea341056ef20f2616628b3e964764cfd": {
      "abstract": "We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.",
      "arxivId": "1506.02640",
      "authors": [
        {
          "ids": [
            "40497777"
          ],
          "name": "Joseph Redmon"
        },
        {
          "ids": [
            "2038685"
          ],
          "name": "S. Divvala"
        },
        {
          "ids": [
            "2983898"
          ],
          "name": "Ross B. Girshick"
        },
        {
          "ids": [
            "143787583"
          ],
          "name": "Ali Farhadi"
        }
      ],
      "corpusid": 206594738,
      "doi": "10.1109/CVPR.2016.91",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1506.02640",
        "CorpusId": 206594738,
        "DBLP": "journals/corr/RedmonDGF15",
        "DOI": "10.1109/CVPR.2016.91",
        "MAG": "2950099460",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      "isOpenAccess": true,
      "journalName": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
      "journalPages": "779-788",
      "journalVolume": null,
      "magId": "2950099460",
      "number_of_authors": 4,
      "paperId": "f8e79ac0ea341056ef20f2616628b3e964764cfd",
      "pdfUrls": [
        "https://arxiv.org/pdf/1506.02640"
      ],
      "pmid": "",
      "publicationDate": "2015-06-08",
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ],
      "title": "You Only Look Once: Unified, Real-Time Object Detection",
      "tldr": "Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background, and outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.",
      "url": "https://www.semanticscholar.org/paper/f8e79ac0ea341056ef20f2616628b3e964764cfd",
      "venue": "Computer Vision and Pattern Recognition",
      "year": 2015,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "f8e79ac0ea341056ef20f2616628b3e964764cfd"
      ],
      "path_length": 5.019878472498986,
      "pos": [
        -70.48107653414647,
        -125.52360722863367
      ]
    },
    "45d45687ebca6281d44e477cd012a1ef48ebf286": {
      "abstract": "An accurate and reliable image based fruit detection system is critical for supporting higher level agriculture tasks such as yield mapping and robotic harvesting. This paper presents the use of a state-of-the-art object detection framework, Faster R-CNN, in the context of fruit detection in orchards, including mangoes, almonds and apples. Ablation studies are presented to better understand the practical deployment of the detection network, including how much training data is required to capture variability in the dataset. Data augmentation techniques are shown to yield significant performance gains, resulting in a greater than two-fold reduction in the number of training images required. In contrast, transferring knowledge between orchards contributed to negligible performance gain over initialising the Deep Convolutional Neural Network directly from ImageNet features. Finally, to operate over orchard data containing between 100\u20131000 fruit per image, a tiling approach is introduced for the Faster R-CNN framework. The study has resulted in the best yet detection performance for these orchards relative to previous works, with an F1-score of > 0.9 achieved for apples and mangoes.",
      "arxivId": "1610.03677",
      "authors": [
        {
          "ids": [
            "2690856"
          ],
          "name": "Suchet Bargoti"
        },
        {
          "ids": [
            "3319082"
          ],
          "name": "J. Underwood"
        }
      ],
      "corpusid": 3763290,
      "doi": "10.1109/ICRA.2017.7989417",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1610.03677",
        "CorpusId": 3763290,
        "DBLP": "conf/icra/BargotiU17",
        "DOI": "10.1109/ICRA.2017.7989417",
        "MAG": "2963523428",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering"
      ],
      "id": "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "isOpenAccess": true,
      "journalName": "2017 IEEE International Conference on Robotics and Automation (ICRA)",
      "journalPages": "3626-3633",
      "journalVolume": null,
      "magId": "2963523428",
      "number_of_authors": 2,
      "paperId": "45d45687ebca6281d44e477cd012a1ef48ebf286",
      "pdfUrls": [
        "https://arxiv.org/pdf/1610.03677"
      ],
      "pmid": "",
      "publicationDate": "2016-10-12",
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ],
      "title": "Deep fruit detection in orchards",
      "tldr": "The use of a state-of-the-art object detection framework, Faster R-CNN, in the context of fruit detection in orchards, including mangoes, almonds and apples, has resulted in the best yet detection performance for these orchard relative to previous works.",
      "url": "https://www.semanticscholar.org/paper/45d45687ebca6281d44e477cd012a1ef48ebf286",
      "venue": "IEEE International Conference on Robotics and Automation",
      "year": 2016,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "45d45687ebca6281d44e477cd012a1ef48ebf286"
      ],
      "path_length": 1.4856273981463097,
      "pos": [
        -17.489789146209283,
        79.5837115982848
      ]
    },
    "405bf4eb5af09ddad173ac02f9035c4876e8a3c9": {
      "abstract": "This manuscript conduct a deep routed survey of various existing fruit recognition system (FRS) for identifying different variety of fruits. From extensive survey it is seen the existing model does not perform well when color intensity and fruit size varies. Thus, it is important build an efficient feature extraction model to build a good training descriptor. Thus, this paper extract the fruit shape and color for establishing each fruit feature set. Our model is consisted of following phases, pre-processing (PP) phase, feature extraction (FE) phase, and testing phase. In PP stage, the image is resized. In FE stage, color, shape features, and scale invariant feature transform is used to build feature vector for each fruit variety. Then, in testing phase, we use K-Nearest Neighborhood classification algorithm to identify fruits. Our model can automatically recognize fruit along with calorie it can offer.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "72819789"
          ],
          "name": "Pavan N. Kunchur"
        },
        {
          "ids": [
            "9867186"
          ],
          "name": "V. Pandurangi"
        },
        {
          "ids": [
            "1492125870"
          ],
          "name": "Madhu Hollikeri"
        }
      ],
      "corpusid": 211119285,
      "doi": "10.1109/ICAIT47043.2019.8987358",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 211119285,
        "DBLP": null,
        "DOI": "10.1109/ICAIT47043.2019.8987358",
        "MAG": "3005882720",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science"
      ],
      "id": "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "isOpenAccess": false,
      "journalName": "2019 1st International Conference on Advances in Information Technology (ICAIT)",
      "journalPages": "277-281",
      "journalVolume": null,
      "magId": "3005882720",
      "number_of_authors": 3,
      "paperId": "405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2019-07-01",
      "publicationTypes": [
        "Conference",
        "Review"
      ],
      "title": "Building Efficient Fruit Detection Model",
      "tldr": null,
      "url": "https://www.semanticscholar.org/paper/405bf4eb5af09ddad173ac02f9035c4876e8a3c9",
      "venue": "2019 1st International Conference on Advances in Information Technology (ICAIT)",
      "year": 2019,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "405bf4eb5af09ddad173ac02f9035c4876e8a3c9"
      ],
      "path_length": 3.169446174824272,
      "pos": [
        -182.5616907501299,
        138.16064916378608
      ]
    },
    "b6946370d6c13d562b96e42d494817c7d1969a8f": {
      "abstract": "S2 TL;DR: This thesis surveys an array of techniques and parameter settings in order to further optimize bounding-box regression and provide guidance for its implementation and refute a claim regarding training procedure, and demonstrate the effectiveness of using principal component analysis to handle unwieldy numbers of features produced by very deep CNNs.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "72081157"
          ],
          "name": "Naomi Lynn Dickerson"
        }
      ],
      "corpusid": 13662463,
      "doi": "10.15760/ETD.5824",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 13662463,
        "DBLP": null,
        "DOI": "10.15760/ETD.5824",
        "MAG": "2767890894",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "isOpenAccess": true,
      "journalName": "",
      "journalPages": null,
      "journalVolume": "",
      "magId": "2767890894",
      "number_of_authors": 1,
      "paperId": "b6946370d6c13d562b96e42d494817c7d1969a8f",
      "pdfUrls": [
        "https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=4949&context=open_access_etds"
      ],
      "pmid": "",
      "publicationDate": null,
      "publicationTypes": [
        "Review"
      ],
      "title": "Refining Bounding-Box Regression for Object Localization",
      "tldr": "This thesis surveys an array of techniques and parameter settings in order to further optimize bounding-box regression and provide guidance for its implementation and refute a claim regarding training procedure, and demonstrate the effectiveness of using principal component analysis to handle unwieldy numbers of features produced by very deep CNNs.",
      "url": "https://www.semanticscholar.org/paper/b6946370d6c13d562b96e42d494817c7d1969a8f",
      "venue": "",
      "year": 2017,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "b6946370d6c13d562b96e42d494817c7d1969a8f"
      ],
      "path_length": 4.883707559171131,
      "pos": [
        0.9731890918044144,
        -64.0747993978558
      ]
    },
    "eaa7b6893790279292e9f2fafe48662af8b6ae3d": {
      "abstract": null,
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "49872143"
          ],
          "name": "C. McCool"
        },
        {
          "ids": [
            "1867220"
          ],
          "name": "Inkyu Sa"
        },
        {
          "ids": [
            "1757942"
          ],
          "name": "Feras Dayoub"
        },
        {
          "ids": [
            "2355154"
          ],
          "name": "Christopher F. Lehnert"
        },
        {
          "ids": [
            "2068824789"
          ],
          "name": "Tristan Perez"
        },
        {
          "ids": [
            "1803115"
          ],
          "name": "B. Upcroft"
        }
      ],
      "corpusid": 15499689,
      "doi": "10.1109/ICRA.2016.7487405",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 15499689,
        "DBLP": "conf/icra/McCoolSDLPU16",
        "DOI": "10.1109/ICRA.2016.7487405",
        "MAG": "2409375369",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering"
      ],
      "id": "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      "isOpenAccess": true,
      "journalName": "2016 IEEE International Conference on Robotics and Automation (ICRA)",
      "journalPages": "2506-2512",
      "journalVolume": null,
      "magId": "2409375369",
      "number_of_authors": 6,
      "paperId": "eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      "pdfUrls": [
        "https://eprints.qut.edu.au/94274/1/ICRA16_2174_FI.pdf"
      ],
      "pmid": "",
      "publicationDate": "2016-05-16",
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ],
      "title": "Visual detection of occluded crop: For automated harvesting",
      "tldr": null,
      "url": "https://www.semanticscholar.org/paper/eaa7b6893790279292e9f2fafe48662af8b6ae3d",
      "venue": "IEEE International Conference on Robotics and Automation",
      "year": 2016,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "eaa7b6893790279292e9f2fafe48662af8b6ae3d"
      ],
      "path_length": 2.4110612321798905,
      "pos": [
        -75.60483665456937,
        173.38048028743918
      ]
    },
    "938ed8b290dcc01acfacf3533477e404f1d19c23": {
      "abstract": "Detection of images or objects in motion have been highly worked upon, and the detection has been incorporated, required and utilized in applications. A few of the limitations include the lack of computational resources, lack of strategic and methodological data analysis of the observed trained data. The accuracy of detection is dependent on movement, velocity of the objects and Illuminacy. Therefore, it is required that new techniques and strategies of detection are drafted, applied and recognized. In this work, we have worked upon a model based on scalable object detection, using Deep Neural Networks to localize and track people, cars, potted plants and other categories in the camera preview in real-time. The trained model from google inception model has been implemented in an android application. This integrated application works real-time and can be used handy in a mobile phone or any other smart device with minimal computational resources.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "150036694"
          ],
          "name": "Ameema Zainab"
        },
        {
          "ids": [
            "3465161"
          ],
          "name": "Dabeeruddin Syed"
        }
      ],
      "corpusid": 218597086,
      "doi": "10.1109/ICIoT48696.2020.9089651",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 218597086,
        "DBLP": "conf/iciot3/ZainabS20",
        "DOI": "10.1109/ICIoT48696.2020.9089651",
        "MAG": "3024981193",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "id": "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "isOpenAccess": false,
      "journalName": "2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT)",
      "journalPages": "73-78",
      "journalVolume": null,
      "magId": "3024981193",
      "number_of_authors": 2,
      "paperId": "938ed8b290dcc01acfacf3533477e404f1d19c23",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2020-02-01",
      "publicationTypes": [
        "JournalArticle",
        "Conference",
        "Review"
      ],
      "title": "Deployment of Deep Learning Models on Resource-Deficient Devices for Object Detection",
      "tldr": null,
      "url": "https://www.semanticscholar.org/paper/938ed8b290dcc01acfacf3533477e404f1d19c23",
      "venue": "International Conference on Informatics, IoT, and Enabling Technologies",
      "year": 2020,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "938ed8b290dcc01acfacf3533477e404f1d19c23"
      ],
      "path_length": 4.1436052628719615,
      "pos": [
        106.57246319310428,
        18.317645886592363
      ]
    },
    "365b31515028f2c7444d5b5afd865d242b229bd2": {
      "abstract": "S2 TL;DR: A fully convolutional network (FCN) model for classification and detection of tunnel lining defects, inspired by the state\u2010of\u2010the\u2010art deep learning, is proposed and shown to be very fast and efficient.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "31967811"
          ],
          "name": "Ya-dong Xue"
        },
        {
          "ids": [
            "2155180560"
          ],
          "name": "Yicheng Li"
        }
      ],
      "corpusid": 52070480,
      "doi": "10.1111/mice.12367",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 52070480,
        "DBLP": "journals/cacie/XueL18",
        "DOI": "10.1111/mice.12367",
        "MAG": "2801439730",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "id": "365b31515028f2c7444d5b5afd865d242b229bd2",
      "isOpenAccess": true,
      "journalName": "Computer\u2010Aided Civil and Infrastructure Engineering",
      "journalPages": null,
      "journalVolume": "33",
      "magId": "2801439730",
      "number_of_authors": 2,
      "paperId": "365b31515028f2c7444d5b5afd865d242b229bd2",
      "pdfUrls": [
        "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/mice.12367"
      ],
      "pmid": "",
      "publicationDate": "2018-08-01",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "A Fast Detection Method via Region\u2010Based Fully Convolutional Neural Networks for Shield Tunnel Lining Defects",
      "tldr": "A fully convolutional network (FCN) model for classification and detection of tunnel lining defects, inspired by the state\u2010of\u2010the\u2010art deep learning, is proposed and shown to be very fast and efficient.",
      "url": "https://www.semanticscholar.org/paper/365b31515028f2c7444d5b5afd865d242b229bd2",
      "venue": "Comput. Aided Civ. Infrastructure Eng.",
      "year": 2018,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "365b31515028f2c7444d5b5afd865d242b229bd2"
      ],
      "path_length": 4.931529273987683,
      "pos": [
        152.15778759492417,
        17.712003405677635
      ]
    },
    "b70bc54f360857ba0dbee3d6c85792ac03fae946": {
      "abstract": "S2 TL;DR: The performance of six existing deep learning architectures were compared for the task of detection of mango fruit in images of tree canopies and a new architecture was developed, termed \u2018MangoYOLO\u2019, which outperformed other models in processing of full images, requiring just 70\u00a0ms per image.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "7239856"
          ],
          "name": "A. Koirala"
        },
        {
          "ids": [
            "2011584"
          ],
          "name": "K. Walsh"
        },
        {
          "ids": [
            "2145911384"
          ],
          "name": "Zhenglin Wang"
        },
        {
          "ids": [
            "2059954536"
          ],
          "name": "C. McCarthy"
        }
      ],
      "corpusid": 71146797,
      "doi": "10.1007/s11119-019-09642-0",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 71146797,
        "DBLP": null,
        "DOI": "10.1007/s11119-019-09642-0",
        "MAG": "2920621226",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Mathematics"
      ],
      "id": "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "isOpenAccess": true,
      "journalName": "Precision Agriculture",
      "journalPages": "1-29",
      "journalVolume": "",
      "magId": "2920621226",
      "number_of_authors": 4,
      "paperId": "b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "pdfUrls": [
        "https://link.springer.com/content/pdf/10.1007/s11119-019-09642-0.pdf"
      ],
      "pmid": "",
      "publicationDate": "2019-12-01",
      "publicationTypes": null,
      "title": "Deep learning for real-time fruit detection and orchard fruit load estimation: benchmarking of \u2018MangoYOLO\u2019",
      "tldr": "The performance of six existing deep learning architectures were compared for the task of detection of mango fruit in images of tree canopies and a new architecture was developed, termed \u2018MangoYOLO\u2019, which outperformed other models in processing of full images, requiring just 70\u00a0ms per image.",
      "url": "https://www.semanticscholar.org/paper/b70bc54f360857ba0dbee3d6c85792ac03fae946",
      "venue": "Precision Agriculture",
      "year": 2019,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "b70bc54f360857ba0dbee3d6c85792ac03fae946"
      ],
      "path_length": 3.876914159182338,
      "pos": [
        62.26625427965622,
        -0.1808278659766307
      ]
    },
    "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1": {
      "abstract": "Segmenting pomegranate fruit on the field has many practical uses, including estimating yield, assessing fruit quality, identifying diseases, and optimizing harvest timing. This paper introduces a novel technique for detecting and segmenting pomegranate fruit from images. The proposed approach, named DetSSeg, combines YOLOv5s and UNet-MobileNetV2 models for selective on-field pomegranate fruit segmentation. This approach includes a unique training and inference flow that has significantly improved segmentation accuracy for on-the-field pomegranate images, which are often challenging due to diverse backgrounds, varying lighting conditions, and environmental factors. The proposed approach was evaluated through several case studies, and the results demonstrated a high dice coefficient of 98.18 % for outdoor pomegranate fruit segmentation, outperforming the single deep learning model that achieved a 99.32 % dice coefficient for indoor images but showing a lower accuracy of 87.56 % dice coefficient for on-field pomegranate fruit images. Moreover, the proposed approach outperformed other state-of-the-art segmentation models.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "71771398"
          ],
          "name": "Shubham S. Mane"
        },
        {
          "ids": [
            "2376349497"
          ],
          "name": "Prashant Bartakke"
        },
        {
          "ids": [
            "2222070729"
          ],
          "name": "Tulshidas Bastewad"
        }
      ],
      "corpusid": 268541542,
      "doi": "10.1109/CVMI59935.2023.10464563",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 268541542,
        "DBLP": "conf/cvmi/ManeBB23",
        "DOI": "10.1109/CVMI59935.2023.10464563",
        "MAG": null,
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science"
      ],
      "id": "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "isOpenAccess": false,
      "journalName": "2023 IEEE International Conference on Computer Vision and Machine Intelligence (CVMI)",
      "journalPages": "1-6",
      "journalVolume": null,
      "magId": null,
      "number_of_authors": 3,
      "paperId": "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2023-12-10",
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ],
      "title": "DetSSeg: A Selective On-Field Pomegranate Segmentation Approach",
      "tldr": null,
      "url": "https://www.semanticscholar.org/paper/5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1",
      "venue": "2023 IEEE International Conference on Computer Vision and Machine Intelligence (CVMI)",
      "year": 2023,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1"
      ],
      "path_length": 1.547172683077717,
      "pos": [
        -114.29886465162225,
        -98.50336746176538
      ]
    },
    "ac03e40cc705cbd9270d221eb23cf06460be579e": {
      "abstract": "S2 TL;DR: A review of developments in the rapidly developing field of deep learning is presented, with emphasis on practical aspects for application of deeplearning models for the task of fruit detection and localisation, in support of tree crop load estimation.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "7239856"
          ],
          "name": "A. Koirala"
        },
        {
          "ids": [
            "2011584"
          ],
          "name": "K. Walsh"
        },
        {
          "ids": [
            "2145911384"
          ],
          "name": "Zhenglin Wang"
        },
        {
          "ids": [
            "32869427"
          ],
          "name": "C. McCarthy"
        }
      ],
      "corpusid": 146057651,
      "doi": "10.1016/J.COMPAG.2019.04.017",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 146057651,
        "DBLP": "journals/cea/KoiralaWWM19",
        "DOI": "10.1016/J.COMPAG.2019.04.017",
        "MAG": "2936307272",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science"
      ],
      "id": "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "isOpenAccess": true,
      "journalName": "Comput. Electron. Agric.",
      "journalPages": "219-234",
      "journalVolume": "162",
      "magId": "2936307272",
      "number_of_authors": 4,
      "paperId": "ac03e40cc705cbd9270d221eb23cf06460be579e",
      "pdfUrls": [
        "https://www.sciencedirect.com/science/article/am/pii/S0168169919301164"
      ],
      "pmid": "",
      "publicationDate": "2019-07-01",
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ],
      "title": "Deep learning - Method overview and review of use for fruit detection and yield estimation",
      "tldr": "A review of developments in the rapidly developing field of deep learning is presented, with emphasis on practical aspects for application of deeplearning models for the task of fruit detection and localisation, in support of tree crop load estimation.",
      "url": "https://www.semanticscholar.org/paper/ac03e40cc705cbd9270d221eb23cf06460be579e",
      "venue": "Computers and Electronics in Agriculture",
      "year": 2019,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "ac03e40cc705cbd9270d221eb23cf06460be579e"
      ],
      "path_length": 5.123464044304989,
      "pos": [
        -43.42281606615529,
        -22.032914610035828
      ]
    },
    "d3eb6e57f618cf0830678594efd7e67eec76a898": {
      "abstract": null,
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2110909893"
          ],
          "name": "Steven W. Chen"
        },
        {
          "ids": [
            "9680224"
          ],
          "name": "Shreyas S. Shivakumar"
        },
        {
          "ids": [
            "9683783"
          ],
          "name": "Sandeep Dcunha"
        },
        {
          "ids": [
            "36405105"
          ],
          "name": "J. Das"
        },
        {
          "ids": [
            "150989139"
          ],
          "name": "Edidiong Okon"
        },
        {
          "ids": [
            "2064702575"
          ],
          "name": "Chao Qu"
        },
        {
          "ids": [
            "31589308"
          ],
          "name": "C. J. Taylor"
        },
        {
          "ids": [
            "37956314"
          ],
          "name": "Vijay R. Kumar"
        }
      ],
      "corpusid": 5352148,
      "doi": "10.1109/LRA.2017.2651944",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 5352148,
        "DBLP": "journals/ral/ChenSDDOQT017",
        "DOI": "10.1109/LRA.2017.2651944",
        "MAG": "2578363764",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "d3eb6e57f618cf0830678594efd7e67eec76a898",
      "isOpenAccess": true,
      "journalName": "IEEE Robotics and Automation Letters",
      "journalPages": "781-788",
      "journalVolume": "2",
      "magId": "2578363764",
      "number_of_authors": 8,
      "paperId": "d3eb6e57f618cf0830678594efd7e67eec76a898",
      "pdfUrls": [
        "https://doi.org/10.1109/lra.2017.2651944"
      ],
      "pmid": "",
      "publicationDate": "2017-01-11",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Counting Apples and Oranges With Deep Learning: A Data-Driven Approach",
      "tldr": null,
      "url": "https://www.semanticscholar.org/paper/d3eb6e57f618cf0830678594efd7e67eec76a898",
      "venue": "IEEE Robotics and Automation Letters",
      "year": 2017,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "d3eb6e57f618cf0830678594efd7e67eec76a898"
      ],
      "path_length": 4.096845479070101,
      "pos": [
        -117.46444209613637,
        80.46946687493622
      ]
    },
    "1c8c77afa31d57c45cfbf404231217dc4db17a14": {
      "abstract": "Accurate localization of crop remains highly challenging in unstructured environments, such as farms. Many developed systems still rely on the use of hand selected features for crop identification and often neglect the estimation of crop quantity and ripeness, which is a key to assigning labor during farming processes. To alleviate these limitations, we present a robotic vision system that can accurately estimate the quantity and ripeness of sweet pepper (Capsicum annuum L), a key horticultural crop. This system consists of three parts: detection, ripeness estimation, and tracking. Efficient detection is achieved using the FasterRCNN (FRCNN) framework. Ripeness is then estimated in the same framework by learning a parallel layer which we experimentally show results in superior performance than treating ripeness as extra classes in the traditional FRCNN framework. Evaluation of these two techniques outlines the improved performance of the parallel layer, where we achieve an  $F_1$ score of 77.3 for the parallel technique yet only 72.5 for the best scoring (red) of the multiclass implementation. To track the crop, we present a vision only tracking via detection approach, which uses the FRCNN with parallel layers as input. Being a vision only solution, this approach is cheap to implement as it only requires a camera and in experiments, using field data, we show that our proposed system can accurately estimate the number of sweet pepper present, to within 4.1% of the visual ground truth.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2861522"
          ],
          "name": "Michael Halstead"
        },
        {
          "ids": [
            "49872143"
          ],
          "name": "C. McCool"
        },
        {
          "ids": [
            "1980700"
          ],
          "name": "Simon Denman"
        },
        {
          "ids": [
            "2068824789"
          ],
          "name": "Tristan Perez"
        },
        {
          "ids": [
            "3140440"
          ],
          "name": "C. Fookes"
        }
      ],
      "corpusid": 49654877,
      "doi": "10.1109/LRA.2018.2849514",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 49654877,
        "DBLP": "journals/ral/HalsteadMDPF18",
        "DOI": "10.1109/LRA.2018.2849514",
        "MAG": "2942821311",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering"
      ],
      "id": "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "isOpenAccess": false,
      "journalName": "IEEE Robotics and Automation Letters",
      "journalPages": "2995-3002",
      "journalVolume": "3",
      "magId": "2942821311",
      "number_of_authors": 5,
      "paperId": "1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2018-06-21",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Fruit Quantity and Ripeness Estimation Using a Robotic Vision System",
      "tldr": null,
      "url": "https://www.semanticscholar.org/paper/1c8c77afa31d57c45cfbf404231217dc4db17a14",
      "venue": "IEEE Robotics and Automation Letters",
      "year": 2018,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "1c8c77afa31d57c45cfbf404231217dc4db17a14"
      ],
      "path_length": 2.777893510322868,
      "pos": [
        -87.96666434854974,
        -53.02898143502445
      ]
    },
    "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f": {
      "abstract": "S2 TL;DR: This work is a pioneer to create a multi-labeled and knowledge-based outdoor orchard image library using 4000 images in the real world and improvement of the convolutional and pooling layers is achieved to have a more accurate and faster detection.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "31197849"
          ],
          "name": "Shaohua Wan"
        },
        {
          "ids": [
            "144461881"
          ],
          "name": "Sotirios K Goudos"
        }
      ],
      "corpusid": 210873750,
      "doi": "10.1016/j.comnet.2019.107036",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 210873750,
        "DBLP": "journals/cn/WanG20",
        "DOI": "10.1016/j.comnet.2019.107036",
        "MAG": "2991844793",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering"
      ],
      "id": "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "isOpenAccess": false,
      "journalName": "Comput. Networks",
      "journalPages": null,
      "journalVolume": "168",
      "magId": "2991844793",
      "number_of_authors": 2,
      "paperId": "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2020-02-01",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Faster R-CNN for multi-class fruit detection using a robotic vision system",
      "tldr": "This work is a pioneer to create a multi-labeled and knowledge-based outdoor orchard image library using 4000 images in the real world and improvement of the convolutional and pooling layers is achieved to have a more accurate and faster detection.",
      "url": "https://www.semanticscholar.org/paper/1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f",
      "venue": "Comput. Networks",
      "year": 2020,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f"
      ],
      "path_length": 4.290516992280083,
      "pos": [
        27.172915072295954,
        38.714607974431644
      ]
    },
    "4ef826d8915a1b28980ef883dbd623a8f9bf54f1": {
      "abstract": "This paper presents a novel multi-sensor framework to efficiently identify, track, localise and map every piece of fruit in a commercial mango orchard. A multiple viewpoint approach is used to solve the problem of occlusion, thus avoiding the need for labour-intensive field calibration to estimate actual yield. Fruit are detected in images using a state-of-the-art faster R-CNN detector, and pair-wise correspondences are established between images using trajectory data provided by a navigation system. A novel LiDAR component automatically generates image masks for each canopy, allowing each fruit to be associated with the corresponding tree. The tracked fruit are triangulated to locate them in 3D, enabling a number of spatial statistics per tree, row or orchard block. A total of 522 trees and 71,609 mangoes were scanned on a Calypso mango orchard near Bundaberg, Queensland, Australia, with 16 trees counted by hand for validation, both on the tree and after harvest. The results show that single, dual and multi-view methods can all provide precise yield estimates, but only the proposed multi-view approach can do so without calibration, with an error rate of only 1.36% for individual trees.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "40400516"
          ],
          "name": "M. Stein"
        },
        {
          "ids": [
            "2690856"
          ],
          "name": "Suchet Bargoti"
        },
        {
          "ids": [
            "3319082"
          ],
          "name": "J. Underwood"
        }
      ],
      "corpusid": 4697534,
      "doi": "10.3390/s16111915",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 4697534,
        "DBLP": "journals/sensors/SteinBU16",
        "DOI": "10.3390/s16111915",
        "MAG": "2555576940",
        "PubMed": "27854271",
        "PubMedCentral": "5134574"
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering",
        "Environmental Science",
        "Medicine"
      ],
      "id": "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "isOpenAccess": true,
      "journalName": "Sensors (Basel, Switzerland)",
      "journalPages": null,
      "journalVolume": "16",
      "magId": "2555576940",
      "number_of_authors": 3,
      "paperId": "4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "pdfUrls": [
        "https://www.mdpi.com/1424-8220/16/11/1915/pdf?version=1479197164"
      ],
      "pmid": "27854271",
      "publicationDate": "2016-11-01",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Image Based Mango Fruit Detection, Localisation and Yield Estimation Using Multiple View Geometry",
      "tldr": "A multiple viewpoint approach is used to solve the problem of occlusion, thus avoiding the need for labour-intensive field calibration to estimate actual yield, and the proposed multi-view approach can do so without calibration, with an error rate of only 1.36% for individual trees.",
      "url": "https://www.semanticscholar.org/paper/4ef826d8915a1b28980ef883dbd623a8f9bf54f1",
      "venue": "Italian National Conference on Sensors",
      "year": 2016,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "4ef826d8915a1b28980ef883dbd623a8f9bf54f1"
      ],
      "path_length": 3.496712478041394,
      "pos": [
        -70.51594645681288,
        49.036556333628404
      ]
    },
    "663a60841c3e703d7c18cf78f0657efee6aebb9d": {
      "abstract": null,
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2272787306"
          ],
          "name": "Zhiqiang Wang"
        },
        {
          "ids": [
            "2100546995"
          ],
          "name": "Liu Jun"
        }
      ],
      "corpusid": 13021171,
      "doi": "10.23919/CHICC.2017.8029130",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 13021171,
        "DBLP": null,
        "DOI": "10.23919/CHICC.2017.8029130",
        "MAG": "2755118520",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "isOpenAccess": false,
      "journalName": "2017 36th Chinese Control Conference (CCC)",
      "journalPages": "11104-11109",
      "journalVolume": null,
      "magId": "2755118520",
      "number_of_authors": 2,
      "paperId": "663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2017-07-26",
      "publicationTypes": [
        "Conference",
        "Review"
      ],
      "title": "A review of object detection based on convolutional neural network",
      "tldr": null,
      "url": "https://www.semanticscholar.org/paper/663a60841c3e703d7c18cf78f0657efee6aebb9d",
      "venue": "Cybersecurity and Cyberforensics Conference",
      "year": 2017,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "663a60841c3e703d7c18cf78f0657efee6aebb9d"
      ],
      "path_length": 4.238315712819225,
      "pos": [
        135.45663801349338,
        -94.96095655266177
      ]
    },
    "c2eaffc617c57ab5106ba3bc95b7b910be473389": {
      "abstract": "S2 TL;DR: Various techniques and their advantages and disadvantages in detecting fruit in plant or tree canopies are summarized and the sensors and systems developed and used by researchers to localize fruit are summarized.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "3365825"
          ],
          "name": "Aleana Gongal"
        },
        {
          "ids": [
            "32180738"
          ],
          "name": "Suraj Amatya"
        },
        {
          "ids": [
            "2872408"
          ],
          "name": "M. Karkee"
        },
        {
          "ids": [
            "46324711"
          ],
          "name": "Qin Zhang"
        },
        {
          "ids": [
            "143760166"
          ],
          "name": "Karen Lewis"
        }
      ],
      "corpusid": 2667595,
      "doi": "10.1016/J.COMPAG.2015.05.021",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 2667595,
        "DBLP": "journals/cea/GongalAKZL15",
        "DOI": "10.1016/J.COMPAG.2015.05.021",
        "MAG": "2396098103",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering",
        "Environmental Science"
      ],
      "id": "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      "isOpenAccess": false,
      "journalName": "Comput. Electron. Agric.",
      "journalPages": "8-19",
      "journalVolume": "116",
      "magId": "2396098103",
      "number_of_authors": 5,
      "paperId": "c2eaffc617c57ab5106ba3bc95b7b910be473389",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2015-08-01",
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ],
      "title": "Sensors and systems for fruit detection and localization: A review",
      "tldr": "Various techniques and their advantages and disadvantages in detecting fruit in plant or tree canopies are summarized and the sensors and systems developed and used by researchers to localize fruit are summarized.",
      "url": "https://www.semanticscholar.org/paper/c2eaffc617c57ab5106ba3bc95b7b910be473389",
      "venue": "Computers and Electronics in Agriculture",
      "year": 2015,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "c2eaffc617c57ab5106ba3bc95b7b910be473389"
      ],
      "path_length": 3.709960128410297,
      "pos": [
        -182.49065551883862,
        64.92417570653184
      ]
    },
    "7e1e9488e65ad2f9d9171ebac959969b1ca19188": {
      "abstract": "Accurate localisation of crop remains highly challenging in unstructured environments such as farms. Many of the developed systems still rely on the use of hand selected features for crop identification and often neglect the estimation of crop quantity and quality, which is key to assigning labor during farming processes. To alleviate these limitations we present a robotic vision system that can accurately estimate the quantity and quality of sweet pepper (Capsicum annuum L), a key horticultural crop. This system consists of three parts: detection, quality estimation, and tracking. Efficient detection is achieved using the FasterRCNN framework. Quality is then estimated in the same framework by learning a parallel layer which we show experimentally results in superior performance than treating quality as extra classes in the traditional Faster-RCNN framework. Evaluation of these two techniques outlines the improved performance of the parallel layer, where we achieve an F1 score of 77.3 for the parallel technique yet only 72.5 for the best scoring (red) of the multi-class implementation. To track the crop we present a tracking via detection approach, which uses the FasterRCNN with parallel layers, that is also a vision-only solution. This approach is cheap to implement as it only requires a camera and in experiments across 2 days we show that our proposed system can accurately estimate the number of sweet pepper present, within 4.1% of the ground truth.",
      "arxivId": "1801.05560",
      "authors": [
        {
          "ids": [
            "2861522"
          ],
          "name": "Michael Halstead"
        },
        {
          "ids": [
            "49872143"
          ],
          "name": "C. McCool"
        },
        {
          "ids": [
            "1980700"
          ],
          "name": "Simon Denman"
        },
        {
          "ids": [
            "2068824789"
          ],
          "name": "Tristan Perez"
        },
        {
          "ids": [
            "3140440"
          ],
          "name": "C. Fookes"
        }
      ],
      "corpusid": 12891543,
      "doi": "",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1801.05560",
        "CorpusId": 12891543,
        "DBLP": "journals/corr/abs-1801-05560",
        "DOI": null,
        "MAG": "2783864900",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering"
      ],
      "id": "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "isOpenAccess": false,
      "journalName": "ArXiv",
      "journalPages": null,
      "journalVolume": "abs/1801.05560",
      "magId": "2783864900",
      "number_of_authors": 5,
      "paperId": "7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2018-01-17",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Fruit Quantity and Quality Estimation using a Robotic Vision System",
      "tldr": "This work presents a robotic vision system that can accurately estimate the quantity and quality of sweet pepper, a key horticultural crop, and presents a tracking via detection approach, which uses the FasterRCNN with parallel layers, that is also a vision-only solution.",
      "url": "https://www.semanticscholar.org/paper/7e1e9488e65ad2f9d9171ebac959969b1ca19188",
      "venue": "arXiv.org",
      "year": 2018,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "1c8c77afa31d57c45cfbf404231217dc4db17a14",
        "7e1e9488e65ad2f9d9171ebac959969b1ca19188"
      ],
      "path_length": 3.799491181648799,
      "pos": [
        -67.76165175459921,
        102.3229500450342
      ]
    },
    "a08767952d56b006deecb75488a6c5ce5c8aa16d": {
      "abstract": "S2 TL;DR: The automation technology used in harvesting the yellow bell pepper makes use of open source computer vision platform to detect the crop amidst the foliage using various image processing techniques and send appropriate signals to move the robot to harvest the crop.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2109543859"
          ],
          "name": "Silpa Ajith Kumar"
        },
        {
          "ids": [
            "144117323"
          ],
          "name": "J. S. Kumar"
        }
      ],
      "corpusid": 212581359,
      "doi": "",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 212581359,
        "DBLP": null,
        "DOI": null,
        "MAG": null,
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering"
      ],
      "id": "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "isOpenAccess": false,
      "journalName": null,
      "journalPages": null,
      "journalVolume": null,
      "magId": null,
      "number_of_authors": 2,
      "paperId": "a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": null,
      "publicationTypes": null,
      "title": "Automated Bell Pepper Harvesting using Robotic Vision System",
      "tldr": "The automation technology used in harvesting the yellow bell pepper makes use of open source computer vision platform to detect the crop amidst the foliage using various image processing techniques and send appropriate signals to move the robot to harvest the crop.",
      "url": "https://www.semanticscholar.org/paper/a08767952d56b006deecb75488a6c5ce5c8aa16d",
      "venue": "",
      "year": 2019,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a08767952d56b006deecb75488a6c5ce5c8aa16d"
      ],
      "path_length": 1.3000950974449854,
      "pos": [
        29.443335728955326,
        96.09619023803862
      ]
    },
    "51579a8a40aea8dc6b9cdea9499dc27c2797499d": {
      "abstract": "Recent years have witnessed significant advancement in computer vision research based on deep learning. Success of these tasks largely depends on the availability of a large amount of training samples. Labeling the training samples is an expensive process. In this paper, we present a simulated deep convolutional neural network for yield estimation. Knowing the exact number of fruits, flowers, and trees helps farmers to make better decisions on cultivation practices, plant disease prevention, and the size of harvest labor force. The current practice of yield estimation based on the manual counting of fruits or flowers by workers is a very time consuming and expensive process and it is not practical for big fields. Automatic yield estimation based on robotic agriculture provides a viable solution in this regard. Our network is trained entirely on synthetic data and tested on real data. To capture features on multiple scales, we used a modified version of the Inception-ResNet architecture. Our algorithm counts efficiently even if fruits are under shadow, occluded by foliage, branches, or if there is some degree of overlap amongst fruits. Experimental results show a 91% average test accuracy on real images and 93% on synthetic images.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2394165882"
          ],
          "name": "Maryam Rahnemoonfar"
        },
        {
          "ids": [
            "35194161"
          ],
          "name": "Clay Sheppard"
        }
      ],
      "corpusid": 20299776,
      "doi": "10.3390/s17040905",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 20299776,
        "DBLP": "journals/sensors/RahnemoonfarS17",
        "DOI": "10.3390/s17040905",
        "MAG": "2611227133",
        "PubMed": "28425947",
        "PubMedCentral": "5426829"
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering",
        "Medicine"
      ],
      "id": "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "isOpenAccess": true,
      "journalName": "Sensors (Basel, Switzerland)",
      "journalPages": null,
      "journalVolume": "17",
      "magId": "2611227133",
      "number_of_authors": 2,
      "paperId": "51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "pdfUrls": [
        "https://www.mdpi.com/1424-8220/17/4/905/pdf?version=1492689357"
      ],
      "pmid": "28425947",
      "publicationDate": "2017-04-01",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Deep Count: Fruit Counting Based on Deep Simulated Learning",
      "tldr": "A simulated deep convolutional neural network for yield estimation based on robotic agriculture that counts efficiently even if fruits are under shadow, occluded by foliage, branches, or if there is some degree of overlap amongst fruits.",
      "url": "https://www.semanticscholar.org/paper/51579a8a40aea8dc6b9cdea9499dc27c2797499d",
      "venue": "Italian National Conference on Sensors",
      "year": 2017,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "51579a8a40aea8dc6b9cdea9499dc27c2797499d"
      ],
      "path_length": 3.0154496649518125,
      "pos": [
        62.04958748367295,
        136.4547559069064
      ]
    },
    "8352826ff8f12ded684bf07540341a5ef6da06fd": {
      "abstract": "S2 TL;DR: The aim is to build an accurate, fast and reliable fruit detection system using machine learning facts and the proposed system has applied convolutional neural network (CNN) to the tasks of detecting fruit images.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2083813030"
          ],
          "name": "Fouzia Risdin"
        },
        {
          "ids": [
            "33279069"
          ],
          "name": "P. Mondal"
        },
        {
          "ids": [
            "1452348685"
          ],
          "name": "Kazi Mahmudul Hassan"
        }
      ],
      "corpusid": 215797273,
      "doi": "",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 215797273,
        "DBLP": null,
        "DOI": null,
        "MAG": null,
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science"
      ],
      "id": "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "isOpenAccess": false,
      "journalName": null,
      "journalPages": null,
      "journalVolume": null,
      "magId": null,
      "number_of_authors": 3,
      "paperId": "8352826ff8f12ded684bf07540341a5ef6da06fd",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": null,
      "publicationTypes": null,
      "title": "Convolutional Neural Networks (CNN) for Detecting Fruit Information Using Machine Learning Techniques",
      "tldr": "The aim is to build an accurate, fast and reliable fruit detection system using machine learning facts and the proposed system has applied convolutional neural network (CNN) to the tasks of detecting fruit images.",
      "url": "https://www.semanticscholar.org/paper/8352826ff8f12ded684bf07540341a5ef6da06fd",
      "venue": "",
      "year": 2020,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "8352826ff8f12ded684bf07540341a5ef6da06fd"
      ],
      "path_length": 1.4398907477773968,
      "pos": [
        -141.4885045589095,
        -55.77385936151762
      ]
    },
    "b95191e4672475b32d0a4c571bd2817659747dca": {
      "abstract": "Ground vehicles equipped with monocular vision systems are a valuable source of high\u2010resolution image data for precision agriculture applications in orchards. This paper presents an image processing framework for fruit detection and counting using orchard image data. A general\u2010purpose image segmentation approach is used, including two feature learning algorithms; multiscale multilayered perceptrons (MLP) and convolutional neural networks (CNN). These networks were extended by including contextual information about how the image data was captured (metadata), which correlates with some of the appearance variations and/or class distributions observed in the data. The pixel\u2010wise fruit segmentation output is processed using the watershed segmentation (WS) and circular Hough transform (CHT) algorithms to detect and count individual fruits. Experiments were conducted in a commercial apple orchard near Melbourne, Australia. The results show an improvement in fruit segmentation performance with the inclusion of metadata on the previously benchmarked MLP network. We extend this work with CNNs, bringing agrovision closer to the state\u2010of\u2010the\u2010art in computer vision, where although metadata had negligible influence, the best pixel\u2010wise F1\u2010score of 0.791 was achieved. The WS algorithm produced the best apple detection and counting results, with a detection F1\u2010score of 0.861. As a final step, image fruit counts were accumulated over multiple rows at the orchard and compared against the post\u2010harvest fruit counts that were obtained from a grading and counting machine. The count estimates using CNN and WS resulted in the best performance for this data set, with a squared correlation coefficient of r2=0.826 .",
      "arxivId": "1610.08120",
      "authors": [
        {
          "ids": [
            "2690856"
          ],
          "name": "Suchet Bargoti"
        },
        {
          "ids": [
            "3319082"
          ],
          "name": "J. Underwood"
        }
      ],
      "corpusid": 7524678,
      "doi": "10.1002/rob.21699",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1610.08120",
        "CorpusId": 7524678,
        "DBLP": "journals/jfr/BargotiU17",
        "DOI": "10.1002/rob.21699",
        "MAG": "2952751307",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering"
      ],
      "id": "b95191e4672475b32d0a4c571bd2817659747dca",
      "isOpenAccess": true,
      "journalName": "Journal of Field Robotics",
      "journalPages": null,
      "journalVolume": "34",
      "magId": "2952751307",
      "number_of_authors": 2,
      "paperId": "b95191e4672475b32d0a4c571bd2817659747dca",
      "pdfUrls": [
        "https://arxiv.org/pdf/1610.08120"
      ],
      "pmid": "",
      "publicationDate": "2016-10-25",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Image Segmentation for Fruit Detection and Yield Estimation in Apple Orchards",
      "tldr": "An image processing framework for fruit detection and counting using orchard image data is presented, bringing agrovision closer to the state\u2010of\u2010the\u2010art in computer vision, where although metadata had negligible influence, the best pixel\u2010wise F1\u2010score of 0.791 was achieved.",
      "url": "https://www.semanticscholar.org/paper/b95191e4672475b32d0a4c571bd2817659747dca",
      "venue": "J. Field Robotics",
      "year": 2016,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "b95191e4672475b32d0a4c571bd2817659747dca"
      ],
      "path_length": 2.6790367613564774,
      "pos": [
        -126.52262658960947,
        31.42211954523641
      ]
    },
    "a598e30cce3902fafa5c2692e2ad68437339b383": {
      "abstract": "S2 TL;DR: The proposed method uses MangoNet, a deep convolutional neural network based architecture for mango detection using semantic segmentation, which demonstrates the robustness of detection for a multitude of factors such as scale, occlusion, distance and illumination conditions, characteristic to open field conditions.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "67336383"
          ],
          "name": "Ramesh Kestur"
        },
        {
          "ids": [
            "66173522"
          ],
          "name": "Avadesh Meduri"
        },
        {
          "ids": [
            "66681267"
          ],
          "name": "Omkar Narasipura"
        }
      ],
      "corpusid": 57663962,
      "doi": "10.1016/j.engappai.2018.09.011",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 57663962,
        "DBLP": "journals/eaai/KesturMN19",
        "DOI": "10.1016/j.engappai.2018.09.011",
        "MAG": "2896971046",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Environmental Science"
      ],
      "id": "a598e30cce3902fafa5c2692e2ad68437339b383",
      "isOpenAccess": false,
      "journalName": "Eng. Appl. Artif. Intell.",
      "journalPages": "59-69",
      "journalVolume": "77",
      "magId": "2896971046",
      "number_of_authors": 3,
      "paperId": "a598e30cce3902fafa5c2692e2ad68437339b383",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": null,
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "MangoNet: A deep semantic segmentation architecture for a method to detect and count mangoes in an open orchard",
      "tldr": "The proposed method uses MangoNet, a deep convolutional neural network based architecture for mango detection using semantic segmentation, which demonstrates the robustness of detection for a multitude of factors such as scale, occlusion, distance and illumination conditions, characteristic to open field conditions.",
      "url": "https://www.semanticscholar.org/paper/a598e30cce3902fafa5c2692e2ad68437339b383",
      "venue": "Engineering applications of artificial intelligence",
      "year": 2019,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "45d45687ebca6281d44e477cd012a1ef48ebf286",
        "a598e30cce3902fafa5c2692e2ad68437339b383"
      ],
      "path_length": 4.268866020496522,
      "pos": [
        14.532365140577308,
        152.28132835592953
      ]
    },
    "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81": {
      "abstract": "Accurate detection and recognition of various kinds of fruits and vegetables by using the artificial intelligence (AI) approach always remain a challenging task due to similarity between various types of fruits and challenging environments such as lighting and background variations. Therefore, developing and exploring an expert system for automatic fruits' recognition is getting more and more important after many successful approaches; however, this technology is still far from being mature. The deep learning-based models have emerged as state-of-the-art techniques for image segmentation and classification and have a lot of promise in challenging domains such as agriculture, where they can deal with the large variability in data better than classical computer vision methods. In this study, we proposed a deep learning-based framework to detect and recognize fruits and vegetables automatically with difficult real-world scenarios. The proposed method might be helpful for the fruit sellers to identify and differentiate various kinds of fruits and vegetables that have similarities. The proposed method has applied deep convolutional neural network (DCNN) to the undertakings of distinguishing natural fruit images of the Gilgit-Baltistan (GB) region as this area is famous for fruits' production in Pakistan as well as in the world. The experimental outcomes demonstrate that the suggested deep learning algorithm has the effective capability of automatically recognizing the fruit with high accuracy of 96%. This high accuracy exhibits that the proposed approach can meet world application requirements.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2347559223"
          ],
          "name": "Dostdar Hussain"
        },
        {
          "ids": [
            "2065353672"
          ],
          "name": "I. Hussain"
        },
        {
          "ids": [
            "1381707828"
          ],
          "name": "Muhammad Ismail"
        },
        {
          "ids": [
            "2890322"
          ],
          "name": "Amerah A. Alabrah"
        },
        {
          "ids": [
            "1733087752"
          ],
          "name": "Syed Sajid Ullah"
        },
        {
          "ids": [
            "2155920423"
          ],
          "name": "Hayat Mansoor Alaghbari"
        }
      ],
      "corpusid": 247063868,
      "doi": "10.1155/2022/6538117",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 247063868,
        "DBLP": null,
        "DOI": "10.1155/2022/6538117",
        "MAG": null,
        "PubMed": "35237311",
        "PubMedCentral": "8885238"
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Medicine"
      ],
      "id": "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      "isOpenAccess": true,
      "journalName": "Computational Intelligence and Neuroscience",
      "journalPages": null,
      "journalVolume": "2022",
      "magId": null,
      "number_of_authors": 6,
      "paperId": "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      "pdfUrls": [
        "https://downloads.hindawi.com/journals/cin/2022/6538117.pdf"
      ],
      "pmid": "35237311",
      "publicationDate": "2022-02-21",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "A Simple and Efficient Deep Learning-Based Framework for Automatic Fruit Recognition",
      "tldr": "A deep learning-based framework to detect and recognize fruits and vegetables automatically with difficult real-world scenarios is proposed and has the effective capability of automatically recognizing the fruit with high accuracy of 96%.",
      "url": "https://www.semanticscholar.org/paper/e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81",
      "venue": "Computational Intelligence and Neuroscience",
      "year": 2022,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "a08767952d56b006deecb75488a6c5ce5c8aa16d",
        "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81"
      ],
      "path_length": 4.3884114132014425,
      "pos": [
        -27.76379004063424,
        132.88807660746753
      ]
    },
    "0d44970499a233c3be99995f615a91980becf3d4": {
      "abstract": "Fruit classification is playing a vital role in robot-based farming. The plucking of fruits and packing is done using robots nowadays. This could only be possible using efficiently trained robots base on machine learning. Different techniques have been developed for fruit classification, but still, there are many gaps, i.e., efficiency and accuracy. In this research work, we are targeting classification accuracy. This paper presented an Automatic Fruit Detection tool with good precision and recalled using deep learning neural networks. It will help in farming, cultivation, and produce sound effects in robotic farming. The aim is to build an accurate, fast and reliable fruit detection system, a vital element of an autonomous agricultural robotic platform; it is a crucial element for fruit yield estimation and automated harvesting. We used the ResNet-50 in the context of transfer learning. Different training choices were defined, i.e., 10% to 80%. Experimental results show that we compete for the prior approaches even on only 10% training. The proposed approach achieves state-of-the-art results compared to prior work with the F1 Score, which considers both precision and recall performances improving from 0.838 to 0.894 and 0.995 of accuracy. In addition to improved accuracy, this approach is also much quicker as compared to recent approaches.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "2092370011"
          ],
          "name": "Khadija Munir"
        },
        {
          "ids": [
            "2287708"
          ],
          "name": "A. I. Umar"
        },
        {
          "ids": [
            "1490939863"
          ],
          "name": "Waqas Yousaf"
        }
      ],
      "corpusid": 234546908,
      "doi": "10.24949/NJES.V13I1.501",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 234546908,
        "DBLP": null,
        "DOI": "10.24949/NJES.V13I1.501",
        "MAG": "3146547654",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Agricultural and Food Sciences",
        "Computer Science",
        "Engineering"
      ],
      "id": "0d44970499a233c3be99995f615a91980becf3d4",
      "isOpenAccess": true,
      "journalName": "NUST Journal of Engineering Sciences",
      "journalPages": null,
      "journalVolume": null,
      "magId": "3146547654",
      "number_of_authors": 3,
      "paperId": "0d44970499a233c3be99995f615a91980becf3d4",
      "pdfUrls": [
        "https://journals.nust.edu.pk/index.php/njes/article/download/501/136"
      ],
      "pmid": "",
      "publicationDate": "2020-12-01",
      "publicationTypes": null,
      "title": "Automatic Fruits Classification System Based on Deep Neural Network",
      "tldr": "The aim is to build an accurate, fast and reliable fruit detection system, a vital element of an autonomous agricultural robotic platform; it is a crucial element for fruit yield estimation and automated harvesting.",
      "url": "https://www.semanticscholar.org/paper/0d44970499a233c3be99995f615a91980becf3d4",
      "venue": "NUST Journal of engineering sciences",
      "year": 2020,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "0d44970499a233c3be99995f615a91980becf3d4"
      ],
      "path_length": 1.3795267027628146,
      "pos": [
        -151.65659456833728,
        -9.651808907065005
      ]
    },
    "3bb4c3127c77ffb06a81cfe09862716a0828114c": {
      "abstract": "Convolutional neural network (CNN) based methods have achieved great success in image classification and object detection tasks. However, unlike the image classification task, object detection is much more computation-intensive and energy-consuming since a large number of possible object proposals need to be evaluated. Consequently, it is difficult for object detection methods to be integrated into embedded systems with limited computing resources and energy supply. In this paper, we propose a pipelined object detection implementation on the embedded platform. We present a comprehensive analysis of state-of-the-art object detection algorithms and select Fast R-CNN as a possible solution. Additional modifications on the Fast R-CNN method are made to fit the specific platform and achieve trade-off between speed and accuracy on embedded systems. Finally, a multi-stage pipelined implementation on the embedded CPU<inline-formula><tex-math notation=\"LaTeX\">$+$</tex-math><alternatives> <inline-graphic xlink:href=\"mao-ieq1-2593643.gif\"/></alternatives></inline-formula>GPU platform with duplicated module-parallelism is proposed to make full use of the limited computation resources. The proposed system is highly energy-efficient and close to real-time performance. In the first Low-Power Image Recognition Challenge (LPIRC), our system achieved the best result with mAP/Energy of 1.818e-2/(W<inline-formula><tex-math notation=\"LaTeX\">$\\cdot$ </tex-math><alternatives><inline-graphic xlink:href=\"mao-ieq2-2593643.gif\"/></alternatives></inline-formula>h) on the embedded Jetson TK1 CPU<inline-formula><tex-math notation=\"LaTeX\">$+$</tex-math><alternatives> <inline-graphic xlink:href=\"mao-ieq3-2593643.gif\"/></alternatives></inline-formula>GPU platform.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "3123774"
          ],
          "name": "Huizi Mao"
        },
        {
          "ids": [
            "2067824417"
          ],
          "name": "Song Yao"
        },
        {
          "ids": [
            "2150320841"
          ],
          "name": "Tianqi Tang"
        },
        {
          "ids": [
            "2789329"
          ],
          "name": "Boxun Li"
        },
        {
          "ids": [
            "2109803248"
          ],
          "name": "Jun Yao"
        },
        {
          "ids": [
            "40987227"
          ],
          "name": "Yu Wang"
        }
      ],
      "corpusid": 52162690,
      "doi": "10.1109/TETC.2016.2593643",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 52162690,
        "DBLP": "journals/tetc/MaoYTLYW18",
        "DOI": "10.1109/TETC.2016.2593643",
        "MAG": "2515751428",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "id": "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "isOpenAccess": false,
      "journalName": "IEEE Transactions on Emerging Topics in Computing",
      "journalPages": "417-431",
      "journalVolume": "6",
      "magId": "2515751428",
      "number_of_authors": 6,
      "paperId": "3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": "2018-07-01",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Towards Real-Time Object Detection on Embedded Systems",
      "tldr": null,
      "url": "https://www.semanticscholar.org/paper/3bb4c3127c77ffb06a81cfe09862716a0828114c",
      "venue": "IEEE Transactions on Emerging Topics in Computing",
      "year": 2018,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "3bb4c3127c77ffb06a81cfe09862716a0828114c"
      ],
      "path_length": 4.350815616063446,
      "pos": [
        94.0256905539232,
        -136.05364429563056
      ]
    },
    "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9": {
      "abstract": "We present RON, an efficient and effective framework for generic object detection. Our motivation is to smartly associate the best of the region-based (e.g., Faster R-CNN) and region-free (e.g., SSD) methodologies. Under fully convolutional architecture, RON mainly focuses on two fundamental problems: (a) multi-scale object localization and (b) negative sample mining. To address (a), we design the reverse connection, which enables the network to detect objects on multi-levels of CNNs. To deal with (b), we propose the objectness prior to significantly reduce the searching space of objects. We optimize the reverse connection, objectness prior and object detector jointly by a multi-task loss function, thus RON can directly predict final detection results from all locations of various feature maps. Extensive experiments on the challenging PASCAL VOC 2007, PASCAL VOC 2012 and MS COCO benchmarks demonstrate the competitive performance of RON. Specifically, with VGG-16 and low resolution 384&#xd7;384 input size, the network gets 81.3% mAP on PASCAL VOC 2007, 80.7% mAP on PASCAL VOC 2012 datasets. Its superiority increases when datasets become larger and more difficult, as demonstrated by the results on the MS COCO dataset. With 1.5G GPU memory at test phase, the speed of the network is 15 FPS, 3 times faster than the Faster R-CNN counterpart. Code will be made publicly available.",
      "arxivId": "1707.01691",
      "authors": [
        {
          "ids": [
            "145868988"
          ],
          "name": "Tao Kong"
        },
        {
          "ids": [
            "143823065"
          ],
          "name": "F. Sun"
        },
        {
          "ids": [
            "2021251"
          ],
          "name": "Anbang Yao"
        },
        {
          "ids": [
            "145433219"
          ],
          "name": "Huaping Liu"
        },
        {
          "ids": [
            "123554573"
          ],
          "name": "Ming Lu"
        },
        {
          "ids": [
            "2109184871"
          ],
          "name": "Yurong Chen"
        }
      ],
      "corpusid": 25687156,
      "doi": "10.1109/CVPR.2017.557",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1707.01691",
        "CorpusId": 25687156,
        "DBLP": "conf/cvpr/KongSYLLC17",
        "DOI": "10.1109/CVPR.2017.557",
        "MAG": "2962917547",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "isOpenAccess": true,
      "journalName": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
      "journalPages": "5244-5252",
      "journalVolume": null,
      "magId": "2962917547",
      "number_of_authors": 6,
      "paperId": "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "pdfUrls": [
        "http://arxiv.org/pdf/1707.01691"
      ],
      "pmid": "",
      "publicationDate": "2017-07-06",
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ],
      "title": "RON: Reverse Connection with Objectness Prior Networks for Object Detection",
      "tldr": "This work designs the reverse connection, objectness prior and object detector jointly by a multi-task loss function, thus RON can directly predict final detection results from all locations of various feature maps.",
      "url": "https://www.semanticscholar.org/paper/6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9",
      "venue": "Computer Vision and Pattern Recognition",
      "year": 2017,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9"
      ],
      "path_length": 4.748335043835923,
      "pos": [
        -25.67373424245926,
        -156.74476525141705
      ]
    },
    "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa": {
      "abstract": "Many state-of-the-art general object detection methods make use of shared full-image convolutional features (as in Faster R-CNN). This achieves a reasonable test-phase computation time while enjoys the discriminative power provided by large Convolutional Neural Network (CNN) models. Such designs excel on benchmarks1 which contain natural images but which have very unnatural distributions, i.e. they have an unnaturally high-frequency of the target classes and a bias towards a \u201cfriendly\u201d or \u201cdominant\u201d object scale. In this paper we present further study of the use and adaptation of the Faster R-CNN object detection method for datasets presenting natural scale distribution and unbiased real-world object frequency. In particular, we show that better alignment of the detector scale sensitivity to the extant distribution improves vehicle detection performance. We do this by modifying both the selection of Region Proposals, and through using more scale-appropriate full-image convolution features within the CNN model. By selecting better scales in the region proposal input and by combining feature maps through careful design of the convolutional neural network, we improve performance on smaller objects. We significantly increase detection AP for the KITTI dataset car class from 76.3% on our baseline Faster R-CNN detector to 83.6% in our improved detector.",
      "arxivId": "1802.06926",
      "authors": [
        {
          "ids": [
            "2145973483"
          ],
          "name": "Yang Gao"
        },
        {
          "ids": [
            "22276989"
          ],
          "name": "Shouyan Guo"
        },
        {
          "ids": [
            "2112767856"
          ],
          "name": "Kai-Wei Huang"
        },
        {
          "ids": [
            "2124957359"
          ],
          "name": "Jiaxin Chen"
        },
        {
          "ids": [
            "143683429"
          ],
          "name": "Q. Gong"
        },
        {
          "ids": [
            "2113959886"
          ],
          "name": "Yang Zou"
        },
        {
          "ids": [
            "1571782187"
          ],
          "name": "Tongyao Bai"
        },
        {
          "ids": [
            "1971349"
          ],
          "name": "Gary Overett"
        }
      ],
      "corpusid": 1516637,
      "doi": "10.1109/IVS.2017.7995812",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1802.06926",
        "CorpusId": 1516637,
        "DBLP": "conf/ivs/GaoGHCGZBO17",
        "DOI": "10.1109/IVS.2017.7995812",
        "MAG": "2962982769",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "id": "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "isOpenAccess": true,
      "journalName": "2017 IEEE Intelligent Vehicles Symposium (IV)",
      "journalPages": "785-791",
      "journalVolume": null,
      "magId": "2962982769",
      "number_of_authors": 8,
      "paperId": "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "pdfUrls": [
        "http://arxiv.org/pdf/1802.06926"
      ],
      "pmid": "",
      "publicationDate": "2017-06-11",
      "publicationTypes": [
        "JournalArticle"
      ],
      "title": "Scale optimization for full-image-CNN vehicle detection",
      "tldr": "This paper shows that better alignment of the detector scale sensitivity to the extant distribution improves vehicle detection performance, and selects better scales in the region proposal input and uses more scale-appropriate full-image convolution features within the CNN model to improve performance on smaller objects.",
      "url": "https://www.semanticscholar.org/paper/8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa",
      "venue": "2017 IEEE Intelligent Vehicles Symposium (IV)",
      "year": 2017,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa"
      ],
      "path_length": 4.728984358502075,
      "pos": [
        135.8510312903154,
        67.39293312527346
      ]
    },
    "1c96a4595fcc2ca71ae937acda22de4ba790a4af": {
      "abstract": "S2 TL;DR: The experimental results show that VGG16 with Faster R-CNN perform better than other architectures on the training dataset, and visual analysis of the test dataset is also presented.",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "145116865"
          ],
          "name": "M. Saqib"
        },
        {
          "ids": [
            "2257498"
          ],
          "name": "N. Sharma"
        },
        {
          "ids": [
            "2247706254"
          ],
          "name": "Sultan Daud Khan"
        },
        {
          "ids": [
            "2247672166"
          ],
          "name": "Michael Blumenstein"
        }
      ],
      "corpusid": 262990821,
      "doi": "",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 262990821,
        "DBLP": null,
        "DOI": null,
        "MAG": null,
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "id": "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "isOpenAccess": false,
      "journalName": null,
      "journalPages": null,
      "journalVolume": null,
      "magId": null,
      "number_of_authors": 4,
      "paperId": "1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "pdfUrls": [
        ""
      ],
      "pmid": "",
      "publicationDate": null,
      "publicationTypes": null,
      "title": "A Study on Detecting Drone Using Deep Convolutional Neural Network",
      "tldr": "The experimental results show that VGG16 with Faster R-CNN perform better than other architectures on the training dataset, and visual analysis of the test dataset is also presented.",
      "url": "https://www.semanticscholar.org/paper/1c96a4595fcc2ca71ae937acda22de4ba790a4af",
      "venue": "",
      "year": 2017,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "1c96a4595fcc2ca71ae937acda22de4ba790a4af"
      ],
      "path_length": 4.6324744736346855,
      "pos": [
        11.290731401044104,
        -13.982648949973566
      ]
    },
    "dc1e8c6db204da40791fc61c5cb69bb95ce5c825": {
      "abstract": "State-of-the-art object detection systems rely on an accurate set of region proposals. Several recent methods use a neural network architecture to hypothesize promising object locations. While these approaches are computationally efficient, they rely on fixed image regions as anchors for predictions. In this paper we propose to use a search strategy that adaptively directs computational resources to sub-regions likely to contain objects. Compared to methods based on fixed anchor locations, our approach naturally adapts to cases where object instances are sparse and small. Our approach is comparable in terms of accuracy to the state-of-the-art Faster R-CNN approach while using two orders of magnitude fewer anchors on average. Code is publicly available.",
      "arxivId": "1512.07711",
      "authors": [
        {
          "ids": [
            "2325498"
          ],
          "name": "Y. Lu"
        },
        {
          "ids": [
            "47197693"
          ],
          "name": "T. Javidi"
        },
        {
          "ids": [
            "1749609"
          ],
          "name": "Svetlana Lazebnik"
        }
      ],
      "corpusid": 6368876,
      "doi": "10.1109/CVPR.2016.258",
      "externalIds": {
        "ACL": null,
        "ArXiv": "1512.07711",
        "CorpusId": 6368876,
        "DBLP": "journals/corr/LuJL15",
        "DOI": "10.1109/CVPR.2016.258",
        "MAG": "2963790522",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      "isOpenAccess": true,
      "journalName": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
      "journalPages": "2351-2359",
      "journalVolume": null,
      "magId": "2963790522",
      "number_of_authors": 3,
      "paperId": "dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      "pdfUrls": [
        "https://arxiv.org/pdf/1512.07711"
      ],
      "pmid": "",
      "publicationDate": "2015-12-24",
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ],
      "title": "Adaptive Object Detection Using Adjacency and Zoom Prediction",
      "tldr": "This paper proposes to use a search strategy that adaptively directs computational resources to sub-regions likely to contain objects, similar to the state-of-the-art Faster R-CNN approach while using two orders of magnitude fewer anchors on average.",
      "url": "https://www.semanticscholar.org/paper/dc1e8c6db204da40791fc61c5cb69bb95ce5c825",
      "venue": "Computer Vision and Pattern Recognition",
      "year": 2015,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "dc1e8c6db204da40791fc61c5cb69bb95ce5c825"
      ],
      "path_length": 5.087795175375805,
      "pos": [
        93.19741584098986,
        -81.86667702035993
      ]
    },
    "f4a2732d4051b9c4b5d1f057aaa7935be390f51e": {
      "abstract": "\n \n Region based detectors like Faster R-CNN and R-FCN have achieved leading performance on object detection benchmarks. However, in Faster R-CNN, RoI pooling is used to extract feature of each region, which might harm the classification as the RoI pooling loses spatial resolution. Also it gets slow when a large number of proposals are utilized. R-FCN is a fully convolutional structure that uses a position-sensitive pooling layer to extract prediction score of each region, which speeds up network by sharing computation of RoIs and prevents the feature map from losing information in RoI-pooling. But R-FCN can not benefit from fully connected layer (or global average pooling), which enables Faster R-CNN to utilize global context information. In this paper, we propose R-FCN++ to address this issue in two-fold: first we involve Global Context Module to improve the classification score maps by adopting large, separable convolutional kernels. Second we introduce a new pooling method to better extract scores from the score maps, by using row-wise or column-wise max pooling. Our approach achieves state-of-the-art single-model results on both Pascal VOC and MS COCO object detection benchmarks, 87.3% on Pascal VOC 2012 test dataset and 42.3% on COCO 2015 test-dev dataset. Code will be made publicly available.\n \n",
      "arxivId": null,
      "authors": [
        {
          "ids": [
            "6000385"
          ],
          "name": "Zeming Li"
        },
        {
          "ids": [
            "2664636"
          ],
          "name": "Yilun Chen"
        },
        {
          "ids": [
            "2116565951"
          ],
          "name": "Gang Yu"
        },
        {
          "ids": [
            "40381677"
          ],
          "name": "Yangdong Deng"
        }
      ],
      "corpusid": 19097331,
      "doi": "10.1609/aaai.v32i1.12265",
      "externalIds": {
        "ACL": null,
        "ArXiv": null,
        "CorpusId": 19097331,
        "DBLP": "conf/aaai/LiCYD18",
        "DOI": "10.1609/aaai.v32i1.12265",
        "MAG": "2789006728",
        "PubMed": null,
        "PubMedCentral": null
      },
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "id": "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      "isOpenAccess": true,
      "journalName": null,
      "journalPages": "7073-7080",
      "journalVolume": null,
      "magId": "2789006728",
      "number_of_authors": 4,
      "paperId": "f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      "pdfUrls": [
        "https://ojs.aaai.org/index.php/AAAI/article/download/12265/12124"
      ],
      "pmid": "",
      "publicationDate": "2018-04-27",
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ],
      "title": "R-FCN++: Towards Accurate Region-Based Fully Convolutional Networks for Object Detection",
      "tldr": "This paper involves Global Context Module to improve the classification score maps by adopting large, separable convolutional kernels and introduces a new pooling method to better extract scores from the score maps, by using row-wise or column-wise max pooling.",
      "url": "https://www.semanticscholar.org/paper/f4a2732d4051b9c4b5d1f057aaa7935be390f51e",
      "venue": "AAAI Conference on Artificial Intelligence",
      "year": 2018,
      "path": [
        "9397e7acd062245d37350f5c05faf56e9cfae0d6",
        "f4a2732d4051b9c4b5d1f057aaa7935be390f51e"
      ],
      "path_length": 4.42054334909701,
      "pos": [
        52.38262062793962,
        -110.42573103629941
      ]
    }
  },
  "path_lengths": {
    "9397e7acd062245d37350f5c05faf56e9cfae0d6": 0,
    "f622c957ffcee97299deb2c76334667cb61501cb": 6.450396367762371,
    "479bd6d4a871fd2e0b718c8a106f86acda2878b0": 5.348668210527676,
    "0bd949f948f8f7afc0578d23d065b36c5c03c509": 6.144114779731152,
    "a13f17c989b7f3328be7b8392e360172c6292492": 7.822736837125379,
    "e35d05f5abd049389e3022f40d467cf472f4987e": 4.9530663616321515,
    "1ac0ab5919725fb535b96a97fec42a027ddab54e": 6.6845807122871985,
    "689757a2c0443f2f98c1c99c9e71683a49b1b757": 7.102153557979742,
    "ec76e9d9e73351933740bd95774b798ab775fccb": 6.839331219357639,
    "c4700a0be2f3621310c5d1142bd2d29431efcc10": 4.084883119019987,
    "8b9253650137ae378f061c5bf9f112d368d08b88": 7.395693716343052,
    "1b6e3cca886eb6a8b9018ab8b87b3a0be02665a2": 6.254580549039626,
    "ea18b5cb9cda042e69c2045e1a8c964aa132bfb3": 6.141204452937721,
    "43e4e008d85a6d6e806fd197725e623c7bd90aa1": 5.50106343744119,
    "2b16d04ae11a903c079946c83ea2b5d517cce970": 4.8211946209059375,
    "2f285bde35b5c328b059c9df40576aba662ca051": 7.448442528242749,
    "be1fb04cf17e259933ce33f0015cf54132f266be": 4.437416229805832,
    "a3a45ce4474f736861216a141ea4f006dac78244": 7.395693716343052,
    "361b19d2c00d086fa8ef860374f5e1d862fd2f30": 6.542794459865371,
    "6b8d0df903496699e52b4daee5d1815b7b784cf7": 5.7989130758751335,
    "51f5e7b847e65a4cd0634ed9efc6b19819742b70": 6.245724101060537,
    "bac287c2da6c02a2de88f8e0ea8d45f77de4670d": 7.375388347729939,
    "7c2f6424b0bb2c28f282fbc0b4e98bf85d5584eb": 4.728984358502075,
    "518a7c79968a56d63a691d42f8378be6c776167e": 7.4309744488488345,
    "c5260d2ec5916a85f772ca000d731fd6bc1e3c5c": 4.432298853880181,
    "738fa51e1a0f5c652019ab7165841ca4d399ce59": 5.087795175375805,
    "5761bb2f65cf1de3a08c09d3c7e362cd7d17fed9": 7.367395640531338,
    "26c35c20fb7f5b354fb72bad867b8b54b07e2bd3": 5.760123136476343,
    "cdd8bad29b5e90a1f92080eaca51ba123f34ada5": 5.160934066553201,
    "7e74aeedff4a0a071a981e591758cc263a04952a": 7.1462384811265345,
    "b2480a283178f79f12b6ccee3e6bafad4bfe20a4": 7.023277345719928,
    "0f366de3ea595932dad06389f6e61fe0dd8cbe74": 5.414741765996206,
    "1080c99530beb71efd915f0615e532987a334d4b": 6.923026385483989,
    "67cdd7b7d8413ce7b177a6b7e6199a575aa0b315": 7.4357616516362866,
    "c1e53c31202d7c9512857d4dd73a8e6d05a48849": 7.036618443194257,
    "25bb88d33937e3adfd928a92271d4e85779efa5c": 7.168133909686345,
    "63828ee0e448694447cc8833960a59a77009667d": 6.500905689052079,
    "e7713751e08a6e837a4b9bcd766b021ee5c15502": 6.610377968599076,
    "c2f06ff302c393d8e14b90ebd14e28582631209f": 7.67021490744189,
    "506c2fbfa9d16037d50d650547ad3366bb1e1cde": 7.624280904523754,
    "deb324e53955621095e0fc76679e1701f7d18b23": 5.983454987806299,
    "b02535c3c9364375950d0e608c40e2fb945e4907": 5.3029874465652895,
    "71a0f60d000253f9ca13ba4819e2c8ac91d68715": 5.17436625755923,
    "34f6eaa5d5abb02fd9aabbcc090a8e890a3472a4": 6.2119378333550666,
    "ca7871a6571158cad8d8fcd114c115c39c372ac6": 4.010575152528445,
    "5987d33f3011408c89d92a64090a0b03f264f3be": 7.59638776081287,
    "dc386d60f0291abcc9750d4218a5f1c717301710": 6.835598252114866,
    "f35559b2497a885bd3dad039ad5212bb48a0e60f": 6.473615057651362,
    "f075f89b4f4026748cbf2fb9f989a9934c42ee8f": 6.812109629571886,
    "1158de029ac516d1f073c8db46005f187eceb0ef": 7.67652515061016,
    "7372537b10f52b0c855b5c7e2ee35f64ee4b0381": 7.549285914304001,
    "c0e08662562025a8a93026f3e8c5ed12d6df50cb": 6.638110399926702,
    "a6107dbdaaa548f115576c7288034114c5462df4": 6.530654052347611,
    "b724c3f7ff395235b62537203ddeb710f0eb27bb": 5.150042848924902,
    "e94183191183a368bf07eb544654bae4b3cbf407": 6.166049681239709,
    "dbc886bcfd504bb1f977eeaf191dac08566f4584": 7.227715120155379,
    "4328ec9d98eff5d7eb70997f76d81b27849f3220": 4.735232000688618,
    "eb46cf7e2eb7f2fa8eca7ee6e0b18fe96ea26965": 5.5273789172055725,
    "9d749272116cf168b6aefe1289bbbbb31313b4e5": 7.219198294328303,
    "1fc5465f3aa9c3efddd23cbaedf96399d9d40711": 7.506583045636434,
    "f8e79ac0ea341056ef20f2616628b3e964764cfd": 5.019878472498986,
    "540b5b4919d345e4da3cc4f3e8a7862329bf41a2": 8.11791249875154,
    "63333669bcf694aba2e1928f6060ab1d6a5161fe": 6.798705180161613,
    "12e94e888a9966738c56430abff7ed7fa452221b": 6.912234786452799,
    "8b1971f47e7cc1416d695a8df610e90a709acf47": 6.82679419970128,
    "abe334384f09edfb53bb9e5ce37e8c04ab5e401e": 5.863855358321688,
    "45d45687ebca6281d44e477cd012a1ef48ebf286": 1.4856273981463097,
    "405bf4eb5af09ddad173ac02f9035c4876e8a3c9": 3.169446174824272,
    "5c64f130f14ce50ca77385840795e75ea38b2a95": 5.388511249169993,
    "ddbd24a73ba3d74028596f393bb07a6b87a469c0": 6.62242278957527,
    "b655a9488edd938f2a75d0f238667826d6d1c474": 5.9738913026772975,
    "605f67614cb2f6e747b1c035912d1636e7b6c564": 6.826965509416395,
    "f4c42c58c6649538c85b85b5357b29793798109b": 6.369652401247693,
    "f6e0856b4a9199fa968ac00da612a9407b5cb85c": 7.637483758987814,
    "b6946370d6c13d562b96e42d494817c7d1969a8f": 4.883707559171131,
    "15a4e2a15f20ed77609a70fb268cbcfafa21df54": 7.381271984565535,
    "6dc71e318afd9a9628ab091ea7519fbfd97e0ef4": 7.602417706575971,
    "908aede816237fb8b9c265d95fa1f2240c13604f": 7.694373551407805,
    "6547857057e139bde9818610fb5d80b3af935c8f": 5.300274319716016,
    "923b8b4d95d85add562708d982c38ad2ce662a5b": 5.333514192363429,
    "9b3ebe2dd5172e4d24dfa0882747c3fbe675f452": 8.151400250400409,
    "eaa7b6893790279292e9f2fafe48662af8b6ae3d": 2.4110612321798905,
    "ec5e361de214c2a1f1893c947b2b4e5ad6e61e4d": 6.952703169669142,
    "eb42cf88027de515750f230b23b1a057dc782108": 6.122821425324513,
    "2a94c84383ee3de5e6211d43d16e7de387f68878": 6.29323986334606,
    "938ed8b290dcc01acfacf3533477e404f1d19c23": 4.1436052628719615,
    "365b31515028f2c7444d5b5afd865d242b229bd2": 4.931529273987683,
    "0e979c8ccc42c1e222770dff1fb8b67e0b027262": 6.514103819297,
    "6a42027ae2ecfdb78e60c49c35dc054579b108e1": 5.597573322308579,
    "cc8c435453d57ff1ea5b81fe9c3f0c948ec8f97d": 6.891236216150339,
    "d5c4a0d3da58ed31223d543207beabbcbe55f293": 7.969172606815228,
    "42ede987f94692f47038d02d936bdcb6bc37d0c9": 7.623253522999762,
    "e30d9b8ce108d982169621b88a5e3fb69fec70e1": 6.5282657363436725,
    "842ca93d770edef147e9ca117e1c0294a596cb82": 6.929908729632145,
    "424561d8585ff8ebce7d5d07de8dbf7aae5e7270": 5.665248883770734,
    "b70bc54f360857ba0dbee3d6c85792ac03fae946": 3.876914159182338,
    "5b5302e1fb7e791ce2c8c563a91f9d7a73bfa2c1": 1.547172683077717,
    "0be9113b606e8d39285c6d598b915e510ac7dd2c": 6.9419554460328134,
    "2755c2bed9e698020fc1e2a47a314338bb39b6a9": 5.422080928556309,
    "51ac16a6b9909f63b5f289a3159afb6955742a30": 7.302445217525228,
    "b83e129daf39089f33a47395c0357ae6158277d6": 6.716519604329402,
    "64628673d884b5f3a506a55c01cfeb76878a5aa3": 6.372596375090261,
    "092f71e25dcc1839508ba18728eefd8ce4ef4b08": 7.5030158565197596,
    "8a969bac2ade5c1c64be3fde47fc206e1c4cbe49": 6.852201825584639,
    "ac03e40cc705cbd9270d221eb23cf06460be579e": 5.123464044304989,
    "cbb19236820a96038d000dc629225d36e0b6294a": 6.490036584648811,
    "d3eb6e57f618cf0830678594efd7e67eec76a898": 4.096845479070101,
    "1c8c77afa31d57c45cfbf404231217dc4db17a14": 2.777893510322868,
    "1d0e7715a4c3f6c81fe35f766d96eb74178e6b2f": 4.290516992280083,
    "4ef826d8915a1b28980ef883dbd623a8f9bf54f1": 3.496712478041394,
    "4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0": 5.595912038702361,
    "14a657db8a4e95e07379494828717027965022dc": 7.174622564564043,
    "663a60841c3e703d7c18cf78f0657efee6aebb9d": 4.238315712819225,
    "0c61c9a4e9bf2b592fed965359dfdaf170f3023e": 5.50106343744119,
    "58b09127761bb83f4761de108eb4d88e92b4f451": 6.851977898263343,
    "c2eaffc617c57ab5106ba3bc95b7b910be473389": 3.709960128410297,
    "7e1e9488e65ad2f9d9171ebac959969b1ca19188": 3.799491181648799,
    "a62c5449a65c5590c93423ddfc76bd46d0469684": 7.282174968296673,
    "a08767952d56b006deecb75488a6c5ce5c8aa16d": 1.3000950974449854,
    "336d6b546ecef1f8464ed9da81fde0d77f438404": 6.141204452937721,
    "cb6190167ec5834c429e1a156d71396c6bb89289": 5.563993058646601,
    "51579a8a40aea8dc6b9cdea9499dc27c2797499d": 3.0154496649518125,
    "f96f8d0dc849361405ed12b2227a41bfa25b4b20": 6.536496075734156,
    "290ac8dc6be972230e9ba1290c2a354800274cfb": 7.346073505728155,
    "168078e8a405526976533fd92b61085041ee1d2c": 7.368565130717883,
    "21552fa5a24ec4bee1bfe780aa8cc450bce03a47": 7.183558879187945,
    "8352826ff8f12ded684bf07540341a5ef6da06fd": 1.4398907477773968,
    "d70da852acf3498225a14c25007926d5399092e2": 5.239107695956282,
    "2a206f4735a544021a6b87059033f4a98b6f26c6": 6.781677416055659,
    "b95191e4672475b32d0a4c571bd2817659747dca": 2.6790367613564774,
    "9b7af646fc817fa1aca2fc6655d64686a65ab17a": 7.0846635249807575,
    "12f0a96d3c8c082278a7d19a99eea20f1eb3c0ef": 7.1722049368690595,
    "8d0662ab216352a020ed83f5b8c3ff79fa9507aa": 5.166288141865112,
    "36f470a638d9a759132e2112689d2ce96646d4cb": 6.9119159280241815,
    "7856b3a1ad066b81a67c22c6d739e34c55cf6d89": 5.8267860339247015,
    "84e99ced038b6255f750b368cb4d59d458ad1f31": 7.694373551407805,
    "c158b0f91837a3499682a11ed8fa1687d6fbd910": 5.874933726180772,
    "f3567cc03b0116138b8f60bb0b0b7221b2838dfd": 6.402603068705986,
    "48504abf10689257bf92ff44b41e80dd5e0167f4": 8.083723629482076,
    "a598e30cce3902fafa5c2692e2ad68437339b383": 4.268866020496522,
    "c2849dd4c5de2d765f512c1503076932bea18f4f": 6.1440141784165725,
    "9ce1fc051a3629b4265d473d395b58154db4bf90": 7.964593232984826,
    "e1bb28dd60616a2224195c9a76a1c6ecb9a3dd81": 4.3884114132014425,
    "0d44970499a233c3be99995f615a91980becf3d4": 1.3795267027628146,
    "2808a637e3967e94d479f93d632e1b76030a96dc": 7.811182979391274,
    "899e7ff67aa2630edc8776758cc5d65823f099c1": 5.997145295111656,
    "1a05dff7bb97f1c930de961fa6c6587f231f4214": 7.699578050754364,
    "49036dab78cf63b120de6ac3e90b8a616809a671": 6.652862269424084,
    "3bb4c3127c77ffb06a81cfe09862716a0828114c": 4.350815616063446,
    "5f35c45bad6a7a9e8783d36773ab571f1f7a9084": 6.485454489716217,
    "74dfc77f5e635cedbaf8592db5ce3784c80a9b40": 7.604600003036183,
    "6e4e5ef25f657de8fb383c8dfeb8e229eea28bb9": 4.748335043835923,
    "3247610e9ed42c773113f6f6d75b14a4e3188ad0": 7.144775440592963,
    "c37fe13f94dfc2f3494a35a63336689ce4392135": 5.254608131945504,
    "e39ea61d4751fa3447041ad0706e32e88be15e9d": 7.509878123749282,
    "7d39d69b23424446f0400ef603b2e3e22d0309d6": 5.873150550319674,
    "8e9ff8224753b22e3b1f8bbe271382d6fdb8ddfa": 4.728984358502075,
    "b026a4735566a51f03bf3a1669cf259a6e72b182": 5.790593092043357,
    "1c96a4595fcc2ca71ae937acda22de4ba790a4af": 4.6324744736346855,
    "dc1e8c6db204da40791fc61c5cb69bb95ce5c825": 5.087795175375805,
    "f4a2732d4051b9c4b5d1f057aaa7935be390f51e": 4.42054334909701
  },
  "start_id": "9397e7acd062245d37350f5c05faf56e9cfae0d6"
}