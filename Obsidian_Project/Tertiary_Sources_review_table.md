> Tags: #LiteratureReview #TranslationTheory #Skopos #Critique #Tables

# Tertiary Sources Review: Mapping Theory to Computation

## 1. Usage Notes
This table identifies the **Tertiary Sources**—the theoretical lenses from Translation Studies and Critical AI Studies—required to analyze the engineering breakthroughs listed in the previous files. These sources provide the "Why" and the "How" for human translators interacting with machines.

**Legend:**
- **TS Source**: The classic Translation Studies text.
- **AI/LLM Counterpart**: The engineering concept that unknowingly replicates the TS theory.
- **Operational Lesson**: How to apply this theory when prompting or evaluating LLMs.

## 2. The Master Table of Tertiary Sources

| Critical Vector | Source (Author, Year) | Key Concept (TS) | AI/LLM Counterpart | Operational Application for Translators |
| :--- | :--- | :--- | :--- | :--- |
| **1. Skopos & Prompting** | **Reiss & Vermeer (2013)**<br>*Towards a General Theory of Translational Action: Skopos Theory Explained* | **Skopos Theory**:<br>The purpose (Skopos) of the translation determines the method. The target text (Translatum) is functionally dependent on the brief. | **System Instruction / Prompting**:<br>The prompt sets the "objective function" or "alignment goal" for the generation. | **Prompting as Briefing**:<br>A prompt must explicitly define the Skopos (Purpose), Addressee, and Function. Without a Skopos, the LLM reverts to its training average (probabilistic default). |
| **1. Skopos & Prompting** | **Christiane Nord (1997)**<br>*Translating as a Purposeful Activity* | **Functionality + Loyalty**:<br>Balancing the client's purpose with ethical loyalty to the source author/text. | **Alignment (RLHF)**:<br>The tension between "Helpfulness" (User intent) and "Truthfulness" (Factual grounding). | **Ethical Prompting**:<br>Instructing the model to flag ambiguity or refuse hallucination to maintain "Loyalty" to the source truth. |
| **2. Context Engineering** | **M.A.K. Halliday (1978)**<br>*Language as Social Semiotic* | **Register Theory (Field, Tenor, Mode)**:<br>Language variation depends on the social setting, relationship between participants, and medium. | **Context Window / Style Transfer**:<br>The token limit wherein the model attends to stylistic cues. | **Parameterizing Context**:<br>Defining "Tenor" (Formal/Casual) and "Field" (Legal/Medical) in the system prompt to constrain the search space of the LLM. |
| **2. Context Engineering** | **Juliane House (2015)**<br>*Translation Quality Assessment* | **Overt vs. Covert Translation**:<br>Is the translation visible as a translation, or does it pass as an original? | **Zero-shot vs. Few-shot Style Adaptation**:<br>Instructing the model to "mimic natural target flow" (Covert) vs. "literal gloss" (Overt). | **Style Guides as Few-Shot**:<br>Providing 3 examples of the desired "Covert" style in the prompt prevents the "Translationese" often generated by default. |
| **3. Empiric Critique** | **Dorothy Kenny (2022)**<br>*Machine Translation for Everyone: Empowering Users in the Age of Artificial Intelligence* | **Machine Translation Literacy**:<br>Understanding *how* the engine works to critique its output effectively. | **Explainability / Interpretability**:<br>The "Black Box" problem in Neural Networks. | **Process Analysis**:<br>Moving from "Spot the Error" to "Audit the Process." Asking the LLM *why* it chose a term (Chain-of-Thought) to assess its logic. |
| **3. Empiric Critique** | **Lynne Bowker (2023)**<br>*De-mystifying Translation: Introducing Translation to Non-translators* | **The "Data Void"**:<br>LLMs perform poorly on low-resource languages or specialized domains due to lack of training data. | **Bias & Hallucination**:<br>The model fabricating facts when the probability distribution is flat (unknown territory). | **Risk Assessment**:<br>Identifying "High Risk" texts (nuanced, cultural, low-resource) where LLMs should not be used or require 100% human post-editing. |
| **3. Empiric Critique** | **Philipp Koehn (2010/2020)**<br>*Statistical Machine Translation* | **The Flaw of BLEU**:<br>Automatic metrics (BLEU) do not measure meaning, only n-gram overlap. | **Loss Functions**:<br>Training objectives minimize mathematical error, not semantic error. | **Human-in-the-Loop**:<br>Rejecting "Score-based" trust. Adopting "Holistic Evaluation" where the translator assesses coherence and cohesion, not just word matches. |

## 3. Data Download (CSV Simulation)
*Copy the block below to save as `tertiary_sources.csv`.*

```csv
Vector,Source,Concept,AI_Counterpart,Application
Skopos,Reiss & Vermeer (2013),Skopos Theory,System Instruction,Prompting as Briefing
Skopos,Nord (1997),Loyalty,RLHF Alignment,Ethical Prompting
Context,Halliday (1978),Register (Field/Tenor/Mode),Context Window,Parameterizing Context
Context,House (2015),Overt/Covert,Style Transfer,Style Guides as Few-Shot
Critique,Kenny (2022),MT Literacy,Explainability,Process Analysis
Critique,Bowker (2023),Data Void,Hallucination/Bias,Risk Assessment
Critique,Koehn (2010),BLEU Flaw,Loss Functions,Human-in-the-Loop
```

## 4. References (Short Form)
*Full citations available in References.md*

- **Bowker, L.** (2023). *De-mystifying Translation: Introducing Translation to Non-translators*.
- **Halliday, M. A. K.** (1978). *Language as Social Semiotic*.
- **House, J.** (2015). *Translation Quality Assessment: Past and Present*.
- **Kenny, D.** (2022). *Machine Translation for Everyone: Empowering Users in the Age of Artificial Intelligence*.
- **Koehn, P.** (2010). *Statistical Machine Translation*.
- **Nord, C.** (1997). *Translating as a Purposeful Activity*.
- **Reiss, K., & Vermeer, H. J.** (2013). *Towards a General Theory of Translational Action: Skopos Theory Explained* (C. Nord, Trans.).


---
## Cross-References
- [[outline]]
- [[References]]
- [[General_Terminology]]
- [[Visual_Assets]]
