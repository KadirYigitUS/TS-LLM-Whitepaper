---
title: Discussion — Collision of Probability and Purpose
---

# Discussion — Probability vs. Purpose

This chapter preserves the argumentative structure of `Discussions.md` and is intended for seminars or peer-review packets.

## 1. Two Epistemologies
- **Engineering lineage**: Optimize prediction, scaling, loss minimization.
- **Translation Studies lineage**: Optimize purpose, culture, ethics.
- **Collision**: We use prediction machines to achieve purposeful social action.

## 2. Dialogue 1 — Average vs. Skopos
- Scaling papers (Kaplan, Brown) chase the linguistic mean.
- Vermeer’s Skopos demands *particular* outcomes.
- Translators must fight regression-to-the-mean by scripting prompts that embody marginal use cases.

## 3. Dialogue 2 — Alignment vs. Loyalty
- RLHF encodes crowd-worker preferences (helpful, harmless, honest).
- Nord’s Loyalty adds obligations to author/client/reader that may conflict with safety layers.
- Professional fix: maintain open-weight stacks for sensitive work or capture legal justification when overriding alignment.

## 4. Dialogue 3 — Context Window vs. Context of Situation
- Transformers understand syntactic context; they do not perceive history/culture outside the token window.
- Halliday’s Field/Tenor/Mode must be manually injected—context windows are simulacra.

## 5. Role Shift Table
```{list-table}
:header-rows: 1
* - Traditional role
  - AI-augmented role
  - Supporting theory
* - Drafting
  - Prompting / Commission design
  - Skopos (Vermeer, Nord)
* - Dictionary lookup
  - Retrieval APIs / Toolformer
  - Schick et al., 2023
* - Contextualization
  - Context injection packets
  - Halliday, 1978
* - Revision
  - Probabilistic auditing / MQM
  - Kenny, 2022
* - Ethics
  - Alignment overrides, loyalty memos
  - Nord, 1997
```

## 6. Cyborg Conclusion
LLMs solved text prediction (Papers #1–5) but not social negotiation. Translators become pilots who direct probabilistic engines through cultural terrain.
